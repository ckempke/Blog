{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my little corner of the Internet! I'll assume you're one of my legions of fans that have come from the Terrain Generation pages: https://ckempke.github.io/UnityTerrainGeneration with questions like \"wait, you have legions of fans?\" and \"how do I actually find what's new on that site, anyway?\" You'll be ecstatic to learn that this is a much more traditional \"Blog\" format, with, like, dated pages and \"most-recent-at-the-top\" and all that cool stuff that was state of the art in the late 90's. The Actual Blog \u00b6 {{ blog_content }} Who Am I? \u00b6 I'm Chris Kempke. Over my 30-year career, I've worked for a few consulting companies, MultiAd Services, HP, Microsoft, and Everbridge. I have a Master's Degree in Computer Science from Oregon State University and a B.A. in Computer Science from Carleton College. (Trivia: I graduated in 1989, and was the first declared Computer Science major at Carleton). Now retired, I've been spending my time writing (both fiction and not), and learning some of those technologies I didn't have time for in my working life. I still have too many hobbies, and occasionally do a little consulting to keep my hand in. A lot of my time these days is spent in Unity (the 3D game engine), mostly trying to make it do things that it doesn't want to do. I tend to write about those, too; I haven't yet made the jump to video like all the \"cool kids\" are doing these days. My blogging software is adapted from a system more intended for documentation; it does not have a \"comments\" section, as you can probably tell by the lack of off-topic badly-written political rants. But if you have comments, you can e-mail them to me at my gmail.com address of \"Christopher.kempke\" and maybe I'll add constructive comments here, manually. My own little rant is that I'm not a fan of most of the large social media apps: I blame their algorithmic, engagement-driven but truth-independent \"filtering\" for a society in which there seems to be no conspiracy or information so obviously, ridiculously, over-the-top-obviously false that about a third of supposedly rational adults won't still somehow believe it. So now that I have no need to integrate with these things for work, I don't. I have no (active, anyway) accounts on Facebook, Twitter, Instagram, TikTok, etc. I do maintain a presence on LinkedIn, primarily because it amuses me how their algorithms don't handle \"Retired\" as a status, and keep recommending to me hundreds of people at \"my company: Retired\" as close network associates. But if you need a temporary, part-time employee for a technical or documentation project, feel free to reach out to me. I might be interested. About this Site \u00b6 A few of you may have stumbled on my previous blog, with one of those hosting services that shall not be named. I'm not entirely sure how they continue to exist, but this one takes forever (minutes sometimes) to process every change, doesn't support Safari (mobile or desktop) with their main theme, and seems more intent on upselling various services than actually providing a web site. Ah, well, water under the bridge. Very expensive water. We're now hosting on GitHub Pages , which is free (for sites within reason), pretty easy for a developer to use (it's the same Git tools we use every day, and the content is just Markdown), and extremely performant. This site uses the MkDocs publishing system, Material theme, and a blogging plugin from https://liang2kl.codes/mkdocs-blogging-plugin/ . Material is supposed to support blogging internally later this year (2022) or early next, so the appearance of the site may change then. I use KaTeX for mathematical markup, and Mermaid-js if I need graphs or flowcharts. Editorial Policy \u00b6 I believe there's some value in a \"paper trail\" of what people say. Information on the web is malleable; I can say today that I hate Honey Nut Cheerios, and tomorrow that exact same article can say I love them. (If it's going to keep you up at night, I'm actually rather ambivalent about them, and on the rare occasions when they're in my house, they're usually generic ones, anyway). There's no accountability in the face of the ability to retroactively edit. So while I'm a fan of \"edit\" buttons\u2014because I mess up spelling and grammar, especially when I type quickly\u2014I generally prefer the ones that have a short time limit before the entered information becomes immutable. However , this isn't meant to be an opinion site. I mean, it is \u2014all blogs are, I suppose\u2014but it's not meant to be a place for public discourse. The opinions here are just mine or those I choose to present. And frankly, opinion pieces on the net, or elsewhere, tend not to change many minds, in my experience. So I intend to use this blog mostly to inform, amuse, or teach. And for those purposes, being able to clean up language, grammar, presentation, outright mistakes, images, etc. over time is invaluable, and tends to make the presented information more valuable, not less. So you'll probably see small edits frequently, and large ones occasionally. Getting things right often involves a step of getting them wrong, first. If I find that something's wrong, I'll change it. And I'm one of those people that fiddles constantly with wording and grammar, can't ever get \"it's\" and \"its\" correct on the first try, and have an evolving, adversarial relationship with bold, italics, code case , and other formatting standards. But if I actually change content in a significant way (correcting something that was originally wrong, or explicitly changing my mind or advice), I'll try to indicate that, along with the reason for the change. Cookies \u00b6 If this site uses cookies, I don't know about them. It's possible the underlying document presentation engine does. In any event, by continuing to use the site: You agree to all cookies, even the ones with raisins in them and even if you don't like raisins. You also agree to send me all your money You agree not to consult a lawyer about whether or not the previous clause is enforceable or not. I don't want your personal information, and if I get any on me, I'll wash it off. However, I think that usage statistics are gathered here by some analytics engine or other. So if you're particularly paranoid about your IP address or something, be aware that someone's probably got it in a log somewhere.","title":"Home"},{"location":"#the-actual-blog","text":"{{ blog_content }}","title":"The Actual Blog"},{"location":"#who-am-i","text":"I'm Chris Kempke. Over my 30-year career, I've worked for a few consulting companies, MultiAd Services, HP, Microsoft, and Everbridge. I have a Master's Degree in Computer Science from Oregon State University and a B.A. in Computer Science from Carleton College. (Trivia: I graduated in 1989, and was the first declared Computer Science major at Carleton). Now retired, I've been spending my time writing (both fiction and not), and learning some of those technologies I didn't have time for in my working life. I still have too many hobbies, and occasionally do a little consulting to keep my hand in. A lot of my time these days is spent in Unity (the 3D game engine), mostly trying to make it do things that it doesn't want to do. I tend to write about those, too; I haven't yet made the jump to video like all the \"cool kids\" are doing these days. My blogging software is adapted from a system more intended for documentation; it does not have a \"comments\" section, as you can probably tell by the lack of off-topic badly-written political rants. But if you have comments, you can e-mail them to me at my gmail.com address of \"Christopher.kempke\" and maybe I'll add constructive comments here, manually. My own little rant is that I'm not a fan of most of the large social media apps: I blame their algorithmic, engagement-driven but truth-independent \"filtering\" for a society in which there seems to be no conspiracy or information so obviously, ridiculously, over-the-top-obviously false that about a third of supposedly rational adults won't still somehow believe it. So now that I have no need to integrate with these things for work, I don't. I have no (active, anyway) accounts on Facebook, Twitter, Instagram, TikTok, etc. I do maintain a presence on LinkedIn, primarily because it amuses me how their algorithms don't handle \"Retired\" as a status, and keep recommending to me hundreds of people at \"my company: Retired\" as close network associates. But if you need a temporary, part-time employee for a technical or documentation project, feel free to reach out to me. I might be interested.","title":"Who Am I?"},{"location":"#about-this-site","text":"A few of you may have stumbled on my previous blog, with one of those hosting services that shall not be named. I'm not entirely sure how they continue to exist, but this one takes forever (minutes sometimes) to process every change, doesn't support Safari (mobile or desktop) with their main theme, and seems more intent on upselling various services than actually providing a web site. Ah, well, water under the bridge. Very expensive water. We're now hosting on GitHub Pages , which is free (for sites within reason), pretty easy for a developer to use (it's the same Git tools we use every day, and the content is just Markdown), and extremely performant. This site uses the MkDocs publishing system, Material theme, and a blogging plugin from https://liang2kl.codes/mkdocs-blogging-plugin/ . Material is supposed to support blogging internally later this year (2022) or early next, so the appearance of the site may change then. I use KaTeX for mathematical markup, and Mermaid-js if I need graphs or flowcharts.","title":"About this Site"},{"location":"#editorial-policy","text":"I believe there's some value in a \"paper trail\" of what people say. Information on the web is malleable; I can say today that I hate Honey Nut Cheerios, and tomorrow that exact same article can say I love them. (If it's going to keep you up at night, I'm actually rather ambivalent about them, and on the rare occasions when they're in my house, they're usually generic ones, anyway). There's no accountability in the face of the ability to retroactively edit. So while I'm a fan of \"edit\" buttons\u2014because I mess up spelling and grammar, especially when I type quickly\u2014I generally prefer the ones that have a short time limit before the entered information becomes immutable. However , this isn't meant to be an opinion site. I mean, it is \u2014all blogs are, I suppose\u2014but it's not meant to be a place for public discourse. The opinions here are just mine or those I choose to present. And frankly, opinion pieces on the net, or elsewhere, tend not to change many minds, in my experience. So I intend to use this blog mostly to inform, amuse, or teach. And for those purposes, being able to clean up language, grammar, presentation, outright mistakes, images, etc. over time is invaluable, and tends to make the presented information more valuable, not less. So you'll probably see small edits frequently, and large ones occasionally. Getting things right often involves a step of getting them wrong, first. If I find that something's wrong, I'll change it. And I'm one of those people that fiddles constantly with wording and grammar, can't ever get \"it's\" and \"its\" correct on the first try, and have an evolving, adversarial relationship with bold, italics, code case , and other formatting standards. But if I actually change content in a significant way (correcting something that was originally wrong, or explicitly changing my mind or advice), I'll try to indicate that, along with the reason for the change.","title":"Editorial Policy"},{"location":"#cookies","text":"If this site uses cookies, I don't know about them. It's possible the underlying document presentation engine does. In any event, by continuing to use the site: You agree to all cookies, even the ones with raisins in them and even if you don't like raisins. You also agree to send me all your money You agree not to consult a lawyer about whether or not the previous clause is enforceable or not. I don't want your personal information, and if I get any on me, I'll wash it off. However, I think that usage statistics are gathered here by some analytics engine or other. So if you're particularly paranoid about your IP address or something, be aware that someone's probably got it in a log somewhere.","title":"Cookies"},{"location":"tags/","text":"Blog Posts by Tag/Topic \u00b6 These are the same blog posts, but indexed by their content tags rather than date. {{ tag_content }}","title":"Posts by Topic"},{"location":"tags/#blog-posts-by-tagtopic","text":"These are the same blog posts, but indexed by their content tags rather than date. {{ tag_content }}","title":"Blog Posts by Tag/Topic"},{"location":"blog/1-AUG-2022/","tags":["mkdocs","blogging","github-pages"],"text":"#mkdocs #blogging #github-pages .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } This is just a test page being used while I set up GitHub pages. It'll disappear soon, but if you take screenshots and print them out, you can post them on your refrigerator and keep them forever.","title":"Hello, World!"},{"location":"blog/7-JULY-2021/","tags":["mkdocs","markdown","technology"],"text":"#mkdocs #markdown #technology .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } [This blog post has time travelled. It is from a previous blog that predates the very existence of this one.] Being the Internet, I should probably attribute that to either Mark Twain or Abraham Lincoln (and in fact, Google and Bing give dozens of people who supposedly said it), but it's from Andrew Tannenbaum's Computer Networking textbook that I used when I was in college, and seems to be original with him. My \"standard of the day\" is Markdown. If you're not familiar with it, it's basically \"HTML lite\" -- a way of writing documentation by specifying the function, rather than the format, of each textual element, and then it gets magically massaged into something that looks good. It's very lightweight, very broadly supported, and you can learn it in about fifteen minutes (for example, look here: https://www.markdownguide.org/cheat-sheet/). It makes up the baseline documentation format for many blog tools (including this one, although I haven't figured out how to turn it on, yet), GitHub, most modern Wikis, and the internal documentation systems of both Android and Apple. Apple's recent WWDC had a number of sessions on their flavor, called DocC, that's basically the future of formatting for them (even for in-code comments, which is pretty slick, actually). As a baseline documentation language, it serves roughly the same function for technical writers as C does for developers: what you use might not be exactly the same, but you can bet it's heavily influenced by it. But--as with C-like languages--\"flavor\" is the right word. John Gruber invented it in 2004 or so, and the basics haven't changed much. But all it really does is give you formatting of lists in various ways, headings and outlines, paragraphs, internal and external links, and the sort of basic \"emphasis\" technologies like italics and boldface. Which is actually sort of a nice feature: it basically removes the emphasis from formatting back to content . But there's a lot of ways of presenting information, some of which are pretty standard: footnotes, references, tables, various types of \"code\" blocks, and the like. So lots of systems have \"extended\" it in various ways, and not all of those are compatible with each other. So when someone tells you to write in Markdown, \"Which one?\" is not an unreasonable question. Probably the de-facto winner in the Markdown war is \"Github Flavored Markdown,\" (https://github.github.com/gfm/) just because of its centrality to one of the most common developer tools on the web. So if that same someone responds to your question with \"Uh, I don't know?\" GFM is a good baseline assumption. Github also has a backend system called Github Pages that allows you to add structured Markdown files to your Github projects (or just to your Github account), and it will render them using its \"Jekyll\" rendering engine. Looking into technologies for a potential writing project, a former boss of mine pointed me at Docsify (https://docsify.js.org/#/), which is a replacement for Jekyll that does a little more stuff: in particular, it supports custom sidebars/guides, renders the markdown into HTML on demand (rather than requiring a compiling step), and is also supported by Github Pages. Even better, if you fuss with it a little bit, you can use Mermaid (https://mermaid-js.github.io/mermaid/#/) in code blocks, which gives you a near-magical ability to create the various charts (Gantt, Flow, Sequence Diagram, etc.) that make up the technical documenter's nightmares, using a language so simple you can teach it to pretty much anybody who understands what the charts are supposed to represent. I've been playing with this a bit on a GitHub project for terrain generation in the Unity game engine. You can see the documentation as it gets written here: https://ckempke.github.io/UnityTerrainGeneration/#/ [Update, a year later]. Docsify proved to be a little too \"strict\" in its formatting options to allow the flexibility I was looking for, so I currently use MkDocs , which is a more advanced version of the same sort of markdown->HTML site generator. In fact, you're looking at it now, since this blog is rendered with it.","title":"The nice thing about standards is that you have so many to choose from."},{"location":"blog/8-DEC-2021/","tags":["writing","grammar"],"text":"#writing #grammar .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } [This blog post has time travelled. It is from a previous blog that predates the very existence of this one.] We often don't pay much attention to the humble apostrophe. It serves its purposes so well that it just sort of blends into the background, unnoticed and unloved. But it lies at the epicenter of an interesting and common cognitive bug. The apostrophe serves several purposes (in English, anyway). First, an apostrophe can indicate elided (left out) letters in contractions. When we lose the \"o\" in \"does not\", it is replaced with an apostrophe: \"doesn't.\" Similarly \"cannot\" becomes \"can't,\" and so on. The utility of this in modern English is debated; some styles prohibit contractions at all in formal writing. After all, \"doesn't\" replaces a mere two characters (the \"o\" and a space) with one (the apostrophe itself), and the savings in other contractions are similarly small. If the goal is saving space, abbreviations, acronyms, and other more powerful linguistic tools are a better choice. There are environments where saving a character or two matters a lot: the canonical example is print newspapers, whose narrow columns are prone to unfortunate line breaks. But for most writing, most of the time, the contraction is a stylistic choice. Where it really shines is conveying dialog; however much we may differ in expressing ourselves in writing, nearly everyone uses contractions in speech. It's difficult not to: the science fiction character Data from Star Trek supposedly cannot (or does not) use contractions, but the writers of the show accidentally included them with some frequency despite this. In writing, both fiction and nonfiction, contractions help convey how people actually speak. Apostrophes help with dialog in other ways: they can convey a sort of inside-a-word pause like glottal stops or syllabic breaks, either when transcribing a word of foreign origin like \"Sahai'a\" or \"Xi'an,\" or for ex-contractions where the original form has vanished from usage entirely, such as \"o'clock.\" Science fiction writers love this for \"alien\" names; there are books where every other character's name is something like \"K'th'q'dp'tl'nt'sr'thik.\" (For real-world speech which uses sounds atypical in other languages--such as that of the San people--all sorts of punctuation may be waylaid and repurposed for transcription.) Probably the most common use of the apostrophe, however, is to show possession. The \"girl's pet,\" the \"shop's inventory,\" the \"dog's bone.\" This use is so common that it's often misused , ala Dave Barry's joke that the use of an apostrophe is to indicate to the reader that an \"s\" is coming up. And the misuses are interesting to me. I'm a writer. Directly and otherwise, a significant portion of my income has always derived from my ability to convey information in written form; it's safe to say that I do this for a living. And yet, I cannot seem to get \"its\" and \"it's\" right in my first drafts--I'm so consistently wrong that checking it is the first item on my personal proofreading list. Heck, this article is literally about the use of \"it's\" and \"its\", and I've had to correct the mistake twice already. Luckily for my writing ego, I'm not alone. I consume a lot of writing as well as producing it, and a surprisingly large percentage of the writers use the wrong form frequently. A quick google indicates that it's a problem for a very large number--perhaps even a majority--of \"casual\" writers of English. (It is, ironically, one of those mistakes made much less frequently by non-native speakers.) It's not that I don't know the rule, and I suspect it's not that other writers don't know the rule, either. We teach this distinction in roughly third or fourth grade in the US. My suspicion is that what we're looking at here is a conflict in how our brains deal with rules in general. Grammar is hard. The rules of English grammar alone are enough to fill a very long book, and--largely because English has borrowed from so many other languages over time--the rules often have exceptions: *\"I\" before \"E,\" * Except after \"C,\" Or when sound is \"long a\", As in \"neighbor\" and \"weigh,\" None of which helps a bit, With \"weird\" \"foreign\" words, like \"counterfeit.\" As an amusing(?) aside, a recent study found that the \"'I' before 'e'\" rule in English is actually wrong slightly more often than it's right. The exceptions don't just prove the rule, they outnumber it. If we had to pin down every rule, exception, and usage for everything we say or write, we'd never get to convey anything. So we rely on sentence patterns, experience, and rules of thumb to get us through. These \"rules of thumb\" are simpler rules that--hopefully--fail us rarely enough that it doesn't matter. We can keep enough of these simpler rules \"in our heads\" to help us through day to day conversations and writing, and either live with or deal with the exceptions in a separate pass or with separate tools. It's obvious that the particular rule set is at least somewhat personalized. Consider the sentence: \"Ameilia has less apples than Feifei.\" From my casual surveys, about half the people who hear that cringe internally, and the other half don't give it a second thought. The difference--one I think interesting enough to have its own article--is whether or not your personal rule set includes \"use 'fewer' rather than 'less' for countable items.\" So, back to \"it's\" and \"its.\" We have a few rules that apply here: Rule 1: Use an apostrophe followed by \"s\" after a singular noun or pronoun to indicate possession. (And an \"s\" followed by an apostrophe for plural ones.): \"Bob's hat,\" \"one's speech,\" \"the city schools' funding,\" \"dogs' rights.\" Rule 2: Use an apostrophe for left-out characters in a contraction: \"do not\" == \"don't,\" \"is not\" == \"isn't,\" \"it has\" == \"it's.\" The problem is that there are exceptions. Rule 3: We don't use apostrophe-s for pronouns, such as \"his\" for \"he,\" \"their\" or \"theirs\" for \"they,\" or \"hers\" for \"her.\" Rule 4: Rule (1) doesn't apply If the plural form doesn't end in \"s\", instead, we pretend it's singular: \"women's rights,\" not \"womens' rights.\" Rule 5: Rule (3) doesn't apply if there's not a specific possessive form of the pronoun: it's \"one's thoughts,\" not \"ones thoughts.\" Worse, there is at least one case where the correct form depends on usage: Rule 6: The form of \"they\" in the sentence \"That's their dog\" is different from the one in the semantically identical sentence \"That dog is theirs.\" \"Theirs\" is a possessive pronoun in this case, but \"their\" is a pronoun-derived possessive adjective . Which is an incredibly subtle distinction, but--weirdly--one that native speakers almost never get wrong, even though probably fewer than one such speaker in a hundred could tell you why. (And I'm not that one person; I looked it up.) So, that's a lot of rules so far. But why do people have trouble with \"it's\" and \"its,\" but not the others, even in cases like rule (6) that are, on the face of it, much harder? I'd argue it's because your brain has brought too many rules into play. Most possessive pronouns or adjectives have a form different from their base pronoun form: \"His,\" not \"hes\"; \"my,\" not \"Is\"; \"their,\" not \"theys\"; and so on. Rule three only really matches two pronouns whose possessive and base forms differ only by the added \"s\": \"her/hers\" and \"it/its.\" Some quick googling indicates that there's actually a fair amount of folks out there that incorrectly use \"her's,\" but nowhere near the level of \"it's.\" I suspect that it's because \"her\" is a complex usage-based pronoun/adjective, similar to rule (6) above. Rule 7: The feminine pronoun varies a lot based on usage: \"her\" as a pronoun, but only as the object of the sentence : \"I like her.\" \"hers\" as a possessive pronoun: \"That book is hers.\" \"her\" as a possessive adjective: \"Amy ate her lunch.\" \"She\" as the pronoun if it's the subject of the sentence: \"She likes me.\" In other words, if you use she/her/hers without further thinking about it, you're almost certain to get it wrong. So your brain has prioritized this rule as one to be applied first when you're using feminine pronouns. Perhaps more relevantly, you've probably internalized simple rule 8: Rule 8: \"Her's\" is never correct in any usage. Because English doesn't make contractions from nouns used as objects of sentences, there's no contraction form of \"her.\" \"She has\" or \"She is\" are both contractable--\"she's\" in both cases--but never \"her has\" or \"her is.\" At this point, you're probably sick of all these rules. And that's sort of the point; when your brain is trying to construct a sentence, it wants to get on with communicating, not go down checklists of grammatical minutia. And maybe more importantly, your brain evolved to listen, and to speak. Writing is comparatively modern, and even among those of us that do it professionally, we do a lot less of it than speaking and listening. In spoken English, there's no distinction between \"its\" and \"it's\" at all. So, when faced with the decision for a form of \"it,\" some of our brains pretty much give up after rules (1) and (2). In my experience, which rule gets applied tends to differ between people: I will incorrectly use \"it's\" when I mean \"its,\" but almost never the reverse, so my particular grey matter gives up after rule (1). I see others who primarily err the other direction. Why do non-native speakers have less trouble with this? Assuming that this statement is true (I have only anecdotal evidence to support it), my suspicion is because they're always bogged down in rules. Without a lifetime of internalizing patterns, you're basically forced to construct sentences by brute force, and so you're likely to spend more time with the internal checklists. It would be interesting to know whether or not this error starts to creep in as non-native speakers approach native fluency; I have no idea whether it does or not.","title":"If its \"it is\", its \"its\" is \"it's\""},{"location":"blog/ai-generated-art/","tags":["artificial intelligence","technology"],"text":"#artificial intelligence #technology .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } Artists aren't doomed, quite yet \u00b6 In the last few weeks, mainstream news has started covering synthetic art generation systems\u2014Artificial Intelligence systems that can \"learn\" about various art techniques, artists, forms, subjects, and the like, then generate new, original creations based on either a provided \"starter\" image or, more interestingly, a simple text prompt. The general public awareness of this was probably prompted by a story about an AI-generated artwork winning an art competition; more technical sources have been talking about these AIs for several months now. There are several of these around: MidJourney and Stable Diffusion are two of the most discussed, but there are several more. Most have some mechanism by which the general public can try them out, but at the moment they usually require acquiring a bit (or a lot) of technical knowledge. They tend to be driven by command lines, scripts with many complex dependencies, or weird notebook-like things. MidJourney can be invoked by Discord channel. If you want to try them out yourself, you won't have a long wait. There are numerous projects working on creating installable, GUI-based versions of these tools. Several probably exist already if you look around hard enough. Whichever of the sources you use, they work in similar ways. They're fed a massive library of captioned images (typically selected from the Internet), and based on analysis of these images and their captions, they start learning what attributes go with what captions. Given enough source material (and \"enough\" here is very large: hundreds of thousands at a minimum ), they can start to invert the process and construct entirely new images based on text prompts. They can mimic particular art styles or even particular artists, and (at least where the subjects are sufficiently present in the input set) a vast array of different subjects. Need a kitten in the style of Vincent van Gogh? You might get the image at the top, or maybe this one: Which is kinda slick, but you might also get THIS one: That's pretty much just a photo of a kitten pasted over a vaguely van Gogh background. Reaction among artists ranged from amusement to alarm, with many foretelling the end of human artists altogether. (This was also predicted at the invention of the camera, digital cameras, television, video, photoshop, the printing press, and probably most other inventions throughout history). Is that likely? Maybe. But it hasn't happened yet. A quick note: There are several of these AI generators, and they use different code, training models, interfaces, etc. They have their individual strengths and weaknesses. The images in this post all come from Stable Diffusion. How many tails does the average wolf have, again? \u00b6 In order to get those three example images, I produced about twenty. And that's for kittens. With the possible exception of pornography, it seems likely that there are more pictures of cats on the Internet than any other subject. And Vincent van Gogh is probably one of the five or so most common names you'd get if you stopped people on the street and asked them to name a famous historical painter. And even given these subjects--which likely appeared prolifically in the training sets, it generates far more trash than treasure. Realistic subjects are particularly bad: look carefully at that kitten \"photo\" above. What the heck happened to its legs? Here's one of the better images from \"a large gray wolf running through a pacific northwest forest:\" And that's not an exception. I have never , in thousands of images, gotten realistic humans who don't have missing or extra limbs, weird bodily contortions, random numbers of fingers, and the like. It does better with mere faces, but even then you get an awful lot of impossible ones for every good image. And it likes adding humans even when you didn't ask for them: \"An abstract piece of feudal japanese art\" gave me this gem: I don't even want to know what training set produced that. Landscapes and abstractions seem easier for it. \"A river flowing through an ice cave\" produced several very nice images, even if they didn't match the prompt very well. If you look at that closely, there are some shapes that don't make good \"sense,\" but it's a perfectly usable image. As a background for some fantasy adventure, it wouldn't raise an eyebrow. Under the right circumstances, you might be able to pass it off as a photograph. Let's add a \"a dragon resting\" to our ice cave: Don't look too closely, and that image passes pretty well, too. Although the dragon has a weird body shape, as well. We'll come back to dragons, later. I am, apparently, not using very good prompts for most of these. There's an, ah, \"art\" to crafting good prompts, and you'll find references online that can give you help. One reference I used while installing Stable Diffusion suggests this as a test prompt: \"a beautiful dense amazon forest with tall trees and thick cannopy, moss on tree trunks and rocks, big rocks on the ground, a lonely boy stands staring into the path that leads into the forrest, trending on Artstation\" Letting it produce only one image with that prompt, we get this in about 45 seconds: There's no \"lonely boy\" visible in that image, but it's otherwise pretty good. Many of the suggested prompts you see online have things like \"trending on (some social media or art site)\" or \"as imagined/painted by (known artist)\" or a specific style specification. Nearly all have lots of adjectives, multiple small descriptive clauses, and few relationships (on/in/next to). And right now, that seems to be the state of AI image generation. Far from replacing artists, we seem to have developed a new \"prompt crafting\" art form requirement. And even then, we need an awful lot of human curation: The jungle scene above was a first image, but usually you need to generate tens or hundreds of them to get one really good one. Originality? \u00b6 And even when you do, I'm uncertain as to the level of originality being presented. For example, back to the dragons. When fed some prompts of the \"a dragon in (place) ...\" for several different places, I got about 200 images, which contained all of these: Those are based on collector cards from Magic the Gathering or some similar collectable card game, so close to the originals that individual words and numbers are sometimes legible in them. And they made up about eight percent of my output. There are a couple possibilities, here. (A) For each of those \"synthesized\" images, a single, specific source made up the bulk of the image. In other words, less of \"image synthesis,\" more of \"some sort of hallucinogenic search engine.\" (B) These card formats are so distinctive in style that they effectively make up an \"art style\" of their own, and these actually are more or less completely original images, just presented in a \"MTG Card\" style while will have future art historians writing dissertations about the importance of saving throws in mis-21st-century discourse. That's a big difference, and which of those possibilities is its can be important. In part, this is because of a quirk of copyright law: images not produced by humans are in the public domain. But if you can just \"use an AI\" to copy something and magically turn it into public domain art, it's unlikely that rights holders will allow that state will persist long. So, which is it? Short answer: I don't know. Given the vagaries of how these sorts of machine learning models work, it's possible that nobody knows. Machine Learning doesn't always give you good explanations for \"why did you choose this answer?\" (Although they can: consider the \"Why are you showing me this?\" button on many recommendation engines.) But what technology taketh away, technology can also giveth. It's possible to do sort of the \"reverse\" trick, using either Bing Visual Search or Google Image search (just go to Google, click on \"Images\", and then click on the camera in the search box). Both of these are a sort of \"search by visual similarity\" engine for the web. My theory, here, goes a little like this: These AI tools were generated using training sets from the Internet. If case (A) is correct, and we're just getting back heavily distorted versions of some unique original, then it's likely that a reverse image search on the result might find the original image. Like many of my theories, it doesn't work. Neither engine finds particularly close matches to any of these cards, for particular definitions of \"particularly close,\" anyway. These collectable card games are seemingly obsessed with dragons and dragon-like creatures to the point where there are thousands of \"some sort of dragon in one of these card frames\" images out there. Side Note: For this particular case, and in general when I've used it, the Bing engine is overwhelmingly better at producing \"close\" images than the Google one is. Bing generated almost all \"card\" images, Google didn't have any in the first couple pages. I have no idea why. Google also figured out that my kitten images were kittens and gave me lots of them, but Bing not only saw \"kitten\", but also \"Van Gogh Style\" in its results. I'd hoped to find a smoking gun card -- one which matched most of the text and significant parts of the image. I didn't find that for any of my \"generated\" cards, on either search engine. So does that tell me that (B) is a better explanation, or just that the \"visual similarity\" algorithms used by these engines isn't good at unravelling the distortions of case (A)? Again, I have no idea. Back to the Future \u00b6 In 2004, DARPA had a contest for self-driving vehicles. A few dozen teams competed to navigate a 250 km course across a desert with no human intervention. It was a triumph for humanity\u2014in the sense that we had nothing to fear from the robots. None made it even 5% of the distance. Many barely got off the starting line. Skynet was permanently and forever ruled out. Jump forward a mere 18 months. In late 2005, the same challenge was run again, but the results were...different. Many of the vehicles navigated the entire course. All but one did better than all of the previous year's contestants. Everyone named Sarah Connor within the test area was forced to flee. All science and engineering probably used to be this way, massive leaps in understanding, explanation, and general knowledge every few months or years\u2014when they were new. But most of our science and engineering disciplines are hundreds of years old, now. Not computer science, and not A.I. Right now, we're in the \"rapid discovery\" part of virtually every technological field. Sure, the latest iPad may not seem all that innovative compared to the previous model, but a mere fifteen years ago, a computer less than a half inch thick that you could hold in your hand would have been borderline magic. Twice that long ago and the idea that you could have such a device--and on it watch effectively every television show and movie ever made, without requiring it to even be plugged in, in a resolution indistinguishable from photographs, weighing about a pound, and inexpensive enough that almost everybody could have one?...well, it would have been beyond laughable. Nobody would believe it even as science fiction. So while our short term future may be of single-pawed kittens, multi-tailed wolves, and humans that look like the result of a fire in a wax museum, I suspect that this reprieve will be short-lived. Give 'em a year to refine the algorithms, a few million more images for the training sets, and I suspect we'll be looking at a DARPA 2005 situation. Not that we need to wait until then to ask the big question. Really, the one we've been asking since we started scratching on cave walls. Is it art?","title":"Artists aren't doomed, quite yet"},{"location":"blog/ai-generated-art/#artists-arent-doomed-quite-yet","text":"In the last few weeks, mainstream news has started covering synthetic art generation systems\u2014Artificial Intelligence systems that can \"learn\" about various art techniques, artists, forms, subjects, and the like, then generate new, original creations based on either a provided \"starter\" image or, more interestingly, a simple text prompt. The general public awareness of this was probably prompted by a story about an AI-generated artwork winning an art competition; more technical sources have been talking about these AIs for several months now. There are several of these around: MidJourney and Stable Diffusion are two of the most discussed, but there are several more. Most have some mechanism by which the general public can try them out, but at the moment they usually require acquiring a bit (or a lot) of technical knowledge. They tend to be driven by command lines, scripts with many complex dependencies, or weird notebook-like things. MidJourney can be invoked by Discord channel. If you want to try them out yourself, you won't have a long wait. There are numerous projects working on creating installable, GUI-based versions of these tools. Several probably exist already if you look around hard enough. Whichever of the sources you use, they work in similar ways. They're fed a massive library of captioned images (typically selected from the Internet), and based on analysis of these images and their captions, they start learning what attributes go with what captions. Given enough source material (and \"enough\" here is very large: hundreds of thousands at a minimum ), they can start to invert the process and construct entirely new images based on text prompts. They can mimic particular art styles or even particular artists, and (at least where the subjects are sufficiently present in the input set) a vast array of different subjects. Need a kitten in the style of Vincent van Gogh? You might get the image at the top, or maybe this one: Which is kinda slick, but you might also get THIS one: That's pretty much just a photo of a kitten pasted over a vaguely van Gogh background. Reaction among artists ranged from amusement to alarm, with many foretelling the end of human artists altogether. (This was also predicted at the invention of the camera, digital cameras, television, video, photoshop, the printing press, and probably most other inventions throughout history). Is that likely? Maybe. But it hasn't happened yet. A quick note: There are several of these AI generators, and they use different code, training models, interfaces, etc. They have their individual strengths and weaknesses. The images in this post all come from Stable Diffusion.","title":"Artists aren't doomed, quite yet"},{"location":"blog/ai-generated-art/#how-many-tails-does-the-average-wolf-have-again","text":"In order to get those three example images, I produced about twenty. And that's for kittens. With the possible exception of pornography, it seems likely that there are more pictures of cats on the Internet than any other subject. And Vincent van Gogh is probably one of the five or so most common names you'd get if you stopped people on the street and asked them to name a famous historical painter. And even given these subjects--which likely appeared prolifically in the training sets, it generates far more trash than treasure. Realistic subjects are particularly bad: look carefully at that kitten \"photo\" above. What the heck happened to its legs? Here's one of the better images from \"a large gray wolf running through a pacific northwest forest:\" And that's not an exception. I have never , in thousands of images, gotten realistic humans who don't have missing or extra limbs, weird bodily contortions, random numbers of fingers, and the like. It does better with mere faces, but even then you get an awful lot of impossible ones for every good image. And it likes adding humans even when you didn't ask for them: \"An abstract piece of feudal japanese art\" gave me this gem: I don't even want to know what training set produced that. Landscapes and abstractions seem easier for it. \"A river flowing through an ice cave\" produced several very nice images, even if they didn't match the prompt very well. If you look at that closely, there are some shapes that don't make good \"sense,\" but it's a perfectly usable image. As a background for some fantasy adventure, it wouldn't raise an eyebrow. Under the right circumstances, you might be able to pass it off as a photograph. Let's add a \"a dragon resting\" to our ice cave: Don't look too closely, and that image passes pretty well, too. Although the dragon has a weird body shape, as well. We'll come back to dragons, later. I am, apparently, not using very good prompts for most of these. There's an, ah, \"art\" to crafting good prompts, and you'll find references online that can give you help. One reference I used while installing Stable Diffusion suggests this as a test prompt: \"a beautiful dense amazon forest with tall trees and thick cannopy, moss on tree trunks and rocks, big rocks on the ground, a lonely boy stands staring into the path that leads into the forrest, trending on Artstation\" Letting it produce only one image with that prompt, we get this in about 45 seconds: There's no \"lonely boy\" visible in that image, but it's otherwise pretty good. Many of the suggested prompts you see online have things like \"trending on (some social media or art site)\" or \"as imagined/painted by (known artist)\" or a specific style specification. Nearly all have lots of adjectives, multiple small descriptive clauses, and few relationships (on/in/next to). And right now, that seems to be the state of AI image generation. Far from replacing artists, we seem to have developed a new \"prompt crafting\" art form requirement. And even then, we need an awful lot of human curation: The jungle scene above was a first image, but usually you need to generate tens or hundreds of them to get one really good one.","title":"How many tails does the average wolf have, again?"},{"location":"blog/ai-generated-art/#originality","text":"And even when you do, I'm uncertain as to the level of originality being presented. For example, back to the dragons. When fed some prompts of the \"a dragon in (place) ...\" for several different places, I got about 200 images, which contained all of these: Those are based on collector cards from Magic the Gathering or some similar collectable card game, so close to the originals that individual words and numbers are sometimes legible in them. And they made up about eight percent of my output. There are a couple possibilities, here. (A) For each of those \"synthesized\" images, a single, specific source made up the bulk of the image. In other words, less of \"image synthesis,\" more of \"some sort of hallucinogenic search engine.\" (B) These card formats are so distinctive in style that they effectively make up an \"art style\" of their own, and these actually are more or less completely original images, just presented in a \"MTG Card\" style while will have future art historians writing dissertations about the importance of saving throws in mis-21st-century discourse. That's a big difference, and which of those possibilities is its can be important. In part, this is because of a quirk of copyright law: images not produced by humans are in the public domain. But if you can just \"use an AI\" to copy something and magically turn it into public domain art, it's unlikely that rights holders will allow that state will persist long. So, which is it? Short answer: I don't know. Given the vagaries of how these sorts of machine learning models work, it's possible that nobody knows. Machine Learning doesn't always give you good explanations for \"why did you choose this answer?\" (Although they can: consider the \"Why are you showing me this?\" button on many recommendation engines.) But what technology taketh away, technology can also giveth. It's possible to do sort of the \"reverse\" trick, using either Bing Visual Search or Google Image search (just go to Google, click on \"Images\", and then click on the camera in the search box). Both of these are a sort of \"search by visual similarity\" engine for the web. My theory, here, goes a little like this: These AI tools were generated using training sets from the Internet. If case (A) is correct, and we're just getting back heavily distorted versions of some unique original, then it's likely that a reverse image search on the result might find the original image. Like many of my theories, it doesn't work. Neither engine finds particularly close matches to any of these cards, for particular definitions of \"particularly close,\" anyway. These collectable card games are seemingly obsessed with dragons and dragon-like creatures to the point where there are thousands of \"some sort of dragon in one of these card frames\" images out there. Side Note: For this particular case, and in general when I've used it, the Bing engine is overwhelmingly better at producing \"close\" images than the Google one is. Bing generated almost all \"card\" images, Google didn't have any in the first couple pages. I have no idea why. Google also figured out that my kitten images were kittens and gave me lots of them, but Bing not only saw \"kitten\", but also \"Van Gogh Style\" in its results. I'd hoped to find a smoking gun card -- one which matched most of the text and significant parts of the image. I didn't find that for any of my \"generated\" cards, on either search engine. So does that tell me that (B) is a better explanation, or just that the \"visual similarity\" algorithms used by these engines isn't good at unravelling the distortions of case (A)? Again, I have no idea.","title":"Originality?"},{"location":"blog/ai-generated-art/#back-to-the-future","text":"In 2004, DARPA had a contest for self-driving vehicles. A few dozen teams competed to navigate a 250 km course across a desert with no human intervention. It was a triumph for humanity\u2014in the sense that we had nothing to fear from the robots. None made it even 5% of the distance. Many barely got off the starting line. Skynet was permanently and forever ruled out. Jump forward a mere 18 months. In late 2005, the same challenge was run again, but the results were...different. Many of the vehicles navigated the entire course. All but one did better than all of the previous year's contestants. Everyone named Sarah Connor within the test area was forced to flee. All science and engineering probably used to be this way, massive leaps in understanding, explanation, and general knowledge every few months or years\u2014when they were new. But most of our science and engineering disciplines are hundreds of years old, now. Not computer science, and not A.I. Right now, we're in the \"rapid discovery\" part of virtually every technological field. Sure, the latest iPad may not seem all that innovative compared to the previous model, but a mere fifteen years ago, a computer less than a half inch thick that you could hold in your hand would have been borderline magic. Twice that long ago and the idea that you could have such a device--and on it watch effectively every television show and movie ever made, without requiring it to even be plugged in, in a resolution indistinguishable from photographs, weighing about a pound, and inexpensive enough that almost everybody could have one?...well, it would have been beyond laughable. Nobody would believe it even as science fiction. So while our short term future may be of single-pawed kittens, multi-tailed wolves, and humans that look like the result of a fire in a wax museum, I suspect that this reprieve will be short-lived. Give 'em a year to refine the algorithms, a few million more images for the training sets, and I suspect we'll be looking at a DARPA 2005 situation. Not that we need to wait until then to ask the big question. Really, the one we've been asking since we started scratching on cave walls. Is it art?","title":"Back to the Future"},{"location":"blog/procedural-language/","tags":["language","procedural generation","technology","games"],"text":"#language #procedural generation #technology #games .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } Procedural Language Generation for a Fantasy Game \u00b6 No Man's Sky has an interesting\u2014if not particularly realistic\u2014language mechanism. Each of its three main races, plus the Atlas, have their own language. The player learns these languages (if they wish), one word at a time, and when presented with text in the \"alien\" language, known words are substituted with the player's chosen game language (which I'll assume to be English for convenience, here, although the game ships with several real-world languages available). This makes finding and learning new words a background game objective, and adds more things for the player \"to do\" that produce meaningful rewards, which is always a challenge for procedural games, where things like quests, monsters, and locations are almost literally cookie-cutter. NMS makes several simplifying assumptions: A \"word\" in the alien language corresponds to exactly one \"word\" in English. Even more unrealistically: word order, grammar, and punctuation of the alien languages correspond exactly to English, as well. Effectively all alien languages are substitution ciphers, where you take an English sentence, substitute an alien word for each English one, and produce the result. Things like homographs (words that are the same spelling but different pronunciation and/or meaning, like pencil \"lead\" vs. \"lead\" troops) are homographs in all the languages, as well. All the languages are written using the same character set. As anyone who's ever learned another language can tell you, none of these are particularly realistic; some are laughably silly. But the simplifications actually make the language interactions more puzzle-like, since you've got more information available to you than just the set of words that you know. What are we trying to build? \u00b6 For a game I'm writing, I'm looking for a similar mechanism. Like NMS, this game is extremely--almost pathologically-procedural, at least to the limits of what a single developer can produce in a reasonable time. (I've resorted to asset store monsters, for example). One planned element here is procedural pasts. At world creation time, the last few thousand years of \"history\" are procedurally generated. Each empire's ebb and flow are recorded, so that at any given time we can say things like \"this particular area was held by the \\'Empire of Bob\\' 2000 years ago, so if you have ruins/dungeons/castles from that time, they're probably Bobian.\" This stuff then feeds into the quest, lore, and location generators. Similarly, the state of the generator at the \"present time\" determines political boundaries. So I want each of these empires, kingdoms, etc.\u2014both past and present\u2014to have languages associated with them. Often it'll be one-to-one: an empire speaks a specific language. But it need not be: sometimes there will be multiple \"competing\" languages within and empire (especially if it just took over lands that used to be owned by another), and often a language will be shared across empires (especially if friendly, or parts of the same historical empire.). In the real world, languages are sometimes separated by political boundaries, but far more often by either geography, culture, or history. In a nutshell, though, we don't know how many languages we're going to need, it can be arbitrarily many, or few, depending on what the generator produces. And we'd like an additional requirement: these languages shouldn't be just random strings of pronounceable characters. They should be visually distinct from each other. Players should be able to distinguish languages from each other by appearance, at least most of the time. So we want a system to generate arbitrarily many distinct languages, each of which can be \"learned\" piecemeal in the No Man's Sky style. What makes up a language? \u00b6 The dictionary tells us that a \"language\" is...well, it doesn't actually matter, because don't actually want a language. We want something that looks and works just enough like a natural language to be a game substitute for one\u2014similar to how we abstract \"injury\" into \"hit points\" or the uneven task of learning skills into \"skill trees\" of one sort or another. Tolkien was a master of creating languages (he used real languages as a base). Even ignoring the writing system glyphs, you could tell them apart: elvish was full of L and N and vowel sounds, the dwarves used lots of K, H, D, and U. Men (by which he mean \"all humans\"\u2014 The Hobbit was published in 1937) tended toward old-English-y names with lots of E's and O's. Star Trek's Klingon , meant to be the harsh tongue of a warrior race, leans heavily into hard consonants: Q, K, and P, and loves glottal stops (the hard break between consonant sounds that don't blend into each other): \"Q'pla\" and the like; a sort of \"coughing\" language that would probably be impractical in real life. Maybe the closest approximation being something like the San language or German. But if we just make tables of letter frequencies and put them together, we tend to get unpronounceable messes: \"BHGLUM\", \"UEILNL\", and the like. That might actually work for Klingon, but in general, it's not going to give us what we want. We could try to construct rules like \"consonants and vowels need to alternate\", which will produce always-pronounceable strings, but with more regularity than we'd like. Syllables to the rescue \u00b6 Luckily, we've got a better construct to build from: the syllable. Syllables are pronounceable sub-components of a word; effectively they're the \"units\" from which words are build. Typically, each one represents a vowel sound and some optional surrounding consonants. What really sets the sounds of languages apart is their choice of syllables. English is a weird outlier: because of \"borrowing\" from every language under the sun, it has something like 16,000 unique syllables in its lexicon. Mandarin Chinese, on the other hand, has a mere 400 or so, although these are multiplied by four or five different \"pronunciation frequencies\" or \"tones,\" to give about 1700 real ones. Even Mandarin is far more than we need. Depending on who you ask, what you mean by \"word\" (are names included? Are plurals/tenses separate words?), and the specific language you're asking about, most people use about 10,000 different words in daily speech, and languages run somewhere between 80,000 and 150,000 total words. But we don't care about the total words, much. It would be a rare game whose text included all of \"verdant,\" \"riboflavin,\" and \"calligraphic.\" We just need our language to be capable of covering any reasonable set of words that we are actually going to use . I've seen estimates that a mere 1000 words is enough to read a newspaper, even if we double or triple that (say, a game like Skyrim with hundreds of \"books\" in it to read), we're still not talking any significant fraction of a real language's scope. So let's say we choose a target of 5,000 unique constructible \"words\" in our language. How many syllables do we need? If words are one syllable each, we need 5000 of them. But if words are just two syllables, suddenly we need only about 70 of them \\((\\sqrt{5000})\\) . At three syllables, it's ( \\(\\sqrt[3]{5000}\\) ), a mere 18 syllables. Since most languages support words of varying length (in fact, average word length in syllables is one of the distinguishing characteristics of languages), or we allow homographs, we could get by with even fewer. Not all Syllables are equal \u00b6 So far, we've got two \"knobs\" we can adjust in order to create our languages: Number of syllables per word The number of available syllables. Next, we should consider the syllables themselves. This is where we give a language it's character. Consider, for example, a \"soft\" language (like Tolkien's Elvish) where we emphasize lilting or rolling consonants (like L, H, M, N) and vowel sounds: private readonly static List < string > softSyllables = new List < string >() { \"la\" , \"le\" , \"lu\" , \"li\" , \"lo\" , \"ly\" , \"na\" , \"ne\" , \"nu\" , \"ni\" , \"no\" , \"ny\" , \"ha\" , \"he\" , \"hu\" , \"hi\" , \"ho\" , \"hy\" , \"ma\" , \"me\" , \"mu\" , \"mi\" , \"mo\" , \"my\" , \"al\" , \"el\" , \"ul\" , \"il\" , \"ol\" , \"yl\" , \"an\" , \"em\" , \"um\" , \"im\" , \"om\" , \"ym\" , \"an\" , \"en\" , \"un\" , \"in\" , \"on\" , \"yn\" , }; This is C#, because the implementation is going to be in Unity, but the language doesn't matter much. That's 35 syllables right there, and even using just that, we can get pleasant-sounding nonsense like \"\"noulmima na om olloully\" or \"emmuno lo nyhymu ynny.\" The regularity of the 2-character syllables produces a sort of artificial-looking regularity to the generated text, but we can work with that. A different set of syllables, heavy on sibilants (S, soft C) and hard consonants (K, P, T): private readonly static List < string > hardSyllables = new List < string >() { \"ka\" , \"ke\" , \"ku\" , \"ki\" , \"ko\" , \"ky\" , \"sa\" , \"se\" , \"su\" , \"si\" , \"so\" , \"sy\" , \"ta\" , \"te\" , \"tu\" , \"ti\" , \"to\" , \"ty\" , \"pa\" , \"pe\" , \"pu\" , \"pi\" , \"po\" , \"py\" , \"ak\" , \"ek\" , \"uk\" , \"ik\" , \"ok\" , \"yk\" , \"at\" , \"et\" , \"ut\" , \"it\" , \"ot\" , \"yt\" , \"as\" , \"es\" , \"us\" , \"is\" , \"os\" , \"ys\" , }; This gives us phrases like: \"eskiakit ystuet ikas ytteak\" and \"taok ok ik ikpa.\" Again, there's too much repetitiveness and pattern here, but again, that's because our syllables set is somewhat uniform and limited. These are sort of the \"extremes\" of a syllabic spectrum. If we define several sets, ranging from lilting to harsh, we then have a third knob for our languages: what sets of syllables are available to it. Something like English or German might distribute pretty easily across the whole spectrum. Spanish-like languages would tend toward the softer end, something like Russian (or Klingon) toward the harder end. (Fantasy languages will likely go further out on the spectrum than natural languages will, because natural languages tend to evolve toward more easily-spoken forms over time.) So if we provide a way to generate a distribution (so many syllables from group A, so many from group B, etc.), we can use it to generate languages of different \"character.\" There are hundreds, maybe thousands, of potential syllables using roman/English alphabets, spellings, and pronounciation rules. It's not necessary to provide an exhaustive list -- a few dozen at most should be enough to generate a rich set of languages. (I've provided my lists in the code at the end of this article) A M\u00f8\u00f8se Once Bit My Sister \u00b6 Since we're generating for a written form, and not too concerned about pronunciation, we can also use diacritical marks (those little accents, diaereses, umlauts, grave accents, circumflexes, macrons, tildes, etc.) more or less as decorations rather than to fulfill their usual functions of altering pronunciation, aspiration, or emphasis. By building syllable sets that include diacritical forms, we can then choose (or randomly assign) languages to use them or not. There are some caveats to doing this. The first is that we're likely to generate things that range from nonsensical to outright offensive to speakers of the languages whose marks we're borrowing (e.g. there's no such thing as an \"e-umlaut\" in German, but Unicode lets us generate one easily enough: \"\u00eb\".) If the system you're using is not Unicode-savvy, the risks become much higher. A generation of computer users grew up with \"smart quotes\" from a Mac rendering as gibberish on a PC\u2014and vice versa\u2014even if you were using Microsoft Word on both; you still see these weird characters show up on the web occasionally. And the encoding set of your language or OS may be the least of your problems: any new glyph you use has to be present in whatever font you're using; which is a sort of hit-or-miss proposition when you're using characters \"borrowed\" from languages other than the ones the font is meant for. We've all seen the \"square\" character rendered in place of some missing glyph (or lots of them) from a font. Still, if you're confident in your encoding and font, diacriticals can add another visual distinction to a language, especially if you use different selections of them for different languages. We could go even further down this rabbit hole and generate whole new glyphs (like Ultima 's rune writing) for our systems, but that just makes the font problem even worse. You see this a lot in science fiction movies: \"alien\" alphabets that are full of dots and symmetric geometric forms. OK, Now do we put this together? \u00b6 We want to provide our developer with at least the following capabilities: Generate new synthetic languages Provide a string in \"real\" language and have that translated into the equivalent synthetic language string. For convenience, we probably want to do this at the word level as well as at being able to provide a longer string of text. Provide a string in \"real\" language, along with a \"dictionary\" (in the literary, not programming, sense) of words that the player \"knows\", and have it translated into the equivalent synthetic language string with the \"known\" words indicated in the real language. Note that translations are always real -> synthetic, not the other way around. The app will deal in \"real\" strings, and convert them to synthetic (or part-synthetic) when presenting them to the users. Generating the Language Patterns \u00b6 Our first step is to be able to choose values for all those \"knobs\" we discussed earlier: syllable count ranges, which syllable sets to use, how many syllables to use from each set, whether we use punctuation (and if so, which punctuation) as syllable-separators, and the like. We'd like to spare our caller needing to pick values for all those knobs, and ideally allow them to set none at all\u2014if they wish\u2014for a completely random one. So we'll define a couple of \"categories\" here that categorize the language more simply: // Determines whether the language picks mostly from // the \"soft,\" \"middle,\" or \"hard\" syllables // RANDOM chooses one of these values with equal probability. public enum LanguageBias { RANDOM , SOFT , MIDDLE , HARD , } // Determines the number of syllables used for words (simple = fewer), // and the number of total syllables in the language (simple = fewer here, too). // RANDOM generates a random value. public enum LanguageComplexity { RANDOM , SIMPLE , MEDIUM , COMPLEX , } In both cases, we have a .RANDOM value that we can use if the developer doesn't want to think about it. We can then define a bunch of properties for our language: public class Language { // These are the actual syllables that make up the language. Something like // 20 is probably enough for most purposes (remember that the entire vocabulary // necessary will only have to cover the in-game strings that occur, so a few thousand // words will cover it. [JsonProperty] public List < string > syllables ; // These should add up to 100. They are the chances that a given word will // be 1, 2, 3, 4... syllables, respectively. So {10, 80, 10} would mean that // most words in the language are 2 syllables, but 10% are 1 syllable, and 10% are 3. // If the language is very regular: (all words are the same number of syllables, or // there are only a couple of possibilities), you'll want more syllables in the list // above to cover the vocabulary. [JsonProperty] public int [] percentSyllableCountChance ; // If true, the language uses punctuation to separate syllables within a word, // e.g. O'clock, brick-a-brack. // if true, \"punctuations\" holds the list of available characters, and // \"punctuationChance\" is the percent chance that any two syllables will // have a punctuation mark between them, and \"leadPunctuationChance\" is the // percent chance (which could be higher or lower than punctuationChance) that // there will be a punctuation mark specifically after the first syllable. // (Real, Fantasy, and Science fiction \"languages\" seem to emphasize that form a lot. // Q'pla! T'Challa, O'Callahan). [JsonProperty] public bool usesPunctuationDelimeters ; [JsonProperty] public string []? punctuations ; [JsonProperty] public float? punctuationChance ; [JsonProperty] public float? leadPunctuationChance ; // The actual \"dictionary\" of associations between English (or whatever) and // the synthetic language. [JsonProperty] public Dictionary < string , string > dictionary ; // The actual name of the language, in it's own language. [JsonProperty] public string languageName ; Note that I'm using some C# nullables here, for the potentially-unnecessary punctuation dictionary. Unity's Mono support doesn't allow nullables in older versions; so if your compiler complains, just get rid of the \"?\" characters in the definition of punctuations , punctuationChance , and leadPunctuationChance. Let's write a constructor: public Language ( LanguageBias bias = LanguageBias . RANDOM , LanguageComplexity complexity = LanguageComplexity . RANDOM ) { The developer who wants a particular harshness and complexity can choose it, but called without arguments, we'll just choose at random. For harshness bias, that's pretty easy: // Choose a bias emphasis. LanguageBias useBias = bias ; if ( bias == LanguageBias . RANDOM ) { switch ( UnityEngine . Random . Range ( 0 , 3 )) { case 0 : useBias = LanguageBias . SOFT ; break ; case 1 : useBias = LanguageBias . MIDDLE ; break ; default : useBias = LanguageBias . HARD ; break ; } } This makes the odds even for each possibility, but you can fiddle with the values, if you like. Side Note: As you're about to notice, I'm using a lot of \"magic numbers\"\u2014rather than constants. This is an \"author trick\" to make numbers appear near their usage in context. This is great for authoring blog articles, but sucks for maintenance, where you'd like to have them all in an easily-found block. Once you're done fiddling and have dialed in values you like, you may want to consider changing them to proper constants. \"Complexity\" is a little tougher, we're using it as a proxy for both the total number of syllables in the lexicon and the average number of syllables per word. // And a number of syllables (a crude measure of language complexity). int numSyllables = UnityEngine . Random . Range ( 40 , 120 ); percentSyllableCountChance = new int [] { 25 , 30 , 30 , 10 , 5 }; switch ( complexity ) { case LanguageComplexity . SIMPLE : numSyllables = UnityEngine . Random . Range ( 40 , 60 ); percentSyllableCountChance = new int [] { 50 , 40 , 10 }; break ; case LanguageComplexity . MEDIUM : numSyllables = UnityEngine . Random . Range ( 70 , 105 ); percentSyllableCountChance = new int [] { 45 , 35 , 20 }; break ; case LanguageComplexity . COMPLEX : percentSyllableCountChance = new int [] { 15 , 35 , 25 , 20 , 5 }; numSyllables = 120 ; break ; default : break ; // Already covered } syllables = ChooseSyllables ( useBias , numSyllables ); Again, these are numbers that worked pretty well for me; you can change any of these numbers to match your own needs. The main constraint here is the number of syllables available in the sets. Mine are relatively small; if you have a lot of potential syllables, the numSyllables value can go higher and you can bias more toward shorter words. Real world languages tend to settle in around 1-3 syllables for most common words, since it literally makes speaking easier. We're not considering word rarity here (in English, at least, significantly multisyllabic words tend to be used less, e.g. \"significantly multisyllabic\" vs. \"long\"). We'll come back to ChooseSyllables ; it just picks a random set of syllables for the language, biased by useBias . I want to use punctuation to add a little flavor to my languages, but I don't want to use it very often, or very much of it, to prevent the languages looking like caricatures. So I'm fixing some values here. It would make sense to have some rules (e.g. \"harsh languages have more punctuation\"), but I didn't bother for my needs. // We'll use a fixed 15% chance that our language uses punctuation delimiters usesPunctuationDelimeters = UnityEngine . Random . Range ( 0 , 100 ) < 15 ; if ( usesPunctuationDelimeters ) { // Set these to small, fixed values for now. We can be more // selective later, if we need more variation. punctuations = new string [] { \"-\" , \"'\" , \"*\" }; punctuationChance = 10f ; leadPunctuationChance = 35f ; } Again, if your compiler complains about C# nullables (or you just don't want to use them), get rid of the \"if\" and always set those values, even though they won't be used. Note that the two \"...Chance\" variables are floats, not integers, to allow greater fine-tuning (like English, where hyphenated words are well under 1% of the language). Finally, we just initialize the dictionary Dictionary (sigh...) that will hold our translations as we make them, and then generate a name for our language (in itself, of course). dictionary = new Dictionary < string , string >(); languageName = \"\" ; GenerateLanguageName (); } Utilities \u00b6 Let's write a couple utility functions. We've seen one already, ChooseSyllables() , which selects the syllable set that will be part of our language. public static List < string > ChooseSyllables ( LanguageBias bias , int number ) { List < string > chosen = new List < string >(); List < string > favorite , secondBest , thirdBest ; // Order our lists by how much we like them. switch ( bias ) { case LanguageBias . SOFT : favorite = softSyllables ; secondBest = middleSyllables ; thirdBest = hardSyllables ; break ; case LanguageBias . HARD : favorite = hardSyllables ; secondBest = middleSyllables ; thirdBest = softSyllables ; break ; case LanguageBias . MIDDLE : default : favorite = middleSyllables ; secondBest = softSyllables ; thirdBest = hardSyllables ; break ; } while ( chosen . Count < number ) { int percentileRoll = UnityEngine . Random . Range ( 0 , 100 ); string syllable ; if ( percentileRoll < 70 ) { syllable = favorite [ UnityEngine . Random . Range ( 0 , favorite . Count )]; } else if ( percentileRoll < 95 ) { syllable = secondBest [ UnityEngine . Random . Range ( 0 , secondBest . Count )]; } else { syllable = thirdBest [ UnityEngine . Random . Range ( 0 , thirdBest . Count )]; } if (! chosen . Contains ( syllable )) chosen . Add ( syllable ); } return chosen ; } This isn't going to win any efficiency awards. That while loop does an awful lot of List.Contains() calls (which, since our list is unsorted, is O(n) each time), and after all that effort will throw away the syllable it just picked if it happens to already be in the list. The actual performance hit here is inversely proportional to the difference between the total number of syllables available in our lists and the number we're looking for. If we've got lots more syllables available than we need, it's not bad. As the \"excess\" becomes smaller, the odds of a collision get higher, and we end up discarding more syllables. If the excess becomes very small, this could take a very long time to \"find\" those last few free syllables. If the excess is negative (we're asking for more unique syllables than exist), this will loop forever, and you'll get a crash course (well, a \"hang course\") in how to recover from a hang. (Hint -- kill the Unity Editor by whatever the standard means is on your platform). So, let's add a check at the beginning: int syllablesAvailable = softSyllables . Count + middleSyllables . Count + hardSyllables . Count ; Debug . Assert ( syllablesAvailable > number * 1.5f , $\"ASSERT: We're looking for {number} syllables out of {syllablesAvailable}, which will likely take a long time.\" ); This will check (in debug builds) that we've got at least 150% of the number of syllables that we're asking for. That doesn't actually fix the problem, but it should make us aware of it. An easier case is SyllableCount() , which just used that percentSyllableCountChance array to choose the a number of syllables according to the provided probability distribution: private int SyllableCount () { int num = UnityEngine . Random . Range ( 0 , 100 ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } Once again, the Software Engineer in me is squinting unpleasantly at this. The problem is that \"100.\" If we have no bugs, and our \"percent chances\" are actually percents (i.e. add up to 100), then this works fine. But if we happen to give it an array that sums to more than 100, then the higher values will never get picked. And if we give it an array that sums to less than 100, this will crash if the random generator picks a number greater than our maximum! So are you feeling lucky? I'm not. Let's fix it. private int SyllableCount () { int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } That works better\u2014although it the chance array were empty, or if it held negative values, we could get weird effects. We should return a reasonable default in the first case, and assert on the latter: private int SyllableCount () { if ( percentSyllableCountChance . Length == 0 ) { return 2 ; } int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; Debug . Assert ( chance > 0 , \"ASSERT: Zero or negative probability in percentSyllableCountChance.\" ); } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } Some of you may note that that summing foreach loop is the \"Reduce\" of the \"Map / Reduce\" algorithm pair, available in effectively every code framework in the world....except .NET. Linq gives you Select and Aggregate , which are rough equivalents, albeit with a syntax that makes kittens cry. I'll stick with the readable foreach loop. You're welcome. Generating Words \u00b6 We're ready for our big debut. Let's actually build words in our new language! It's sort of anti-climactic, after all that setup: public string GenerateWordFor ( string baseLanguageWord ) { if (! dictionary . ContainsKey ( baseLanguageWord )) { int numSyll = SyllableCount (); string word = \"\" ; for ( int i = 0 ; i < numSyll ; i ++) { word += syllables [ UnityEngine . Random . Range ( 0 , syllables . Count )]; if ( usesPunctuationDelimeters && i < ( numSyll - 1 )) { float percent = UnityEngine . Random . Range ( 0f , 100f ); if ( percent < (( i == 0 ) ? leadPunctuationChance : punctuationChance )) { int choice = UnityEngine . Random . Range ( 0 , punctuations . Length ); word += punctuations [ choice ]; } } } dictionary [ baseLanguageWord ] = word ; } return dictionary [ baseLanguageWord ]; } We start by making sure we haven't already seen this word. If we have, it's in our dictionary (literary sense, although it's also a Dictionary in the software sense), and we just return the previous translation. Otherwise, it's fairly straightforward. Pick a number of syllables, add one at random, and slap a little punctuation on there, if our language and random numbers agree. (Note that we never put punctuation after the last syllable, which is just a stylistic choice.) Generating Longer Text \u00b6 So now we've got all the pieces we need to do longer text: we just divide it into words, pass each word through GenerateWordFor() and concatenate them all back together. But that quick algorithm belies some complicated decisions. Specifically, what's a word? public string GenerateTextFor ( string baseLanguageText ) { string [] words = baseLanguageText . Split ( ' ' ); string outString = \"\" ; foreach ( string word in words ) { outString += GenerateWordFor ( word ) + \" \" ; } // Get rid of that last space. outString = outString . TrimEnd (); return outString ; } That's our baseline case. Maybe it's good enough for some uses, but it's pretty primitive. We're just treating every run of characters that's not a space as a word. \"Don't\" is a word. But so is \"Hello.\", including the period. Or \"funny-looking\". From a quick test run: \"Hello, my fine countryman.\" in language: aklon is \"ni dap foeza vo\" Just at a first glance, we've lost the comma, the period at the end, and the capitalization of the first letter. \"Hello,\" \"Hello\" \"hello\" \"hello.\" would all be treated as different words. If our \"sources\" language is something like Chinese, that doesn't tend to use spaces between words, it's even less useful. We'll gloss over that last point, except to note that we may need to make different versions of GenerateTextFor() for some different (real) input languages. But for our \"generic Roman language\" case: We'd like words to be translated case-insensitively (\"hello\" and \"HELLO\") as the same word. We'd like to maintain first--character--case. If a word is capitalized in the source text, it should be capitalized in the translation, too. But we'll live with words in all-caps or other partial-capitalization patterns being considered as all-lower-case. But even in this case, \"Hello\" and \"hello\" should translated to the same word (say, \"Blah\" and \"blah\"). Many people don't differentiate between hyphens and dashes when writing, so it's probably safest to just treat hyphens as word breaks, unless we know that our text uses them only as hyphens. This will result in hyphenated words remaining hyphenated after translation, which is weird, but not as weird as having things like dashes disappear. We probably want to treat a single-quote as part of a word (don't, doesn't, can't, o'clock). But most other punctuation should be considered a separator, and put back into the string after translation in the same locations. So string.Split(' ') isn't going to do it any more. What will? If you're implementing in a language other than C#/.NET, you may want to just stop reading now and go off on your own. Many modern languages/frameworks have fairly sophisticated parsing capabilities, and you might be able to get some of this stuff for free. But we'll go with a simpler algorithm. We'll keep a list of punctuation we consider part of a word (just single quotes for now, although you could add hyphen if you're confident in your source texts), and letters. We'll run through the text character by character: If it's \"part of a word\", we'll just append it to the \"current\" word we're making. If not, we'll translate the \"current word\" (if any), put the translation in the output string, clear the \"current word,\" and then just echo the character we found to the output string, too. That's not too bad to implement in any language. First, a utility routine: public string TranslationForWordWithCase ( string baseLanguageWord ) { if ( baseLanguageWord . Length == 0 ) { return baseLanguageWord ; } string outWord = GenerateWordFor ( baseLanguageWord . ToLower ()); // If the first character is uppercase, but the second one isn't, convert // the first character of the output word to upper case. if ( char . IsUpper ( baseLanguageWord , 0 ) && !( baseLanguageWord . Length > 1 && char . IsUpper ( baseLanguageWord , 1 ))) { outWord = char . ToUpper ( outWord [ 0 ]) + outWord . Substring ( 1 ); } return outWord ; } This just handles our capitalization rules. A word whose first character is capitalized will produce a translation whose first character is capitalized. But something like \"HELLO\" will be treated as all lower case. As usual, you can fiddle with the code if you want different rules. With that, we can write our long text handler. public string GenerateTextFor ( string baseLanguageText ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } The use of char.IsLetter() means that numbers/digits are considered punctuation. If you don't want that, you can either use IsLetterOrDigit() or just write out your numbers rather than using digits. Partial translations \u00b6 The \"translation\" mechanism in No Man's Sky works by printing out the synthetic text, but with \"known\" words replaced by their real language equivalent: \"Blah blahh, bblah cucumber bbllaahh mauve,\" or suchlike. There are two mechanism for \"knowing\" a word. The player can actually learn them by various means (\"knowledge stones\" on planet surfaces, speaking with aliens, alien monuments, etc.). Those are permanently learned and will always translate once known. The second mechanism are \"machine translators,\" which translate a small number of \"additional\" words on a translation-by-translation basis. These words are translated for the current interaction, but become unknown again afterward. I don't like the exact implementation of that second mechanism\u2014and in fact I'm not sure if my game will even have anything like it\u2014but the idea is sound. So I'm going to modify it slightly; I'm thinking something like a \"linguistics\" skill that gives the player a small chance of \"guessing\" unknown words based on \"context.\" The last routine we're going to generate here is one that generates synthetic language texts with the base language filled in for known words. This will take four arguments: The base language text to translate. An array of \"known\" words in the base language A percent chance to \"guess\" each other word A boolean indicating whether to surround translated words with brackets. That last gives us the option for something like \"Blah blahh, bblah [cucumber] bbllaahh [mauve],\" which makes the \"known words\" more obvious. (It'll use hard brackets for known words and angle-brackets for guessed ones.) This function is going to be very similar to GenerateTextFor . In fact, it's going to be so similar, that we probably don't want to write a separate function for it at all, but rather just pass in some optional arguments to GenerateTextFor . public string GenerateTextFor ( string baseLanguageText , List < string > knownWords = null , float percentGuess = 0f , bool useBracketsForKnown = true ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { if ( knownWords != null && knownWords . Contains ( currentWord . ToLower ())) { if ( useBracketsForKnown ) outString += $\"[{currentWord}]\" ; else outString += currentWord ; } else if ( UnityEngine . Random . Range ( 0f , 100f ) < percentGuess ) { if ( useBracketsForKnown ) outString += $\"<{currentWord}>\" ; else outString += currentWord ; } else { outString += TranslationForWordWithCase ( currentWord ); } currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } There's a little repetition in there that we could factor out, but it's not bad. Testing \u00b6 So, does it work? I come from the mobile development world, where unit testing is relatively rare. And I'm not a fan of unit testing for most things in the first place\u2014in my experience, test-driven development in general never pays for itself in higher quality; just higher effort. A lot of man hours are spent trying to make things unit-testable that would be better spent making them self-diagnostic. Programming cultures that attempt to institutionalize full-automated-testing for code invariably produce thousands of tests that never fail\u2014typically because they're of the \"Does 2 plus 2 still equal 4 today?\" variety (or worse, tests that _do_fail intermittently, with \"automatic re-running\" turned on for as many times as necessary for it to pass), but that never seems to map to higher quality, fewer bugs, or easier integrations. It does check a box on a report, though. Me? I'll take a skilled human tester, any day. Unlike my experiences with automated tests, human QA's have identified that \"weird quirk\" for me more times than I can count. All of that having been said, if a system is: Stateless , in the sense that it doesn't require the system to be in a given state before it will work. (For example, in many apps, most functions don't work unless the user is \"logged in,\" and the output of those functions will vary based on what the user has done recently and in what order.) Predictable , in the sense that the outputs of the system are either non-random or the randomness can be seeded for repeatability, Independent , in the sense that it does not depend on fallible external capabilities like networking, and Measurable , in a broad sense Then unit testing can provide both a sort of automated \"checklist\" for the developer, and a place for other developers to look for examples of the system being called. Our language generation fails the \"predictable\" condition, since it generates both the language construction and the \"guessing\" substitutions randomly. But maybe we can work around that. Non-Random Properties \u00b6 We want our system to have these properties: Given the same input string, a Language object should produce the same output string on every call. Different Language objects should produce different outputs for the same output string. Language objects should produce different outputs for different input strings. If we pass in a \"known\" array that contains a word in the input string, the output string should contain that word verbatim. And if we've got \"useBracketsForKnown\" on, that would should have [brackets] around it. All of the above assume a \"percentGuess\" of 0. If we pass \"percentGuess\" of 100, the output string should contain all the words of the input string: if \"useBracketsForKnown\" is on, every word not in the known list should have around it. If \"useBracketsForKnown\" is off (false), the input string should be exactly the same as the output string. All those can be tested independently of randomness. Setting up Unity's unit testing (a variant of NUnit) is a topic for another time. But assuming you've built one, we can build a test easy enough: // A Test behaves as an ordinary method [Test] public void LanguageSimplePasses () { // Use the Assert class to test conditions string firstTest = \"Hello, my fine countryman!\" ; string secondTest = \"Hello, you awful countryman.\" ; List < string > known = new List < string >(); known . Add ( \"countryman\" ); known . Add ( \"you\" ); Language foreignSpeak = new Language ( Language . LanguageBias . SOFT , Language . LanguageComplexity . SIMPLE ); Debug . Log ( foreignSpeak . GenerateTextFor ( firstTest )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest )); Assert . AreEqual ( foreignSpeak . GenerateTextFor ( firstTest ), foreignSpeak . GenerateTextFor ( firstTest )); Assert . AreNotEqual ( foreignSpeak . GenerateTextFor ( firstTest ), foreignSpeak . GenerateTextFor ( secondTest )); Debug . Log ( foreignSpeak . GenerateTextFor ( firstTest , known , 0 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 0 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , false )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( firstTest , known , 0 , true ). Contains ( \"[countryman]\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 0 , true ). Contains ( \"[you]\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , true ). Contains ( \"<awful>\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , false ). Contains ( secondTest )); } The \"Debug.Log()\" lines there are to make the Unity Test Runner window echo results, so that we can see our languages in process. The test passes, as we can see in the lower part of the Test Runner window. LanguageSimplePasses (0.017s) --- Im, ad nel-yw oswo! Im, va ceth oswo. Im, ad nel-yw [countryman]! Im, [you] ceth [countryman]. <Hello>, [you] <awful> [countryman]. Hello, you awful countryman. Non-Predictable Properties \u00b6 How about the rest? Languages with different settings should \"look different.\" A few languages should have some punctuation in words. Guess amounts 0 < x < 100 should produce roughly a corresponding percent of words. Two different input strings with words in common should results in the same \"translation\" for those words. Leading capitals and punctuation except for single-quotes should be in the same relative places in the output string as it was in the input string. The first three points are going to depend on our random number generator. The last two don't, but they're both something that's trivial for a human to check, but relatively annoying to write code for. We could make the random stuff non-random by using UnityEngine.Random.seed=42 or some other fixed number before doing them. But we're not going to, because doing so creates a subtle dependency: we'll only get the same outputs\u2014even with the same seed\u2014if the number and order of calls to the random number generator don't change. Any tests we build based on the results of a single seed are going to be fragile: Any change (successful or not, valid or not, minor or not) to how the algorithms use Random will make all our tests fail. And then someone's going to have to spend a day figuring out WHY the tests failed, even if the code is still working perfectly. That sort of nonsense is why I'm not a Unit Test believer. But we still need the ability to verify that the code is working as intended, and honestly, we'd be better to rely on human judgement for that. So we'll just add a bunch of output to the end of the existing test, which will produce a \"Manual Evaluation Output\" section that we can just look over: // This isn't checked as part of the test, it just generates more output Debug . Log ( \"----\" ); Debug . Log ( \"Manual Evaluation Output\" ); foreignSpeak = new Language ( Language . LanguageBias . SOFT , Language . LanguageComplexity . SIMPLE ); Debug . Log ( \"Simple, Soft Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"Pass 2: \\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); Debug . Log ( $\"Pass 2: \\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); foreignSpeak = new Language ( Language . LanguageBias . HARD , Language . LanguageComplexity . COMPLEX ); Debug . Log ( \"Hard, Complex Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); foreignSpeak = new Language ( Language . LanguageBias . MIDDLE , Language . LanguageComplexity . MEDIUM ); Debug . Log ( \"Medium, Medium Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); for ( int i = 0 ; i < 20 ; i ++) { foreignSpeak = new Language (); Debug . Log ( \"Random Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); } Some sample output: LanguageSimplePasses (0.036s) --- Ud, evud ussaln nolav! Ud, omien ull nolav. Ud, evud ussaln [countryman]! Ud, [you] ull [countryman]. <Hello>, [you] <awful> [countryman]. Hello, you awful countryman. ---- Manual Evaluation Output Simple, Soft Language \"Hello, my fine countryman!\" in language: Osieh is \"Woyn, ew uw in!\" Pass 2: \"Hello, my fine countryman!\" in language: Osieh is \"Woyn, ew uw in!\" \"Hello, you awful countryman.\" in language: Osieh is \"Woyn, fiean alal in.\" Pass 2: \"Hello, you awful countryman.\" in language: Osieh is \"Woyn, fiean alal in.\" Hard, Complex Language \"Hello, my fine countryman!\" in language: Es is \"Phapi, qui ustabota thuixhagthu!\" \"Hello, you awful countryman.\" in language: Es is \"Phapi, lanet etyvxi thuixhagthu.\" Medium, Medium Language \"Hello, my fine countryman!\" in language: Uph is \"Dar, heiph elong ungyth!\" \"Hello, you awful countryman.\" in language: Uph is \"Dar, asith harhat ungyth.\" Random Language \"Hello, my fine countryman!\" in language: Bihalsse is \"Ubdakfieni, ni phalanthoephaph phalennu!\" \"Hello, you awful countryman.\" in language: Bihalsse is \"Ubdakfieni, bimy myhapkhu phalennu.\" Random Language \"Hello, my fine countryman!\" in language: Ullfaoballes is \"Seoth, zo phi faob!\" \"Hello, you awful countryman.\" in language: Ullfaoballes is \"Seoth, eln foeongiswo faob.\" Random Language \"Hello, my fine countryman!\" in language: Cathfi is \"Ieh, harbe has thi!\" \"Hello, you awful countryman.\" in language: Cathfi is \"Ieh, en dakubthe thi.\" Random Language \"Hello, my fine countryman!\" in language: Kyessiss is \"Tyizz, quo teoxuk onso!\" \"Hello, you awful countryman.\" in language: Kyessiss is \"Tyizz, asax zuosquoosot onso.\" Random Language \"Hello, my fine countryman!\" in language: Athimthoha is \"Olleb, lues elell issse!\" \"Hello, you awful countryman.\" in language: Athimthoha is \"Olleb, en panul issse.\" Random Language \"Hello, my fine countryman!\" in language: Eweih is \"Syiehmidathing, ylnoln phiewill ylnnelan!\" \"Hello, you awful countryman.\" in language: Eweih is \"Syiehmidathing, lynnil kithuvme ylnnelan.\" Random Language \"Hello, my fine countryman!\" in language: Me is \"Ellboba, yss ssadathssuoss bithuthuong!\" \"Hello, you awful countryman.\" in language: Me is \"Ellboba, ulfietu cethollkha bithuthuong.\" Random Language \"Hello, my fine countryman!\" in language: Thuunloavkith is \"Thissiien, ssaki lonul ingoss!\" \"Hello, you awful countryman.\" in language: Thuunloavkith is \"Thissiien, khoki sy ingoss.\" Random Language \"Hello, my fine countryman!\" in language: Uphtuxa is \"Kha, edosatazzcuth de q!\" \"Hello, you awful countryman.\" in language: Uphtuxa is \"Kha, ot sayk q.\" Random Language \"Hello, my fine countryman!\" in language: Ezzuw is \"Tocath, fa ba hah!\" \"Hello, you awful countryman.\" in language: Ezzuw is \"Tocath, ethma kithdaphak hah.\" Random Language \"Hello, my fine countryman!\" in language: Ud is \"Zuzu, phithe nohath okit!\" \"Hello, you awful countryman.\" in language: Ud is \"Zuzu, ixpaque us okit.\" Random Language \"Hello, my fine countryman!\" in language: Di is \"Bo, oskyizz zoizz osxafaik!\" \"Hello, you awful countryman.\" in language: Di is \"Bo, awhahozz doezz osxafaik.\" Random Language \"Hello, my fine countryman!\" in language: Iph is \"Queediss, ykulnqui ingphize q!\" \"Hello, you awful countryman.\" in language: Iph is \"Queediss, depu piadabhan q.\" Random Language \"Hello, my fine countryman!\" in language: Quaaddah is \"Ke, xatenel qu fiphe!\" \"Hello, you awful countryman.\" in language: Quaaddah is \"Ke, etoxkho nel fiphe.\" Random Language \"Hello, my fine countryman!\" in language: Bedagix is \"Sysu, vikhodar lanfephu khiathothse!\" \"Hello, you awful countryman.\" in language: Bedagix is \"Sysu, khu fa khiathothse.\" Random Language \"Hello, my fine countryman!\" in language: Ethssyha is \"Eindathbe, dahse ssithyle ssiwuwa!\" \"Hello, you awful countryman.\" in language: Ethssyha is \"Eindathbe, issceth uth ssiwuwa.\" Random Language \"Hello, my fine countryman!\" in language: Quiud is \"Ux*ssizuusdi, athath*kho qua*ythzi be!\" \"Hello, you awful countryman.\" in language: Quiud is \"Ux*ssizuusdi, se-ukit ti*xu be.\" Random Language \"Hello, my fine countryman!\" in language: Phaus is \"Feekhase, thinol ky haiehobhagieh!\" \"Hello, you awful countryman.\" in language: Phaus is \"Feekhase, kha wypho haiehobhagieh.\" Random Language \"Hello, my fine countryman!\" in language: Hap is \"Kha, lineldatdar akomwaphi sussawy!\" \"Hello, you awful countryman.\" in language: Hap is \"Kha, pho essaln sussawy.\" Random Language \"Hello, my fine countryman!\" in language: Quut is \"Ssoaxqu, zait quike tias!\" \"Hello, you awful countryman.\" in language: Quut is \"Ssoaxqu, kathoqu izz tias.\" That looks good to me. The Code \u00b6 Here's the code, all in one place: using System ; using System.Collections ; using System.Collections.Generic ; using UnityEngine ; using Newtonsoft.Json ; // Implementation of a written language. // // This uses a No Man's Sky-like linguistic system. Languages // all have the same grammar, word order, etc. as the player's chosen // language, but different actual words. // // Messages in game are parsed for words, and each word given a substitute // in the \"foreign\" language. This dictionary is maintained and extended // as new messages are added, and sorted by the frequency of the real-world // words seen so far. // // Players can, through various means, \"learn\" words of a language; when displayed, // those words will be shown in their chosen language (and displayed differently) // rather than the synthetic one. Certain spells and effects may also // allow the player to read the synthetic language directly. // // For the moment, we'll ignore homographs (words that are spelled alike, but are // actually different words, the \"lead\" in \"pencil lead\" vs. \"lead the troops.\") // The synthetic word that matches \"lead\" will be used for both. Given the // large numbers of other ridiculous assumptions being made here (words are 1:1 substitutes?), // I doubt players will care about that one, much. /// <summary> /// This is a mechanismg for making multiple synthetic languages that are visually /// distinct. It basically selects subsets from one of several \"syllable sets\", /// as well as probabilities for short vs. long words, frequency of repeated /// syllables, and punctuation delimiters. It will then use those elements to /// create an infinite number of words, on demand. /// /// ??? Someday might be nice to have \"alphabetic-like\" glyph sets, too, like Ultima's rune /// languages. /// </summary> [Serializable] [JsonObject(MemberSerialization.OptIn)] public class Language { // These are the actual syllables that make up the language. Something like // 20 is probably enough for most purposes (remember that the entire vocabulary // necessary will only have to cover the in-game strings that occur, so a few thousand // words will cover it. [JsonProperty] public List < string > syllables ; // These should add up to 100. They are the chances that a given word will // be 1, 2, 3, 4... syllables, respectively. So {10, 80, 10} would mean that // most words in the language are 2 syllables, but 10% are 1 syllable, and 10% are 3. // If the language is very regular: (all words are the same number of syllables, or // there are only a couple of possibilities), you'll want more syllables in the list // above to cover the vocabulary. [JsonProperty] public int [] percentSyllableCountChance ; // If true, the language uses punctuation to separate syllables within a word, // e.g. O'clock, brick-a-brack. // if true, \"punctuations\" holds the list of available characters, and // \"punctuationChance\" is the percent chance that any two syllables will // have a punctuation mark between them, and \"leadPunctuationChance\" is the // percent chance (which could be higher or lower than punctuationChance) that // there will be a punctuation mark specifically after the first syllable. // (Real, Fantasy, and Science fiction \"languages\" seem to emphasize that form a lot. Q'pla! T'Challa, O'Callahan). [JsonProperty] public bool usesPunctuationDelimeters ; [JsonProperty] public string []? punctuations ; [JsonProperty] public float? punctuationChance ; [JsonProperty] public float? leadPunctuationChance ; // The actual \"dictionary\" of associations between English (or whatever) and // the synthetic language. [JsonProperty] public Dictionary < string , string > dictionary ; // The actual name of the language, in it's own language. [JsonProperty] public string languageName ; private readonly static List < string > softSyllables = new List < string >() { \"la\" , \"le\" , \"lu\" , \"li\" , \"lo\" , \"ly\" , \"na\" , \"ne\" , \"nu\" , \"ni\" , \"no\" , \"ny\" , \"ha\" , \"he\" , \"hu\" , \"hi\" , \"ho\" , \"hy\" , \"ma\" , \"me\" , \"mu\" , \"mi\" , \"mo\" , \"my\" , \"al\" , \"el\" , \"ul\" , \"il\" , \"ol\" , \"yl\" , \"an\" , \"em\" , \"um\" , \"im\" , \"om\" , \"ym\" , \"an\" , \"en\" , \"un\" , \"in\" , \"on\" , \"yn\" , \"lan\" , \"len\" , \"lun\" , \"lin\" , \"lon\" , \"lyn\" , \"nal\" , \"nel\" , \"nul\" , \"nil\" , \"nol\" , \"nyl\" , \"all\" , \"ell\" , \"ull\" , \"ill\" , \"oll\" , \"yll\" , \"aln\" , \"eln\" , \"uln\" , \"iln\" , \"oln\" , \"yln\" , \"eil\" , \"ein\" , \"eim\" , \"eih\" , \"iel\" , \"ien\" , \"iem\" , \"ieh\" , \"av\" , \"ev\" , \"uv\" , \"iv\" , \"ov\" , \"yv\" , \"va\" , \"ve\" , \"vu\" , \"vi\" , \"vo\" , \"vy\" , \"aw\" , \"ew\" , \"uw\" , \"iw\" , \"ow\" , \"yw\" , \"wa\" , \"we\" , \"wu\" , \"wi\" , \"wo\" , \"wy\" , }; private readonly static List < string > middleSyllables = new List < string >() { \"ang\" , \"eng\" , \"ing\" , \"ung\" , \"ong\" , \"fa\" , \"fe\" , \"fi\" , \"fo\" , \"fu\" , \"fae\" , \"fie\" , \"fee\" , \"foe\" , \"fum\" , \"dan\" , \"dat\" , \"dak\" , \"dah\" , \"dal\" , \"dath\" , \"dap\" , \"dag\" , \"dar\" , \"das\" , \"han\" , \"hat\" , \"hak\" , \"hah\" , \"hal\" , \"hath\" , \"hap\" , \"hag\" , \"har\" , \"has\" , \"kha\" , \"khe\" , \"khi\" , \"kho\" , \"khu\" , \"khy\" , \"tha\" , \"the\" , \"thi\" , \"tho\" , \"thu\" , \"thy\" , \"ath\" , \"eth\" , \"ith\" , \"oth\" , \"uth\" , \"yth\" , \"sa\" , \"ssa\" , \"se\" , \"sse\" , \"si\" , \"ssi\" , \"so\" , \"sso\" , \"su\" , \"ssu\" , \"sy\" , \"ssy\" , \"as\" , \"ass\" , \"es\" , \"ess\" , \"is\" , \"iss\" , \"os\" , \"oss\" , \"us\" , \"uss\" , \"ys\" , \"yss\" , \"ba\" , \"be\" , \"bi\" , \"bo\" , \"bu\" , \"ab\" , \"eb\" , \"ib\" , \"ob\" , \"ub\" , \"pha\" , \"phe\" , \"phi\" , \"pho\" , \"phu\" , \"aph\" , \"eph\" , \"iph\" , \"oph\" , \"uph\" , \"cath\" , \"ceth\" , \"kith\" , \"coth\" , \"cuth\" , \"cyth\" , }; private readonly static List < string > hardSyllables = new List < string >() { \"ka\" , \"ke\" , \"ku\" , \"ki\" , \"ko\" , \"ky\" , \"sa\" , \"se\" , \"su\" , \"si\" , \"so\" , \"sy\" , \"ta\" , \"te\" , \"tu\" , \"ti\" , \"to\" , \"ty\" , \"pa\" , \"pe\" , \"pu\" , \"pi\" , \"po\" , \"py\" , \"ak\" , \"ek\" , \"uk\" , \"ik\" , \"ok\" , \"yk\" , \"at\" , \"et\" , \"ut\" , \"it\" , \"ot\" , \"yt\" , \"as\" , \"es\" , \"us\" , \"is\" , \"os\" , \"ys\" , \"xa\" , \"xe\" , \"xi\" , \"xu\" , \"xo\" , \"ax\" , \"ex\" , \"ix\" , \"ux\" , \"ox\" , \"da\" , \"de\" , \"di\" , \"du\" , \"do\" , \"ad\" , \"ed\" , \"id\" , \"ud\" , \"od\" , \"q\" , \"qua\" , \"que\" , \"qui\" , \"quo\" , \"qu\" , \"za\" , \"ze\" , \"zi\" , \"zo\" , \"zu\" , \"azz\" , \"ezz\" , \"izz\" , \"ozz\" , \"uzz\" }; // Determines whether the language picks mostly from // the \"soft,\" \"middle,\" or \"hard\" syllables // RANDOM chooses one of these values with equal probability. public enum LanguageBias { RANDOM , SOFT , MIDDLE , HARD , } // Determines the number of syllables used for words (simple = fewer), // and the number of total syllables in the language (simple = fewer here, too). // RANDOM generates a random value. public enum LanguageComplexity { RANDOM , SIMPLE , MEDIUM , COMPLEX , } public static List < string > ChooseSyllables ( LanguageBias bias , int number ) { int syllablesAvailable = softSyllables . Count + middleSyllables . Count + hardSyllables . Count ; Debug . Assert ( syllablesAvailable > number * 1.5f , $\"ASSERT: We're looking for {number} syllables out of {syllablesAvailable}, which will likely take a long time.\" ); List < string > chosen = new List < string >(); List < string > favorite , secondBest , thirdBest ; // Order our lists by how much we like them. switch ( bias ) { case LanguageBias . SOFT : favorite = softSyllables ; secondBest = middleSyllables ; thirdBest = hardSyllables ; break ; case LanguageBias . HARD : favorite = hardSyllables ; secondBest = middleSyllables ; thirdBest = softSyllables ; break ; case LanguageBias . MIDDLE : default : favorite = middleSyllables ; secondBest = softSyllables ; thirdBest = hardSyllables ; break ; } while ( chosen . Count < number ) { int percentileRoll = UnityEngine . Random . Range ( 0 , 100 ); string syllable ; if ( percentileRoll < 70 ) { syllable = favorite [ UnityEngine . Random . Range ( 0 , favorite . Count )]; } else if ( percentileRoll < 95 ) { syllable = secondBest [ UnityEngine . Random . Range ( 0 , secondBest . Count )]; } else { syllable = thirdBest [ UnityEngine . Random . Range ( 0 , thirdBest . Count )]; } if (! chosen . Contains ( syllable )) chosen . Add ( syllable ); } return chosen ; } /// <summary> /// Constructor to generate one of these. /// </summary> public Language ( LanguageBias bias = LanguageBias . RANDOM , LanguageComplexity complexity = LanguageComplexity . RANDOM ) { // Choose a bias emphasis. LanguageBias useBias = bias ; if ( bias == LanguageBias . RANDOM ) { switch ( UnityEngine . Random . Range ( 0 , 3 )) { case 0 : useBias = LanguageBias . SOFT ; break ; case 1 : useBias = LanguageBias . MIDDLE ; break ; default : useBias = LanguageBias . HARD ; break ; } } // And a number of syllables (a crude measure of language complexity). int numSyllables = UnityEngine . Random . Range ( 40 , 120 ); percentSyllableCountChance = new int [] { 25 , 30 , 30 , 10 , 5 }; switch ( complexity ) { case LanguageComplexity . SIMPLE : numSyllables = UnityEngine . Random . Range ( 40 , 60 ); percentSyllableCountChance = new int [] { 50 , 40 , 10 }; break ; case LanguageComplexity . MEDIUM : numSyllables = UnityEngine . Random . Range ( 70 , 105 ); percentSyllableCountChance = new int [] { 45 , 35 , 20 }; break ; case LanguageComplexity . COMPLEX : percentSyllableCountChance = new int [] { 15 , 35 , 25 , 20 , 5 }; numSyllables = 120 ; break ; default : break ; // Already covered } syllables = ChooseSyllables ( useBias , numSyllables ); // We'll use a fixed 15% chance that our language uses punctuation delimiters usesPunctuationDelimeters = UnityEngine . Random . Range ( 0 , 100 ) < 15 ; if ( usesPunctuationDelimeters ) { // Set these to small, fixed values for now. We can be more // selective later, if we need more variation. punctuations = new string [] { \"-\" , \"'\" , \"*\" }; punctuationChance = 10f ; leadPunctuationChance = 35f ; } dictionary = new Dictionary < string , string >(); languageName = \"\" ; GenerateLanguageName (); } /// <summary> /// Generates the language's actual name /// </summary> private void GenerateLanguageName () { // The \"__\" on the end will guarantee uniqueness, since all other // input sources are filtered for punctuation. languageName = TranslationForWordWithCase ( \"LanguageName__\" ); } /// <summary> /// Picks the number of syllables for a word (randomly) /// </summary> /// <returns></returns> private int SyllableCount () { if ( percentSyllableCountChance . Length == 0 ) { return 2 ; } int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; Debug . Assert ( chance > 0 , \"ASSERT: Zero or negative probability in percentSyllableCountChance.\" ); } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } /// <summary> /// Generates a word for the \"baseLanguageWord\" if it's not already present, /// then adds it to the dictionary and returns it. /// </summary> /// <param name=\"baseLanguageWord\"></param> /// <returns></returns> public string GenerateWordFor ( string baseLanguageWord ) { if (! dictionary . ContainsKey ( baseLanguageWord )) { int numSyll = SyllableCount (); string word = \"\" ; for ( int i = 0 ; i < numSyll ; i ++) { word += syllables [ UnityEngine . Random . Range ( 0 , syllables . Count )]; if ( usesPunctuationDelimeters && i < ( numSyll - 1 )) { float percent = UnityEngine . Random . Range ( 0f , 100f ); if ( percent < (( i == 0 ) ? leadPunctuationChance : punctuationChance )) { int choice = UnityEngine . Random . Range ( 0 , punctuations . Length ); word += punctuations [ choice ]; } } } dictionary [ baseLanguageWord ] = word ; } return dictionary [ baseLanguageWord ]; } public string TranslationForWordWithCase ( string baseLanguageWord ) { if ( baseLanguageWord . Length == 0 ) { return baseLanguageWord ; } string outWord = GenerateWordFor ( baseLanguageWord . ToLower ()); // If the first character is uppercase, but the second one isn't, convert // the first character of the output word to upper case. if ( char . IsUpper ( baseLanguageWord , 0 ) && !( baseLanguageWord . Length > 1 && char . IsUpper ( baseLanguageWord , 1 ))) { outWord = char . ToUpper ( outWord [ 0 ]) + outWord . Substring ( 1 ); } return outWord ; } /// <summary> /// Parses the passed string into words (using spaces as delimeters), /// then calls GenerateWordFor on each one, concatenates the results, /// and returns the text. /// </summary> /// <param name=\"baseLanguageText\"></param> /// <returns></returns> public string GenerateTextFor ( string baseLanguageText , List < string > knownWords = null , float percentGuess = 0f , bool useBracketsForKnown = true ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { if ( knownWords != null && knownWords . Contains ( currentWord . ToLower ())) { if ( useBracketsForKnown ) outString += $\"[{currentWord}]\" ; else outString += currentWord ; } else if ( UnityEngine . Random . Range ( 0f , 100f ) < percentGuess ) { if ( useBracketsForKnown ) outString += $\"<{currentWord}>\" ; else outString += currentWord ; } else { outString += TranslationForWordWithCase ( currentWord ); } currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } }","title":"Procedural Language Generation"},{"location":"blog/procedural-language/#procedural-language-generation-for-a-fantasy-game","text":"No Man's Sky has an interesting\u2014if not particularly realistic\u2014language mechanism. Each of its three main races, plus the Atlas, have their own language. The player learns these languages (if they wish), one word at a time, and when presented with text in the \"alien\" language, known words are substituted with the player's chosen game language (which I'll assume to be English for convenience, here, although the game ships with several real-world languages available). This makes finding and learning new words a background game objective, and adds more things for the player \"to do\" that produce meaningful rewards, which is always a challenge for procedural games, where things like quests, monsters, and locations are almost literally cookie-cutter. NMS makes several simplifying assumptions: A \"word\" in the alien language corresponds to exactly one \"word\" in English. Even more unrealistically: word order, grammar, and punctuation of the alien languages correspond exactly to English, as well. Effectively all alien languages are substitution ciphers, where you take an English sentence, substitute an alien word for each English one, and produce the result. Things like homographs (words that are the same spelling but different pronunciation and/or meaning, like pencil \"lead\" vs. \"lead\" troops) are homographs in all the languages, as well. All the languages are written using the same character set. As anyone who's ever learned another language can tell you, none of these are particularly realistic; some are laughably silly. But the simplifications actually make the language interactions more puzzle-like, since you've got more information available to you than just the set of words that you know.","title":"Procedural Language Generation for a Fantasy Game"},{"location":"blog/procedural-language/#what-are-we-trying-to-build","text":"For a game I'm writing, I'm looking for a similar mechanism. Like NMS, this game is extremely--almost pathologically-procedural, at least to the limits of what a single developer can produce in a reasonable time. (I've resorted to asset store monsters, for example). One planned element here is procedural pasts. At world creation time, the last few thousand years of \"history\" are procedurally generated. Each empire's ebb and flow are recorded, so that at any given time we can say things like \"this particular area was held by the \\'Empire of Bob\\' 2000 years ago, so if you have ruins/dungeons/castles from that time, they're probably Bobian.\" This stuff then feeds into the quest, lore, and location generators. Similarly, the state of the generator at the \"present time\" determines political boundaries. So I want each of these empires, kingdoms, etc.\u2014both past and present\u2014to have languages associated with them. Often it'll be one-to-one: an empire speaks a specific language. But it need not be: sometimes there will be multiple \"competing\" languages within and empire (especially if it just took over lands that used to be owned by another), and often a language will be shared across empires (especially if friendly, or parts of the same historical empire.). In the real world, languages are sometimes separated by political boundaries, but far more often by either geography, culture, or history. In a nutshell, though, we don't know how many languages we're going to need, it can be arbitrarily many, or few, depending on what the generator produces. And we'd like an additional requirement: these languages shouldn't be just random strings of pronounceable characters. They should be visually distinct from each other. Players should be able to distinguish languages from each other by appearance, at least most of the time. So we want a system to generate arbitrarily many distinct languages, each of which can be \"learned\" piecemeal in the No Man's Sky style.","title":"What are we trying to build?"},{"location":"blog/procedural-language/#what-makes-up-a-language","text":"The dictionary tells us that a \"language\" is...well, it doesn't actually matter, because don't actually want a language. We want something that looks and works just enough like a natural language to be a game substitute for one\u2014similar to how we abstract \"injury\" into \"hit points\" or the uneven task of learning skills into \"skill trees\" of one sort or another. Tolkien was a master of creating languages (he used real languages as a base). Even ignoring the writing system glyphs, you could tell them apart: elvish was full of L and N and vowel sounds, the dwarves used lots of K, H, D, and U. Men (by which he mean \"all humans\"\u2014 The Hobbit was published in 1937) tended toward old-English-y names with lots of E's and O's. Star Trek's Klingon , meant to be the harsh tongue of a warrior race, leans heavily into hard consonants: Q, K, and P, and loves glottal stops (the hard break between consonant sounds that don't blend into each other): \"Q'pla\" and the like; a sort of \"coughing\" language that would probably be impractical in real life. Maybe the closest approximation being something like the San language or German. But if we just make tables of letter frequencies and put them together, we tend to get unpronounceable messes: \"BHGLUM\", \"UEILNL\", and the like. That might actually work for Klingon, but in general, it's not going to give us what we want. We could try to construct rules like \"consonants and vowels need to alternate\", which will produce always-pronounceable strings, but with more regularity than we'd like.","title":"What makes up a language?"},{"location":"blog/procedural-language/#syllables-to-the-rescue","text":"Luckily, we've got a better construct to build from: the syllable. Syllables are pronounceable sub-components of a word; effectively they're the \"units\" from which words are build. Typically, each one represents a vowel sound and some optional surrounding consonants. What really sets the sounds of languages apart is their choice of syllables. English is a weird outlier: because of \"borrowing\" from every language under the sun, it has something like 16,000 unique syllables in its lexicon. Mandarin Chinese, on the other hand, has a mere 400 or so, although these are multiplied by four or five different \"pronunciation frequencies\" or \"tones,\" to give about 1700 real ones. Even Mandarin is far more than we need. Depending on who you ask, what you mean by \"word\" (are names included? Are plurals/tenses separate words?), and the specific language you're asking about, most people use about 10,000 different words in daily speech, and languages run somewhere between 80,000 and 150,000 total words. But we don't care about the total words, much. It would be a rare game whose text included all of \"verdant,\" \"riboflavin,\" and \"calligraphic.\" We just need our language to be capable of covering any reasonable set of words that we are actually going to use . I've seen estimates that a mere 1000 words is enough to read a newspaper, even if we double or triple that (say, a game like Skyrim with hundreds of \"books\" in it to read), we're still not talking any significant fraction of a real language's scope. So let's say we choose a target of 5,000 unique constructible \"words\" in our language. How many syllables do we need? If words are one syllable each, we need 5000 of them. But if words are just two syllables, suddenly we need only about 70 of them \\((\\sqrt{5000})\\) . At three syllables, it's ( \\(\\sqrt[3]{5000}\\) ), a mere 18 syllables. Since most languages support words of varying length (in fact, average word length in syllables is one of the distinguishing characteristics of languages), or we allow homographs, we could get by with even fewer.","title":"Syllables to the rescue"},{"location":"blog/procedural-language/#not-all-syllables-are-equal","text":"So far, we've got two \"knobs\" we can adjust in order to create our languages: Number of syllables per word The number of available syllables. Next, we should consider the syllables themselves. This is where we give a language it's character. Consider, for example, a \"soft\" language (like Tolkien's Elvish) where we emphasize lilting or rolling consonants (like L, H, M, N) and vowel sounds: private readonly static List < string > softSyllables = new List < string >() { \"la\" , \"le\" , \"lu\" , \"li\" , \"lo\" , \"ly\" , \"na\" , \"ne\" , \"nu\" , \"ni\" , \"no\" , \"ny\" , \"ha\" , \"he\" , \"hu\" , \"hi\" , \"ho\" , \"hy\" , \"ma\" , \"me\" , \"mu\" , \"mi\" , \"mo\" , \"my\" , \"al\" , \"el\" , \"ul\" , \"il\" , \"ol\" , \"yl\" , \"an\" , \"em\" , \"um\" , \"im\" , \"om\" , \"ym\" , \"an\" , \"en\" , \"un\" , \"in\" , \"on\" , \"yn\" , }; This is C#, because the implementation is going to be in Unity, but the language doesn't matter much. That's 35 syllables right there, and even using just that, we can get pleasant-sounding nonsense like \"\"noulmima na om olloully\" or \"emmuno lo nyhymu ynny.\" The regularity of the 2-character syllables produces a sort of artificial-looking regularity to the generated text, but we can work with that. A different set of syllables, heavy on sibilants (S, soft C) and hard consonants (K, P, T): private readonly static List < string > hardSyllables = new List < string >() { \"ka\" , \"ke\" , \"ku\" , \"ki\" , \"ko\" , \"ky\" , \"sa\" , \"se\" , \"su\" , \"si\" , \"so\" , \"sy\" , \"ta\" , \"te\" , \"tu\" , \"ti\" , \"to\" , \"ty\" , \"pa\" , \"pe\" , \"pu\" , \"pi\" , \"po\" , \"py\" , \"ak\" , \"ek\" , \"uk\" , \"ik\" , \"ok\" , \"yk\" , \"at\" , \"et\" , \"ut\" , \"it\" , \"ot\" , \"yt\" , \"as\" , \"es\" , \"us\" , \"is\" , \"os\" , \"ys\" , }; This gives us phrases like: \"eskiakit ystuet ikas ytteak\" and \"taok ok ik ikpa.\" Again, there's too much repetitiveness and pattern here, but again, that's because our syllables set is somewhat uniform and limited. These are sort of the \"extremes\" of a syllabic spectrum. If we define several sets, ranging from lilting to harsh, we then have a third knob for our languages: what sets of syllables are available to it. Something like English or German might distribute pretty easily across the whole spectrum. Spanish-like languages would tend toward the softer end, something like Russian (or Klingon) toward the harder end. (Fantasy languages will likely go further out on the spectrum than natural languages will, because natural languages tend to evolve toward more easily-spoken forms over time.) So if we provide a way to generate a distribution (so many syllables from group A, so many from group B, etc.), we can use it to generate languages of different \"character.\" There are hundreds, maybe thousands, of potential syllables using roman/English alphabets, spellings, and pronounciation rules. It's not necessary to provide an exhaustive list -- a few dozen at most should be enough to generate a rich set of languages. (I've provided my lists in the code at the end of this article)","title":"Not all Syllables are equal"},{"location":"blog/procedural-language/#a-mse-once-bit-my-sister","text":"Since we're generating for a written form, and not too concerned about pronunciation, we can also use diacritical marks (those little accents, diaereses, umlauts, grave accents, circumflexes, macrons, tildes, etc.) more or less as decorations rather than to fulfill their usual functions of altering pronunciation, aspiration, or emphasis. By building syllable sets that include diacritical forms, we can then choose (or randomly assign) languages to use them or not. There are some caveats to doing this. The first is that we're likely to generate things that range from nonsensical to outright offensive to speakers of the languages whose marks we're borrowing (e.g. there's no such thing as an \"e-umlaut\" in German, but Unicode lets us generate one easily enough: \"\u00eb\".) If the system you're using is not Unicode-savvy, the risks become much higher. A generation of computer users grew up with \"smart quotes\" from a Mac rendering as gibberish on a PC\u2014and vice versa\u2014even if you were using Microsoft Word on both; you still see these weird characters show up on the web occasionally. And the encoding set of your language or OS may be the least of your problems: any new glyph you use has to be present in whatever font you're using; which is a sort of hit-or-miss proposition when you're using characters \"borrowed\" from languages other than the ones the font is meant for. We've all seen the \"square\" character rendered in place of some missing glyph (or lots of them) from a font. Still, if you're confident in your encoding and font, diacriticals can add another visual distinction to a language, especially if you use different selections of them for different languages. We could go even further down this rabbit hole and generate whole new glyphs (like Ultima 's rune writing) for our systems, but that just makes the font problem even worse. You see this a lot in science fiction movies: \"alien\" alphabets that are full of dots and symmetric geometric forms.","title":"A M\u00f8\u00f8se Once Bit My Sister"},{"location":"blog/procedural-language/#ok-now-do-we-put-this-together","text":"We want to provide our developer with at least the following capabilities: Generate new synthetic languages Provide a string in \"real\" language and have that translated into the equivalent synthetic language string. For convenience, we probably want to do this at the word level as well as at being able to provide a longer string of text. Provide a string in \"real\" language, along with a \"dictionary\" (in the literary, not programming, sense) of words that the player \"knows\", and have it translated into the equivalent synthetic language string with the \"known\" words indicated in the real language. Note that translations are always real -> synthetic, not the other way around. The app will deal in \"real\" strings, and convert them to synthetic (or part-synthetic) when presenting them to the users.","title":"OK, Now do we put this together?"},{"location":"blog/procedural-language/#generating-the-language-patterns","text":"Our first step is to be able to choose values for all those \"knobs\" we discussed earlier: syllable count ranges, which syllable sets to use, how many syllables to use from each set, whether we use punctuation (and if so, which punctuation) as syllable-separators, and the like. We'd like to spare our caller needing to pick values for all those knobs, and ideally allow them to set none at all\u2014if they wish\u2014for a completely random one. So we'll define a couple of \"categories\" here that categorize the language more simply: // Determines whether the language picks mostly from // the \"soft,\" \"middle,\" or \"hard\" syllables // RANDOM chooses one of these values with equal probability. public enum LanguageBias { RANDOM , SOFT , MIDDLE , HARD , } // Determines the number of syllables used for words (simple = fewer), // and the number of total syllables in the language (simple = fewer here, too). // RANDOM generates a random value. public enum LanguageComplexity { RANDOM , SIMPLE , MEDIUM , COMPLEX , } In both cases, we have a .RANDOM value that we can use if the developer doesn't want to think about it. We can then define a bunch of properties for our language: public class Language { // These are the actual syllables that make up the language. Something like // 20 is probably enough for most purposes (remember that the entire vocabulary // necessary will only have to cover the in-game strings that occur, so a few thousand // words will cover it. [JsonProperty] public List < string > syllables ; // These should add up to 100. They are the chances that a given word will // be 1, 2, 3, 4... syllables, respectively. So {10, 80, 10} would mean that // most words in the language are 2 syllables, but 10% are 1 syllable, and 10% are 3. // If the language is very regular: (all words are the same number of syllables, or // there are only a couple of possibilities), you'll want more syllables in the list // above to cover the vocabulary. [JsonProperty] public int [] percentSyllableCountChance ; // If true, the language uses punctuation to separate syllables within a word, // e.g. O'clock, brick-a-brack. // if true, \"punctuations\" holds the list of available characters, and // \"punctuationChance\" is the percent chance that any two syllables will // have a punctuation mark between them, and \"leadPunctuationChance\" is the // percent chance (which could be higher or lower than punctuationChance) that // there will be a punctuation mark specifically after the first syllable. // (Real, Fantasy, and Science fiction \"languages\" seem to emphasize that form a lot. // Q'pla! T'Challa, O'Callahan). [JsonProperty] public bool usesPunctuationDelimeters ; [JsonProperty] public string []? punctuations ; [JsonProperty] public float? punctuationChance ; [JsonProperty] public float? leadPunctuationChance ; // The actual \"dictionary\" of associations between English (or whatever) and // the synthetic language. [JsonProperty] public Dictionary < string , string > dictionary ; // The actual name of the language, in it's own language. [JsonProperty] public string languageName ; Note that I'm using some C# nullables here, for the potentially-unnecessary punctuation dictionary. Unity's Mono support doesn't allow nullables in older versions; so if your compiler complains, just get rid of the \"?\" characters in the definition of punctuations , punctuationChance , and leadPunctuationChance. Let's write a constructor: public Language ( LanguageBias bias = LanguageBias . RANDOM , LanguageComplexity complexity = LanguageComplexity . RANDOM ) { The developer who wants a particular harshness and complexity can choose it, but called without arguments, we'll just choose at random. For harshness bias, that's pretty easy: // Choose a bias emphasis. LanguageBias useBias = bias ; if ( bias == LanguageBias . RANDOM ) { switch ( UnityEngine . Random . Range ( 0 , 3 )) { case 0 : useBias = LanguageBias . SOFT ; break ; case 1 : useBias = LanguageBias . MIDDLE ; break ; default : useBias = LanguageBias . HARD ; break ; } } This makes the odds even for each possibility, but you can fiddle with the values, if you like. Side Note: As you're about to notice, I'm using a lot of \"magic numbers\"\u2014rather than constants. This is an \"author trick\" to make numbers appear near their usage in context. This is great for authoring blog articles, but sucks for maintenance, where you'd like to have them all in an easily-found block. Once you're done fiddling and have dialed in values you like, you may want to consider changing them to proper constants. \"Complexity\" is a little tougher, we're using it as a proxy for both the total number of syllables in the lexicon and the average number of syllables per word. // And a number of syllables (a crude measure of language complexity). int numSyllables = UnityEngine . Random . Range ( 40 , 120 ); percentSyllableCountChance = new int [] { 25 , 30 , 30 , 10 , 5 }; switch ( complexity ) { case LanguageComplexity . SIMPLE : numSyllables = UnityEngine . Random . Range ( 40 , 60 ); percentSyllableCountChance = new int [] { 50 , 40 , 10 }; break ; case LanguageComplexity . MEDIUM : numSyllables = UnityEngine . Random . Range ( 70 , 105 ); percentSyllableCountChance = new int [] { 45 , 35 , 20 }; break ; case LanguageComplexity . COMPLEX : percentSyllableCountChance = new int [] { 15 , 35 , 25 , 20 , 5 }; numSyllables = 120 ; break ; default : break ; // Already covered } syllables = ChooseSyllables ( useBias , numSyllables ); Again, these are numbers that worked pretty well for me; you can change any of these numbers to match your own needs. The main constraint here is the number of syllables available in the sets. Mine are relatively small; if you have a lot of potential syllables, the numSyllables value can go higher and you can bias more toward shorter words. Real world languages tend to settle in around 1-3 syllables for most common words, since it literally makes speaking easier. We're not considering word rarity here (in English, at least, significantly multisyllabic words tend to be used less, e.g. \"significantly multisyllabic\" vs. \"long\"). We'll come back to ChooseSyllables ; it just picks a random set of syllables for the language, biased by useBias . I want to use punctuation to add a little flavor to my languages, but I don't want to use it very often, or very much of it, to prevent the languages looking like caricatures. So I'm fixing some values here. It would make sense to have some rules (e.g. \"harsh languages have more punctuation\"), but I didn't bother for my needs. // We'll use a fixed 15% chance that our language uses punctuation delimiters usesPunctuationDelimeters = UnityEngine . Random . Range ( 0 , 100 ) < 15 ; if ( usesPunctuationDelimeters ) { // Set these to small, fixed values for now. We can be more // selective later, if we need more variation. punctuations = new string [] { \"-\" , \"'\" , \"*\" }; punctuationChance = 10f ; leadPunctuationChance = 35f ; } Again, if your compiler complains about C# nullables (or you just don't want to use them), get rid of the \"if\" and always set those values, even though they won't be used. Note that the two \"...Chance\" variables are floats, not integers, to allow greater fine-tuning (like English, where hyphenated words are well under 1% of the language). Finally, we just initialize the dictionary Dictionary (sigh...) that will hold our translations as we make them, and then generate a name for our language (in itself, of course). dictionary = new Dictionary < string , string >(); languageName = \"\" ; GenerateLanguageName (); }","title":"Generating the Language Patterns"},{"location":"blog/procedural-language/#utilities","text":"Let's write a couple utility functions. We've seen one already, ChooseSyllables() , which selects the syllable set that will be part of our language. public static List < string > ChooseSyllables ( LanguageBias bias , int number ) { List < string > chosen = new List < string >(); List < string > favorite , secondBest , thirdBest ; // Order our lists by how much we like them. switch ( bias ) { case LanguageBias . SOFT : favorite = softSyllables ; secondBest = middleSyllables ; thirdBest = hardSyllables ; break ; case LanguageBias . HARD : favorite = hardSyllables ; secondBest = middleSyllables ; thirdBest = softSyllables ; break ; case LanguageBias . MIDDLE : default : favorite = middleSyllables ; secondBest = softSyllables ; thirdBest = hardSyllables ; break ; } while ( chosen . Count < number ) { int percentileRoll = UnityEngine . Random . Range ( 0 , 100 ); string syllable ; if ( percentileRoll < 70 ) { syllable = favorite [ UnityEngine . Random . Range ( 0 , favorite . Count )]; } else if ( percentileRoll < 95 ) { syllable = secondBest [ UnityEngine . Random . Range ( 0 , secondBest . Count )]; } else { syllable = thirdBest [ UnityEngine . Random . Range ( 0 , thirdBest . Count )]; } if (! chosen . Contains ( syllable )) chosen . Add ( syllable ); } return chosen ; } This isn't going to win any efficiency awards. That while loop does an awful lot of List.Contains() calls (which, since our list is unsorted, is O(n) each time), and after all that effort will throw away the syllable it just picked if it happens to already be in the list. The actual performance hit here is inversely proportional to the difference between the total number of syllables available in our lists and the number we're looking for. If we've got lots more syllables available than we need, it's not bad. As the \"excess\" becomes smaller, the odds of a collision get higher, and we end up discarding more syllables. If the excess becomes very small, this could take a very long time to \"find\" those last few free syllables. If the excess is negative (we're asking for more unique syllables than exist), this will loop forever, and you'll get a crash course (well, a \"hang course\") in how to recover from a hang. (Hint -- kill the Unity Editor by whatever the standard means is on your platform). So, let's add a check at the beginning: int syllablesAvailable = softSyllables . Count + middleSyllables . Count + hardSyllables . Count ; Debug . Assert ( syllablesAvailable > number * 1.5f , $\"ASSERT: We're looking for {number} syllables out of {syllablesAvailable}, which will likely take a long time.\" ); This will check (in debug builds) that we've got at least 150% of the number of syllables that we're asking for. That doesn't actually fix the problem, but it should make us aware of it. An easier case is SyllableCount() , which just used that percentSyllableCountChance array to choose the a number of syllables according to the provided probability distribution: private int SyllableCount () { int num = UnityEngine . Random . Range ( 0 , 100 ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } Once again, the Software Engineer in me is squinting unpleasantly at this. The problem is that \"100.\" If we have no bugs, and our \"percent chances\" are actually percents (i.e. add up to 100), then this works fine. But if we happen to give it an array that sums to more than 100, then the higher values will never get picked. And if we give it an array that sums to less than 100, this will crash if the random generator picks a number greater than our maximum! So are you feeling lucky? I'm not. Let's fix it. private int SyllableCount () { int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } That works better\u2014although it the chance array were empty, or if it held negative values, we could get weird effects. We should return a reasonable default in the first case, and assert on the latter: private int SyllableCount () { if ( percentSyllableCountChance . Length == 0 ) { return 2 ; } int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; Debug . Assert ( chance > 0 , \"ASSERT: Zero or negative probability in percentSyllableCountChance.\" ); } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } Some of you may note that that summing foreach loop is the \"Reduce\" of the \"Map / Reduce\" algorithm pair, available in effectively every code framework in the world....except .NET. Linq gives you Select and Aggregate , which are rough equivalents, albeit with a syntax that makes kittens cry. I'll stick with the readable foreach loop. You're welcome.","title":"Utilities"},{"location":"blog/procedural-language/#generating-words","text":"We're ready for our big debut. Let's actually build words in our new language! It's sort of anti-climactic, after all that setup: public string GenerateWordFor ( string baseLanguageWord ) { if (! dictionary . ContainsKey ( baseLanguageWord )) { int numSyll = SyllableCount (); string word = \"\" ; for ( int i = 0 ; i < numSyll ; i ++) { word += syllables [ UnityEngine . Random . Range ( 0 , syllables . Count )]; if ( usesPunctuationDelimeters && i < ( numSyll - 1 )) { float percent = UnityEngine . Random . Range ( 0f , 100f ); if ( percent < (( i == 0 ) ? leadPunctuationChance : punctuationChance )) { int choice = UnityEngine . Random . Range ( 0 , punctuations . Length ); word += punctuations [ choice ]; } } } dictionary [ baseLanguageWord ] = word ; } return dictionary [ baseLanguageWord ]; } We start by making sure we haven't already seen this word. If we have, it's in our dictionary (literary sense, although it's also a Dictionary in the software sense), and we just return the previous translation. Otherwise, it's fairly straightforward. Pick a number of syllables, add one at random, and slap a little punctuation on there, if our language and random numbers agree. (Note that we never put punctuation after the last syllable, which is just a stylistic choice.)","title":"Generating Words"},{"location":"blog/procedural-language/#generating-longer-text","text":"So now we've got all the pieces we need to do longer text: we just divide it into words, pass each word through GenerateWordFor() and concatenate them all back together. But that quick algorithm belies some complicated decisions. Specifically, what's a word? public string GenerateTextFor ( string baseLanguageText ) { string [] words = baseLanguageText . Split ( ' ' ); string outString = \"\" ; foreach ( string word in words ) { outString += GenerateWordFor ( word ) + \" \" ; } // Get rid of that last space. outString = outString . TrimEnd (); return outString ; } That's our baseline case. Maybe it's good enough for some uses, but it's pretty primitive. We're just treating every run of characters that's not a space as a word. \"Don't\" is a word. But so is \"Hello.\", including the period. Or \"funny-looking\". From a quick test run: \"Hello, my fine countryman.\" in language: aklon is \"ni dap foeza vo\" Just at a first glance, we've lost the comma, the period at the end, and the capitalization of the first letter. \"Hello,\" \"Hello\" \"hello\" \"hello.\" would all be treated as different words. If our \"sources\" language is something like Chinese, that doesn't tend to use spaces between words, it's even less useful. We'll gloss over that last point, except to note that we may need to make different versions of GenerateTextFor() for some different (real) input languages. But for our \"generic Roman language\" case: We'd like words to be translated case-insensitively (\"hello\" and \"HELLO\") as the same word. We'd like to maintain first--character--case. If a word is capitalized in the source text, it should be capitalized in the translation, too. But we'll live with words in all-caps or other partial-capitalization patterns being considered as all-lower-case. But even in this case, \"Hello\" and \"hello\" should translated to the same word (say, \"Blah\" and \"blah\"). Many people don't differentiate between hyphens and dashes when writing, so it's probably safest to just treat hyphens as word breaks, unless we know that our text uses them only as hyphens. This will result in hyphenated words remaining hyphenated after translation, which is weird, but not as weird as having things like dashes disappear. We probably want to treat a single-quote as part of a word (don't, doesn't, can't, o'clock). But most other punctuation should be considered a separator, and put back into the string after translation in the same locations. So string.Split(' ') isn't going to do it any more. What will? If you're implementing in a language other than C#/.NET, you may want to just stop reading now and go off on your own. Many modern languages/frameworks have fairly sophisticated parsing capabilities, and you might be able to get some of this stuff for free. But we'll go with a simpler algorithm. We'll keep a list of punctuation we consider part of a word (just single quotes for now, although you could add hyphen if you're confident in your source texts), and letters. We'll run through the text character by character: If it's \"part of a word\", we'll just append it to the \"current\" word we're making. If not, we'll translate the \"current word\" (if any), put the translation in the output string, clear the \"current word,\" and then just echo the character we found to the output string, too. That's not too bad to implement in any language. First, a utility routine: public string TranslationForWordWithCase ( string baseLanguageWord ) { if ( baseLanguageWord . Length == 0 ) { return baseLanguageWord ; } string outWord = GenerateWordFor ( baseLanguageWord . ToLower ()); // If the first character is uppercase, but the second one isn't, convert // the first character of the output word to upper case. if ( char . IsUpper ( baseLanguageWord , 0 ) && !( baseLanguageWord . Length > 1 && char . IsUpper ( baseLanguageWord , 1 ))) { outWord = char . ToUpper ( outWord [ 0 ]) + outWord . Substring ( 1 ); } return outWord ; } This just handles our capitalization rules. A word whose first character is capitalized will produce a translation whose first character is capitalized. But something like \"HELLO\" will be treated as all lower case. As usual, you can fiddle with the code if you want different rules. With that, we can write our long text handler. public string GenerateTextFor ( string baseLanguageText ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } The use of char.IsLetter() means that numbers/digits are considered punctuation. If you don't want that, you can either use IsLetterOrDigit() or just write out your numbers rather than using digits.","title":"Generating Longer Text"},{"location":"blog/procedural-language/#partial-translations","text":"The \"translation\" mechanism in No Man's Sky works by printing out the synthetic text, but with \"known\" words replaced by their real language equivalent: \"Blah blahh, bblah cucumber bbllaahh mauve,\" or suchlike. There are two mechanism for \"knowing\" a word. The player can actually learn them by various means (\"knowledge stones\" on planet surfaces, speaking with aliens, alien monuments, etc.). Those are permanently learned and will always translate once known. The second mechanism are \"machine translators,\" which translate a small number of \"additional\" words on a translation-by-translation basis. These words are translated for the current interaction, but become unknown again afterward. I don't like the exact implementation of that second mechanism\u2014and in fact I'm not sure if my game will even have anything like it\u2014but the idea is sound. So I'm going to modify it slightly; I'm thinking something like a \"linguistics\" skill that gives the player a small chance of \"guessing\" unknown words based on \"context.\" The last routine we're going to generate here is one that generates synthetic language texts with the base language filled in for known words. This will take four arguments: The base language text to translate. An array of \"known\" words in the base language A percent chance to \"guess\" each other word A boolean indicating whether to surround translated words with brackets. That last gives us the option for something like \"Blah blahh, bblah [cucumber] bbllaahh [mauve],\" which makes the \"known words\" more obvious. (It'll use hard brackets for known words and angle-brackets for guessed ones.) This function is going to be very similar to GenerateTextFor . In fact, it's going to be so similar, that we probably don't want to write a separate function for it at all, but rather just pass in some optional arguments to GenerateTextFor . public string GenerateTextFor ( string baseLanguageText , List < string > knownWords = null , float percentGuess = 0f , bool useBracketsForKnown = true ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { if ( knownWords != null && knownWords . Contains ( currentWord . ToLower ())) { if ( useBracketsForKnown ) outString += $\"[{currentWord}]\" ; else outString += currentWord ; } else if ( UnityEngine . Random . Range ( 0f , 100f ) < percentGuess ) { if ( useBracketsForKnown ) outString += $\"<{currentWord}>\" ; else outString += currentWord ; } else { outString += TranslationForWordWithCase ( currentWord ); } currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } There's a little repetition in there that we could factor out, but it's not bad.","title":"Partial translations"},{"location":"blog/procedural-language/#testing","text":"So, does it work? I come from the mobile development world, where unit testing is relatively rare. And I'm not a fan of unit testing for most things in the first place\u2014in my experience, test-driven development in general never pays for itself in higher quality; just higher effort. A lot of man hours are spent trying to make things unit-testable that would be better spent making them self-diagnostic. Programming cultures that attempt to institutionalize full-automated-testing for code invariably produce thousands of tests that never fail\u2014typically because they're of the \"Does 2 plus 2 still equal 4 today?\" variety (or worse, tests that _do_fail intermittently, with \"automatic re-running\" turned on for as many times as necessary for it to pass), but that never seems to map to higher quality, fewer bugs, or easier integrations. It does check a box on a report, though. Me? I'll take a skilled human tester, any day. Unlike my experiences with automated tests, human QA's have identified that \"weird quirk\" for me more times than I can count. All of that having been said, if a system is: Stateless , in the sense that it doesn't require the system to be in a given state before it will work. (For example, in many apps, most functions don't work unless the user is \"logged in,\" and the output of those functions will vary based on what the user has done recently and in what order.) Predictable , in the sense that the outputs of the system are either non-random or the randomness can be seeded for repeatability, Independent , in the sense that it does not depend on fallible external capabilities like networking, and Measurable , in a broad sense Then unit testing can provide both a sort of automated \"checklist\" for the developer, and a place for other developers to look for examples of the system being called. Our language generation fails the \"predictable\" condition, since it generates both the language construction and the \"guessing\" substitutions randomly. But maybe we can work around that.","title":"Testing"},{"location":"blog/procedural-language/#non-random-properties","text":"We want our system to have these properties: Given the same input string, a Language object should produce the same output string on every call. Different Language objects should produce different outputs for the same output string. Language objects should produce different outputs for different input strings. If we pass in a \"known\" array that contains a word in the input string, the output string should contain that word verbatim. And if we've got \"useBracketsForKnown\" on, that would should have [brackets] around it. All of the above assume a \"percentGuess\" of 0. If we pass \"percentGuess\" of 100, the output string should contain all the words of the input string: if \"useBracketsForKnown\" is on, every word not in the known list should have around it. If \"useBracketsForKnown\" is off (false), the input string should be exactly the same as the output string. All those can be tested independently of randomness. Setting up Unity's unit testing (a variant of NUnit) is a topic for another time. But assuming you've built one, we can build a test easy enough: // A Test behaves as an ordinary method [Test] public void LanguageSimplePasses () { // Use the Assert class to test conditions string firstTest = \"Hello, my fine countryman!\" ; string secondTest = \"Hello, you awful countryman.\" ; List < string > known = new List < string >(); known . Add ( \"countryman\" ); known . Add ( \"you\" ); Language foreignSpeak = new Language ( Language . LanguageBias . SOFT , Language . LanguageComplexity . SIMPLE ); Debug . Log ( foreignSpeak . GenerateTextFor ( firstTest )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest )); Assert . AreEqual ( foreignSpeak . GenerateTextFor ( firstTest ), foreignSpeak . GenerateTextFor ( firstTest )); Assert . AreNotEqual ( foreignSpeak . GenerateTextFor ( firstTest ), foreignSpeak . GenerateTextFor ( secondTest )); Debug . Log ( foreignSpeak . GenerateTextFor ( firstTest , known , 0 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 0 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , true )); Debug . Log ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , false )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( firstTest , known , 0 , true ). Contains ( \"[countryman]\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 0 , true ). Contains ( \"[you]\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , true ). Contains ( \"<awful>\" )); Assert . IsTrue ( foreignSpeak . GenerateTextFor ( secondTest , known , 100 , false ). Contains ( secondTest )); } The \"Debug.Log()\" lines there are to make the Unity Test Runner window echo results, so that we can see our languages in process. The test passes, as we can see in the lower part of the Test Runner window. LanguageSimplePasses (0.017s) --- Im, ad nel-yw oswo! Im, va ceth oswo. Im, ad nel-yw [countryman]! Im, [you] ceth [countryman]. <Hello>, [you] <awful> [countryman]. Hello, you awful countryman.","title":"Non-Random Properties"},{"location":"blog/procedural-language/#non-predictable-properties","text":"How about the rest? Languages with different settings should \"look different.\" A few languages should have some punctuation in words. Guess amounts 0 < x < 100 should produce roughly a corresponding percent of words. Two different input strings with words in common should results in the same \"translation\" for those words. Leading capitals and punctuation except for single-quotes should be in the same relative places in the output string as it was in the input string. The first three points are going to depend on our random number generator. The last two don't, but they're both something that's trivial for a human to check, but relatively annoying to write code for. We could make the random stuff non-random by using UnityEngine.Random.seed=42 or some other fixed number before doing them. But we're not going to, because doing so creates a subtle dependency: we'll only get the same outputs\u2014even with the same seed\u2014if the number and order of calls to the random number generator don't change. Any tests we build based on the results of a single seed are going to be fragile: Any change (successful or not, valid or not, minor or not) to how the algorithms use Random will make all our tests fail. And then someone's going to have to spend a day figuring out WHY the tests failed, even if the code is still working perfectly. That sort of nonsense is why I'm not a Unit Test believer. But we still need the ability to verify that the code is working as intended, and honestly, we'd be better to rely on human judgement for that. So we'll just add a bunch of output to the end of the existing test, which will produce a \"Manual Evaluation Output\" section that we can just look over: // This isn't checked as part of the test, it just generates more output Debug . Log ( \"----\" ); Debug . Log ( \"Manual Evaluation Output\" ); foreignSpeak = new Language ( Language . LanguageBias . SOFT , Language . LanguageComplexity . SIMPLE ); Debug . Log ( \"Simple, Soft Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"Pass 2: \\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); Debug . Log ( $\"Pass 2: \\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); foreignSpeak = new Language ( Language . LanguageBias . HARD , Language . LanguageComplexity . COMPLEX ); Debug . Log ( \"Hard, Complex Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); foreignSpeak = new Language ( Language . LanguageBias . MIDDLE , Language . LanguageComplexity . MEDIUM ); Debug . Log ( \"Medium, Medium Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); for ( int i = 0 ; i < 20 ; i ++) { foreignSpeak = new Language (); Debug . Log ( \"Random Language\" ); Debug . Log ( $\"\\\"{firstTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(firstTest)}\\\"\" ); Debug . Log ( $\"\\\"{secondTest}\\\" in language: {foreignSpeak.languageName} is \\\"{foreignSpeak.GenerateTextFor(secondTest)}\\\"\" ); } Some sample output: LanguageSimplePasses (0.036s) --- Ud, evud ussaln nolav! Ud, omien ull nolav. Ud, evud ussaln [countryman]! Ud, [you] ull [countryman]. <Hello>, [you] <awful> [countryman]. Hello, you awful countryman. ---- Manual Evaluation Output Simple, Soft Language \"Hello, my fine countryman!\" in language: Osieh is \"Woyn, ew uw in!\" Pass 2: \"Hello, my fine countryman!\" in language: Osieh is \"Woyn, ew uw in!\" \"Hello, you awful countryman.\" in language: Osieh is \"Woyn, fiean alal in.\" Pass 2: \"Hello, you awful countryman.\" in language: Osieh is \"Woyn, fiean alal in.\" Hard, Complex Language \"Hello, my fine countryman!\" in language: Es is \"Phapi, qui ustabota thuixhagthu!\" \"Hello, you awful countryman.\" in language: Es is \"Phapi, lanet etyvxi thuixhagthu.\" Medium, Medium Language \"Hello, my fine countryman!\" in language: Uph is \"Dar, heiph elong ungyth!\" \"Hello, you awful countryman.\" in language: Uph is \"Dar, asith harhat ungyth.\" Random Language \"Hello, my fine countryman!\" in language: Bihalsse is \"Ubdakfieni, ni phalanthoephaph phalennu!\" \"Hello, you awful countryman.\" in language: Bihalsse is \"Ubdakfieni, bimy myhapkhu phalennu.\" Random Language \"Hello, my fine countryman!\" in language: Ullfaoballes is \"Seoth, zo phi faob!\" \"Hello, you awful countryman.\" in language: Ullfaoballes is \"Seoth, eln foeongiswo faob.\" Random Language \"Hello, my fine countryman!\" in language: Cathfi is \"Ieh, harbe has thi!\" \"Hello, you awful countryman.\" in language: Cathfi is \"Ieh, en dakubthe thi.\" Random Language \"Hello, my fine countryman!\" in language: Kyessiss is \"Tyizz, quo teoxuk onso!\" \"Hello, you awful countryman.\" in language: Kyessiss is \"Tyizz, asax zuosquoosot onso.\" Random Language \"Hello, my fine countryman!\" in language: Athimthoha is \"Olleb, lues elell issse!\" \"Hello, you awful countryman.\" in language: Athimthoha is \"Olleb, en panul issse.\" Random Language \"Hello, my fine countryman!\" in language: Eweih is \"Syiehmidathing, ylnoln phiewill ylnnelan!\" \"Hello, you awful countryman.\" in language: Eweih is \"Syiehmidathing, lynnil kithuvme ylnnelan.\" Random Language \"Hello, my fine countryman!\" in language: Me is \"Ellboba, yss ssadathssuoss bithuthuong!\" \"Hello, you awful countryman.\" in language: Me is \"Ellboba, ulfietu cethollkha bithuthuong.\" Random Language \"Hello, my fine countryman!\" in language: Thuunloavkith is \"Thissiien, ssaki lonul ingoss!\" \"Hello, you awful countryman.\" in language: Thuunloavkith is \"Thissiien, khoki sy ingoss.\" Random Language \"Hello, my fine countryman!\" in language: Uphtuxa is \"Kha, edosatazzcuth de q!\" \"Hello, you awful countryman.\" in language: Uphtuxa is \"Kha, ot sayk q.\" Random Language \"Hello, my fine countryman!\" in language: Ezzuw is \"Tocath, fa ba hah!\" \"Hello, you awful countryman.\" in language: Ezzuw is \"Tocath, ethma kithdaphak hah.\" Random Language \"Hello, my fine countryman!\" in language: Ud is \"Zuzu, phithe nohath okit!\" \"Hello, you awful countryman.\" in language: Ud is \"Zuzu, ixpaque us okit.\" Random Language \"Hello, my fine countryman!\" in language: Di is \"Bo, oskyizz zoizz osxafaik!\" \"Hello, you awful countryman.\" in language: Di is \"Bo, awhahozz doezz osxafaik.\" Random Language \"Hello, my fine countryman!\" in language: Iph is \"Queediss, ykulnqui ingphize q!\" \"Hello, you awful countryman.\" in language: Iph is \"Queediss, depu piadabhan q.\" Random Language \"Hello, my fine countryman!\" in language: Quaaddah is \"Ke, xatenel qu fiphe!\" \"Hello, you awful countryman.\" in language: Quaaddah is \"Ke, etoxkho nel fiphe.\" Random Language \"Hello, my fine countryman!\" in language: Bedagix is \"Sysu, vikhodar lanfephu khiathothse!\" \"Hello, you awful countryman.\" in language: Bedagix is \"Sysu, khu fa khiathothse.\" Random Language \"Hello, my fine countryman!\" in language: Ethssyha is \"Eindathbe, dahse ssithyle ssiwuwa!\" \"Hello, you awful countryman.\" in language: Ethssyha is \"Eindathbe, issceth uth ssiwuwa.\" Random Language \"Hello, my fine countryman!\" in language: Quiud is \"Ux*ssizuusdi, athath*kho qua*ythzi be!\" \"Hello, you awful countryman.\" in language: Quiud is \"Ux*ssizuusdi, se-ukit ti*xu be.\" Random Language \"Hello, my fine countryman!\" in language: Phaus is \"Feekhase, thinol ky haiehobhagieh!\" \"Hello, you awful countryman.\" in language: Phaus is \"Feekhase, kha wypho haiehobhagieh.\" Random Language \"Hello, my fine countryman!\" in language: Hap is \"Kha, lineldatdar akomwaphi sussawy!\" \"Hello, you awful countryman.\" in language: Hap is \"Kha, pho essaln sussawy.\" Random Language \"Hello, my fine countryman!\" in language: Quut is \"Ssoaxqu, zait quike tias!\" \"Hello, you awful countryman.\" in language: Quut is \"Ssoaxqu, kathoqu izz tias.\" That looks good to me.","title":"Non-Predictable Properties"},{"location":"blog/procedural-language/#the-code","text":"Here's the code, all in one place: using System ; using System.Collections ; using System.Collections.Generic ; using UnityEngine ; using Newtonsoft.Json ; // Implementation of a written language. // // This uses a No Man's Sky-like linguistic system. Languages // all have the same grammar, word order, etc. as the player's chosen // language, but different actual words. // // Messages in game are parsed for words, and each word given a substitute // in the \"foreign\" language. This dictionary is maintained and extended // as new messages are added, and sorted by the frequency of the real-world // words seen so far. // // Players can, through various means, \"learn\" words of a language; when displayed, // those words will be shown in their chosen language (and displayed differently) // rather than the synthetic one. Certain spells and effects may also // allow the player to read the synthetic language directly. // // For the moment, we'll ignore homographs (words that are spelled alike, but are // actually different words, the \"lead\" in \"pencil lead\" vs. \"lead the troops.\") // The synthetic word that matches \"lead\" will be used for both. Given the // large numbers of other ridiculous assumptions being made here (words are 1:1 substitutes?), // I doubt players will care about that one, much. /// <summary> /// This is a mechanismg for making multiple synthetic languages that are visually /// distinct. It basically selects subsets from one of several \"syllable sets\", /// as well as probabilities for short vs. long words, frequency of repeated /// syllables, and punctuation delimiters. It will then use those elements to /// create an infinite number of words, on demand. /// /// ??? Someday might be nice to have \"alphabetic-like\" glyph sets, too, like Ultima's rune /// languages. /// </summary> [Serializable] [JsonObject(MemberSerialization.OptIn)] public class Language { // These are the actual syllables that make up the language. Something like // 20 is probably enough for most purposes (remember that the entire vocabulary // necessary will only have to cover the in-game strings that occur, so a few thousand // words will cover it. [JsonProperty] public List < string > syllables ; // These should add up to 100. They are the chances that a given word will // be 1, 2, 3, 4... syllables, respectively. So {10, 80, 10} would mean that // most words in the language are 2 syllables, but 10% are 1 syllable, and 10% are 3. // If the language is very regular: (all words are the same number of syllables, or // there are only a couple of possibilities), you'll want more syllables in the list // above to cover the vocabulary. [JsonProperty] public int [] percentSyllableCountChance ; // If true, the language uses punctuation to separate syllables within a word, // e.g. O'clock, brick-a-brack. // if true, \"punctuations\" holds the list of available characters, and // \"punctuationChance\" is the percent chance that any two syllables will // have a punctuation mark between them, and \"leadPunctuationChance\" is the // percent chance (which could be higher or lower than punctuationChance) that // there will be a punctuation mark specifically after the first syllable. // (Real, Fantasy, and Science fiction \"languages\" seem to emphasize that form a lot. Q'pla! T'Challa, O'Callahan). [JsonProperty] public bool usesPunctuationDelimeters ; [JsonProperty] public string []? punctuations ; [JsonProperty] public float? punctuationChance ; [JsonProperty] public float? leadPunctuationChance ; // The actual \"dictionary\" of associations between English (or whatever) and // the synthetic language. [JsonProperty] public Dictionary < string , string > dictionary ; // The actual name of the language, in it's own language. [JsonProperty] public string languageName ; private readonly static List < string > softSyllables = new List < string >() { \"la\" , \"le\" , \"lu\" , \"li\" , \"lo\" , \"ly\" , \"na\" , \"ne\" , \"nu\" , \"ni\" , \"no\" , \"ny\" , \"ha\" , \"he\" , \"hu\" , \"hi\" , \"ho\" , \"hy\" , \"ma\" , \"me\" , \"mu\" , \"mi\" , \"mo\" , \"my\" , \"al\" , \"el\" , \"ul\" , \"il\" , \"ol\" , \"yl\" , \"an\" , \"em\" , \"um\" , \"im\" , \"om\" , \"ym\" , \"an\" , \"en\" , \"un\" , \"in\" , \"on\" , \"yn\" , \"lan\" , \"len\" , \"lun\" , \"lin\" , \"lon\" , \"lyn\" , \"nal\" , \"nel\" , \"nul\" , \"nil\" , \"nol\" , \"nyl\" , \"all\" , \"ell\" , \"ull\" , \"ill\" , \"oll\" , \"yll\" , \"aln\" , \"eln\" , \"uln\" , \"iln\" , \"oln\" , \"yln\" , \"eil\" , \"ein\" , \"eim\" , \"eih\" , \"iel\" , \"ien\" , \"iem\" , \"ieh\" , \"av\" , \"ev\" , \"uv\" , \"iv\" , \"ov\" , \"yv\" , \"va\" , \"ve\" , \"vu\" , \"vi\" , \"vo\" , \"vy\" , \"aw\" , \"ew\" , \"uw\" , \"iw\" , \"ow\" , \"yw\" , \"wa\" , \"we\" , \"wu\" , \"wi\" , \"wo\" , \"wy\" , }; private readonly static List < string > middleSyllables = new List < string >() { \"ang\" , \"eng\" , \"ing\" , \"ung\" , \"ong\" , \"fa\" , \"fe\" , \"fi\" , \"fo\" , \"fu\" , \"fae\" , \"fie\" , \"fee\" , \"foe\" , \"fum\" , \"dan\" , \"dat\" , \"dak\" , \"dah\" , \"dal\" , \"dath\" , \"dap\" , \"dag\" , \"dar\" , \"das\" , \"han\" , \"hat\" , \"hak\" , \"hah\" , \"hal\" , \"hath\" , \"hap\" , \"hag\" , \"har\" , \"has\" , \"kha\" , \"khe\" , \"khi\" , \"kho\" , \"khu\" , \"khy\" , \"tha\" , \"the\" , \"thi\" , \"tho\" , \"thu\" , \"thy\" , \"ath\" , \"eth\" , \"ith\" , \"oth\" , \"uth\" , \"yth\" , \"sa\" , \"ssa\" , \"se\" , \"sse\" , \"si\" , \"ssi\" , \"so\" , \"sso\" , \"su\" , \"ssu\" , \"sy\" , \"ssy\" , \"as\" , \"ass\" , \"es\" , \"ess\" , \"is\" , \"iss\" , \"os\" , \"oss\" , \"us\" , \"uss\" , \"ys\" , \"yss\" , \"ba\" , \"be\" , \"bi\" , \"bo\" , \"bu\" , \"ab\" , \"eb\" , \"ib\" , \"ob\" , \"ub\" , \"pha\" , \"phe\" , \"phi\" , \"pho\" , \"phu\" , \"aph\" , \"eph\" , \"iph\" , \"oph\" , \"uph\" , \"cath\" , \"ceth\" , \"kith\" , \"coth\" , \"cuth\" , \"cyth\" , }; private readonly static List < string > hardSyllables = new List < string >() { \"ka\" , \"ke\" , \"ku\" , \"ki\" , \"ko\" , \"ky\" , \"sa\" , \"se\" , \"su\" , \"si\" , \"so\" , \"sy\" , \"ta\" , \"te\" , \"tu\" , \"ti\" , \"to\" , \"ty\" , \"pa\" , \"pe\" , \"pu\" , \"pi\" , \"po\" , \"py\" , \"ak\" , \"ek\" , \"uk\" , \"ik\" , \"ok\" , \"yk\" , \"at\" , \"et\" , \"ut\" , \"it\" , \"ot\" , \"yt\" , \"as\" , \"es\" , \"us\" , \"is\" , \"os\" , \"ys\" , \"xa\" , \"xe\" , \"xi\" , \"xu\" , \"xo\" , \"ax\" , \"ex\" , \"ix\" , \"ux\" , \"ox\" , \"da\" , \"de\" , \"di\" , \"du\" , \"do\" , \"ad\" , \"ed\" , \"id\" , \"ud\" , \"od\" , \"q\" , \"qua\" , \"que\" , \"qui\" , \"quo\" , \"qu\" , \"za\" , \"ze\" , \"zi\" , \"zo\" , \"zu\" , \"azz\" , \"ezz\" , \"izz\" , \"ozz\" , \"uzz\" }; // Determines whether the language picks mostly from // the \"soft,\" \"middle,\" or \"hard\" syllables // RANDOM chooses one of these values with equal probability. public enum LanguageBias { RANDOM , SOFT , MIDDLE , HARD , } // Determines the number of syllables used for words (simple = fewer), // and the number of total syllables in the language (simple = fewer here, too). // RANDOM generates a random value. public enum LanguageComplexity { RANDOM , SIMPLE , MEDIUM , COMPLEX , } public static List < string > ChooseSyllables ( LanguageBias bias , int number ) { int syllablesAvailable = softSyllables . Count + middleSyllables . Count + hardSyllables . Count ; Debug . Assert ( syllablesAvailable > number * 1.5f , $\"ASSERT: We're looking for {number} syllables out of {syllablesAvailable}, which will likely take a long time.\" ); List < string > chosen = new List < string >(); List < string > favorite , secondBest , thirdBest ; // Order our lists by how much we like them. switch ( bias ) { case LanguageBias . SOFT : favorite = softSyllables ; secondBest = middleSyllables ; thirdBest = hardSyllables ; break ; case LanguageBias . HARD : favorite = hardSyllables ; secondBest = middleSyllables ; thirdBest = softSyllables ; break ; case LanguageBias . MIDDLE : default : favorite = middleSyllables ; secondBest = softSyllables ; thirdBest = hardSyllables ; break ; } while ( chosen . Count < number ) { int percentileRoll = UnityEngine . Random . Range ( 0 , 100 ); string syllable ; if ( percentileRoll < 70 ) { syllable = favorite [ UnityEngine . Random . Range ( 0 , favorite . Count )]; } else if ( percentileRoll < 95 ) { syllable = secondBest [ UnityEngine . Random . Range ( 0 , secondBest . Count )]; } else { syllable = thirdBest [ UnityEngine . Random . Range ( 0 , thirdBest . Count )]; } if (! chosen . Contains ( syllable )) chosen . Add ( syllable ); } return chosen ; } /// <summary> /// Constructor to generate one of these. /// </summary> public Language ( LanguageBias bias = LanguageBias . RANDOM , LanguageComplexity complexity = LanguageComplexity . RANDOM ) { // Choose a bias emphasis. LanguageBias useBias = bias ; if ( bias == LanguageBias . RANDOM ) { switch ( UnityEngine . Random . Range ( 0 , 3 )) { case 0 : useBias = LanguageBias . SOFT ; break ; case 1 : useBias = LanguageBias . MIDDLE ; break ; default : useBias = LanguageBias . HARD ; break ; } } // And a number of syllables (a crude measure of language complexity). int numSyllables = UnityEngine . Random . Range ( 40 , 120 ); percentSyllableCountChance = new int [] { 25 , 30 , 30 , 10 , 5 }; switch ( complexity ) { case LanguageComplexity . SIMPLE : numSyllables = UnityEngine . Random . Range ( 40 , 60 ); percentSyllableCountChance = new int [] { 50 , 40 , 10 }; break ; case LanguageComplexity . MEDIUM : numSyllables = UnityEngine . Random . Range ( 70 , 105 ); percentSyllableCountChance = new int [] { 45 , 35 , 20 }; break ; case LanguageComplexity . COMPLEX : percentSyllableCountChance = new int [] { 15 , 35 , 25 , 20 , 5 }; numSyllables = 120 ; break ; default : break ; // Already covered } syllables = ChooseSyllables ( useBias , numSyllables ); // We'll use a fixed 15% chance that our language uses punctuation delimiters usesPunctuationDelimeters = UnityEngine . Random . Range ( 0 , 100 ) < 15 ; if ( usesPunctuationDelimeters ) { // Set these to small, fixed values for now. We can be more // selective later, if we need more variation. punctuations = new string [] { \"-\" , \"'\" , \"*\" }; punctuationChance = 10f ; leadPunctuationChance = 35f ; } dictionary = new Dictionary < string , string >(); languageName = \"\" ; GenerateLanguageName (); } /// <summary> /// Generates the language's actual name /// </summary> private void GenerateLanguageName () { // The \"__\" on the end will guarantee uniqueness, since all other // input sources are filtered for punctuation. languageName = TranslationForWordWithCase ( \"LanguageName__\" ); } /// <summary> /// Picks the number of syllables for a word (randomly) /// </summary> /// <returns></returns> private int SyllableCount () { if ( percentSyllableCountChance . Length == 0 ) { return 2 ; } int chanceSum = 0 ; foreach ( int chance in percentSyllableCountChance ) { chanceSum += chance ; Debug . Assert ( chance > 0 , \"ASSERT: Zero or negative probability in percentSyllableCountChance.\" ); } int num = UnityEngine . Random . Range ( 0 , chanceSum ); int outNum = 0 ; while ( num > percentSyllableCountChance [ outNum ]) { num -= percentSyllableCountChance [ outNum ]; outNum ++; } return outNum + 1 ; } /// <summary> /// Generates a word for the \"baseLanguageWord\" if it's not already present, /// then adds it to the dictionary and returns it. /// </summary> /// <param name=\"baseLanguageWord\"></param> /// <returns></returns> public string GenerateWordFor ( string baseLanguageWord ) { if (! dictionary . ContainsKey ( baseLanguageWord )) { int numSyll = SyllableCount (); string word = \"\" ; for ( int i = 0 ; i < numSyll ; i ++) { word += syllables [ UnityEngine . Random . Range ( 0 , syllables . Count )]; if ( usesPunctuationDelimeters && i < ( numSyll - 1 )) { float percent = UnityEngine . Random . Range ( 0f , 100f ); if ( percent < (( i == 0 ) ? leadPunctuationChance : punctuationChance )) { int choice = UnityEngine . Random . Range ( 0 , punctuations . Length ); word += punctuations [ choice ]; } } } dictionary [ baseLanguageWord ] = word ; } return dictionary [ baseLanguageWord ]; } public string TranslationForWordWithCase ( string baseLanguageWord ) { if ( baseLanguageWord . Length == 0 ) { return baseLanguageWord ; } string outWord = GenerateWordFor ( baseLanguageWord . ToLower ()); // If the first character is uppercase, but the second one isn't, convert // the first character of the output word to upper case. if ( char . IsUpper ( baseLanguageWord , 0 ) && !( baseLanguageWord . Length > 1 && char . IsUpper ( baseLanguageWord , 1 ))) { outWord = char . ToUpper ( outWord [ 0 ]) + outWord . Substring ( 1 ); } return outWord ; } /// <summary> /// Parses the passed string into words (using spaces as delimeters), /// then calls GenerateWordFor on each one, concatenates the results, /// and returns the text. /// </summary> /// <param name=\"baseLanguageText\"></param> /// <returns></returns> public string GenerateTextFor ( string baseLanguageText , List < string > knownWords = null , float percentGuess = 0f , bool useBracketsForKnown = true ) { string currentWord = \"\" ; string outString = \"\" ; foreach ( char c in baseLanguageText ) { if ( char . IsLetter ( c ) || c == '\\'' ) { currentWord += c ; } else { if ( currentWord . Length > 0 ) { if ( knownWords != null && knownWords . Contains ( currentWord . ToLower ())) { if ( useBracketsForKnown ) outString += $\"[{currentWord}]\" ; else outString += currentWord ; } else if ( UnityEngine . Random . Range ( 0f , 100f ) < percentGuess ) { if ( useBracketsForKnown ) outString += $\"<{currentWord}>\" ; else outString += currentWord ; } else { outString += TranslationForWordWithCase ( currentWord ); } currentWord = \"\" ; } outString += c ; } } // Repeat this check, just in case we didn't end with punctuation. if ( currentWord . Length > 0 ) { outString += TranslationForWordWithCase ( currentWord ); currentWord = \"\" ; } return outString ; } }","title":"The Code"},{"location":"blog/runtime_navmesh/","tags":["Unity","procedural generation","technology","games"],"text":"#Unity #procedural generation #technology #games .md-typeset .blogging-tags-grid { display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; margin-top: 5px; } .md-typeset .blogging-tag { color: var(--md-typeset-color); background-color: var(--md-typeset-code-color); } .md-typeset .blogging-tag code { border-radius: 5px; } Asynchronous Runtime Navmesh Generation in Unity \u00b6 Buckle in, boys and girls. This one's going to be a ride. I've recently started trying to add monsters to the world I'm creating over in my Unity Procedural Terrain system. I'd like to use the NavMesh system for enemy AI, but since my terrains aren't created in the Unity Editor, but rather randomly at runtime, I need to be able to create the NavMeshes for my monsters at runtime. And thus began the rabbit hole. It became quickly obvious that it could be done, but equally obvious that there wasn't really a good known solution out there, particularly one that was performant enough to use in a runtime environment where terrains were being created and destroyed at a reasonably fast cadence as the player moves around a large open world. As every Unity developer knows, the Unity documentation is sort of like the Evil Stepmother of fairy tales: keeping up an appearance of caring about you while secretly undermining any chance you've got for success, and possibly actually poisoning you. [Author's Note] If anyone at Unity is reading this, please consider hiring me to come in and try and clean up some of that documentation, particularly the scripting side. Some simple rules and standards could make it infinitely more useful for actual developers. So I've dug into this, and it turns out that it's not actually as horrifying as it initially seems, although there's a few caveats. Let's see if we can clear it up a bit. Background \u00b6 Unity provides a built-in AI Navigation system for 3D games. This allows 3D entities to figure out where they can \"walk,\" and provides automatic pathing, obstacle avoidance, patrol points, target tracking, and the like. It's not going to pass the Turing test any time soon, but for many games it provides a moderately sophisticated level of \"enemy\" AI for relatively little effort. The two major components of this system are the NavMesh and the NavMeshAgent . NavMesh \u00b6 NavMesh is a property of the Scene . You can think of it as a sort of invisible carpet that covers the scene in places where an entity of a given size can walk. That is, it'll be all over the floor except right next to walls or under doors and arches that the entity is too large to pass through, or on slopes too steep for that entity to walk up. You can visualize a NavMesh in a scene by: Opening the Navigation Inspector (Window->AI->Navigation). You need to have the inspector active in order to see NavMeshes . Go to the Scene View Turn on Gizmos (either all of them, or the specific ones for Navigation AI). Move your viewpoint close enough to the mesh (navmeshes clip out after a few dozen units). If you've done all that\u2014and there's a NavMesh created for the Scene at all\u2014you should see a sort of blue layer across your walkable areas. Note that the NavMesh is pretty smart: it doesn't allow you to \"walk\" on the cliff faces or steeper areas, and avoids the larger rocks (though not the trees in this case). The image above actually shows two overlapping NavMeshes : one for fairly large entities (giants and such), and one for human-sized ones. You can see the difference particularly along the straight cliff edge, where smaller entities can approach much closer than large ones. Note that the NavMesh indicates where the center of the entity can travel, which is why it doesn't go right to the edges. (That screen shot is from a significant distance from the player in the center.) The NavMesh typically is built for \"walkable\" areas, although you have a great deal of flexibility in its creation. For example, you can mark certain areas as \"walkable, but harder,\" like mud, sand, or shallow water. The AI system will assign these areas higher cost, allowing the navigating to be \"smart\" about whether to walk through such an area or go around. It's also possible to add meshes with different \"up\" orientations, such as for spiders that can walk on walls or ceilings (linking them with \"off mesh links\"). You can't see it here because the distances are too large, but the NavMesh will also intelligently create \"jump\" points, where an entity cannot walk because of steepness or interrupted ground, but could safely jump up, down, or over. There are some other capabilities present, as well: the ability for meshes to connect to other meshes via physical joints or outright teleportation, and the ability to make anti-meshes (non-walkable areas) and the like. We won't be using those today. Finally, we need to note the difference between a NavMesh and a HeightMesh. NavMeshes are approximations to the surfaces they describe; in particular \"stairs\" and other steps tend to get smoothed out into ramps. This doesn't matter for the purposed of navigation, but it can make your entities sort of \"float\" above the ground if they're placed directly on the mesh. HeightMeshes are a similar process, but they're more expensive to build and follow the ground more or less precisely (each stair will be flat, for example). The system I'm describing here makes only NavMeshes, so you may need to tweak monster positions a little bit in order to make them stick to the ground. Ultimately NavMeshes describe connectivity : Our entity can move from any blue area to any connected blue area, jump from one blue area to another across paired jump zones, and not move at all through non-blue areas. One final tip here: You can turn on NavMesh gizmos in the Game view as well as the Scene view. This is horrible for performance; your frame rates will drop precipitously. But it can be useful to occasionally check the meshes from the \"point of view\" of the player. It's also generally easier to see the height offsets between the actual ground and the approximating NavMesh in Game view. NavMeshAgent \u00b6 The other half of the equation is the NavMeshAgent . This is a component that's placed on the gameobject representing the moving 3D entity. It describes the entity's size and movement characteristics, things like: Height Width (technically \"radius\" of an implicit capsule collider) Turn speed in degrees/second How high the agent can step How steep a slope the agent can walk up Speed, acceleration, and stopping distance The NavMeshAgent also includes an \"Agent Type ID\", which is defined in the Navigation window's Agents tab. This duplicates several of the other properties (height, radius, step size, slope), and I'm not at all sure why you have to specify both, since if they don't match, the NavMeshAgent won't work. We'll encounter the Agent Type under another name: \"Build Settings\" later in the process. We will need to generate one NavMesh for every Agent Type that will walk on it. Since it's expensive to make these (in both memory and computation time), you'll likely want to bucket all of your entities into 2-3 different agent types (or just one, if everybody's human), even if that means some of the sizes won't match exactly. (This doesn't apply as much if you're baking in the editor where time doesn't matter, but they still take up a fair amount of memory.) From scripts, we can access the agent in the usual way we access any component: NavMeshAgent _navMeshAgent = gameObject . GetComponent < NavMeshAgent >(); Once you've got the agent, you can set a destination with SetDestination(<Vector3>) and override the speed, acceleration, turn rate, etc. if you like (if you don't, they'll use the ones defined in the agent itself). The Vector3 passed to \"destination\" ignores the Y value unless the NavMesh overlaps itself in 3D. We actually turn it on by telling the agent it should no longer be stopped: _navMeshAgent . isStopped = false ; (You also need the usual stuff like making sure the component is enabled and active.) At this point, one of two things will happen: The agent will start to move the gameObject toward the destination (it controls facing and movement, things like animation are up to you), or you'll start getting tons of error messages about \" can only be called on an active agent that has been placed on a NavMesh.\" Let's ignore the errors for a moment. Assuming your agent is moving your gameObject, you can then use the remainingDistance property on the NavMeshAgent to figure out how far the agent is from its destination (say, to give it another waypoint on a patrol route.). There are two caveats with remainingDistance : 1) It will return 0 when the agent can go no farther. This doesn't necessarily mean that it's at the destination you originally specified, just that it's as close as the NavMesh allows to that point (which could be quite far away, if you specified a someplace way off the mesh). 2) If the agent can't move in a straight line to the destination, it tends to return Infinity while it traverses a path, up until the last \"leg.\" Once it's just on a straight-line route to it's destination, it'll start giving real numbers. Both of these mean that you'll not want to rely on remainingDistance for things like \"time to destination\" calculations, because they'll be as random as a Windows download progress bar. Generally you care if it's very near zero or if it isn't. (It actually seems OK to test for exactly zero, but I've got 45 years of experience telling me to be skittish about exact equality tests on floating point numbers.) You don't need to wait for it to reach a destination before assigning a new one. For example, if it's chasing a player, you can give it the player's position as the destination every few frames. NavAgent \"active agent ... placed on a NavMesh\" Errors \u00b6 OK, back to those errors. In what's probably the biggest understatement in this post: NavAgents are very picky about their placement on a mesh. Very picky. Unbelievably picky. As with many of these sorts of things, a sort of mythology develops, as devs find their superstitious practices that \"fix\" the problem: The position needs to be exactly on the mesh. The feet of your model need to be exactly on the mesh. The model needs a capsule collider of exactly the mesh's agent size. The agent needs to be disabled and then enabled again. The \"Lord of the Rings\" needs to be playing on the TV while you code. The capsule collider thing may be true. Some of the others might work, too, but especially if we're going to be moving these things at runtime on NavMeshes that come and go, we need to have a more reliable way of insuring it. There first thing to check is _navMeshAgent.isActiveAndEnabled . If that returns false, either the gameObject has been set to inactive or the NavMeshAgent component on it is disabled. These are both pretty standard checks for weird Unity behaviors. Next up, we can actually test if the agent is \"really\" on a mesh by asking it. _navMeshAgent.isOnNavMesh returns true , then the agent is properly placed on a NavMesh compatible with its agent. In this case, you should be good to go, and you won't get the \"active agent...\" errors for that particular game object. But what if isOnNavMesh returns false ? First off, verify that the Agent Type selected for the agent is compatible with the NavMesh that you believe it to be on. If you only create the \"humanoid\" NavMesh, and you've got a non-humanoid agent, it'll never work. Otherwise, we should be able to fix it. There's two pieces of \"magic sauce\" here. One of them its the NavMesh.SamplePosition function. Note that this is a class (\"static\" ) function on NavMesh. All of NavMesh's user-accessible functions are static; which means\u2014among other things\u2014that our options for moving it off-thread will be limited, later. SamplePosition () works a lot like Physics.Raycast() . It takes a starting position, tries to find the nearest NavMesh point from it, and returns that value if it works. So: if ( NavMesh . SamplePosition ( transform . position , out NavMeshHit hit , 8f , 1 )) { // \"hit.position\" now contains a valid position on the mesh } else { // We're not close enough to a valid mesh position, do something else } The arguments to SamplePosition are The \"test\" position, probably the location of your gameObject itself. An out parameter of type NavMeshHit to hold the valid point (if any) The greatest distance to look. The manual suggests that this should be limited to twice the height of the agent or else the test starts getting expensive, so \"8f\" may well not be the right value for you. That said, I suspect that \"twice the height\" is a typo, and they mean \"twice the radius,\" since I don't understand how height would have anything to do with it. An \"area mask\" for what part of the NavMesh you want to look at. \"1\" here is the area mask for \"Walkable\", which is often what you want. Alternatively, \"0xFFFF\" (or better, the constant NavMesh.AllAreas ) will give you an area mask with all bits set, which will find allow you to find valid jump points, high-cost walking areas, etc. If your NavMesh has a complex mix of areas, you can be as specific as you want. Look up the area number in the Navigation window, and left-shift \"1\" that many times to set a bit in the mask. (For example, if you want area \"3\", you'd use 1<<3 . If you want area \"3\" and area \"0\", use 1<<3 | 1<<0 , and so on. You may have encountered this before with layer masks, which work the same way.) If SamplePosition returns false, you're out of luck. If you are placing your \"monsters\" randomly, this one's likely in a position that's not walkable or reachable, outside the NavMesh area, or there's no current NavMesh at all. You'll need to determine what to do about it. If this is an initial random placement, try placing somewhere else. There's an example in the documentation for SamplePosition that shows how to use it to find a random point on a mesh, although it's a little, uh, \"hit or miss,\" if you'll excuse the pun. But let's say that SamplePosition has returned true , and now we've got a shiny valid position in hit.position . We can just set our transform.position = hit.position and we're off, right? Right? Of course not. Not always, anyway. It seems to work about half the time. To actually move there, use the NavMeshAgent.Warp() function. This will move the agent's object to the specified position and then apparently do some magic to glue it to the NavMesh. It returns true if successful, which should be basically always if you're feeding it a position from SamplePosition . if ( NavMesh . SamplePosition ( transform . position , out NavMeshHit hit , 8f , 1 )) { // \"hit.position\" now contains a valid position on the mesh if ( _navMeshAgent . Warp ( hit . position )) { // We're good, and the agent should work now. } else { // Something weird happened, probably the NavMesh or NavMeshAgent became invalid // somehow. We have to handle it, of course, but it's going to // be a rare case, so maybe just destroying the object is good enough? } } else { // We're not close enough to a valid mesh position, do something else } What we we talking about, again? \u00b6 Oh yeah. Runtime NavMesh generation. To build a NavMesh at runtime, we need to use a NavMeshBuilder, another class/static class in the AI system. Well, it's actually TWO classes. One's in UnityEngine.AI , the other one's in UnityEditor.AI . But they're documented on the same page, with little annotations for which of the two it applies to. And they have the same name. And do the same things. Except when they don't. Aside: Have I mentioned that the Unity scripting documentation is a crime against humanity? If anybody from Unity is reading this... As with all things runtime, we can only use the functions in UnityEngine.AI; editor functions aren't available to us. We'll come back to this in a bit. If you need to know the answer, you can skip to the end. But I think it's important to understand how to do it wrong, and use the learnings from that to figure out how to do it right. Components for Runtime NavMesh Building. \u00b6 So to start with, users have been wanting build NavMeshes at runtime for a very long time, probably as long as NavMesh has existed. At Unity headquarters, a great flaming eye perches atop a dark tower, sweeping over the landscape looking for developers to torture. At some point about 2016, it settled on developers trying to build runtime NavMeshes. The result was something called \"Components for Runtime NavMesh Building.\" You can learn all about it in a Unity Learn Tutorial here . These were a set of \"prerelease\" components available from a Github project that were eventually meant to end up in Unity itself. They worked by adding a component ( NavMeshSurface ) to the gameObjects that are part of the \"environment\" and then calling a function to go out and find all these, and use them to build a NavMesh. But the Eye of Unity is easily distracted, and it quickly went off to start a new incompatible render pipeline or something. This tutorial makes two claims of note: that these would eventually become part of Unity itself (they didn't), and that they are fast enough to use at runtime, even every frame, at least on simple stuff. That second claim is likely true for things like procedural dungeons with relatively simple structures, but it sure doesn't seem to work that fast on Terrains. You still see poor lost souls wandering the Internet trying to use these; any reference to NavMeshSurface is a red flag. Back away slowly and don't make eye contact. I've actually managed to get them working even in Unity 2021.3, but the fact that these components have been abandoned for half a decade now doesn't give us confidence in using them. Using NavMeshBuilder \u00b6 So let's go back to the \"low level\" API, and try to build this ourselves. There are basically four steps that we need to perform: 1) Collect a list of the surfaces we're interested in some volume of (virtual) space. 2) Get descriptions of each of the \"agent types\" we're going to build the NavMeshes for. 3) Construct a \"NavMeshData\" object by evaluating each of those agent types against the surfaces 4) Add (or replace) that NavMeshData to the scene's current NavMesh. Let's look at each of them. Collecting Sources \u00b6 The first thing we want to do is collect a list of the surfaces, or sources that are available as potential parts of our NavMesh. This list is independent of Agent Type, so we've only got to do it once for a given volume of space. This will be done with NavMeshBuilder.CollectSources() , which takes six parameters. The first thing we need to do is specify the volume of space that the NavMesh will be built in. The larger this space, the longer it takes to build the mesh; I'll give you some actual numbers later on. But however we determine it, we'll need to create a Bounds object with it. That's basically a cube or box with a center and a radius along each axis. Here I make one centered on the player. My world is very 3D, so I use the same radius on all three axis. If yours is relatively flat, you might want to use a much smaller value for \"y\". Bounds patchBounds = new Bounds ( player . transform . position , new Vector3 ( navigationMeshRadius , navigationMeshRadius , navigationMeshRadius )); Next, you may or may not want every object in your scene to potentially be a walkable surface; it depends on your game. If you want to limit it to just certain objects, collect them into a layer. I use one called \"Terrain\". We're going to need a layer mask , which we get similarly to the area masks we described above: int mask = 1 << LayerMask . NameToLayer ( \"Terrain\" ); If you need more layers, \"or\" them together: int mask = ( 1 << LayerMask . NameToLayer ( \"FirstLayer\" )) | ( 1 << LayerMask . NameToLayer ( \"SecondLayer\" )); And so on. You could use 0xFFFF to set all bits, but that's likely to get you some pretty weird layers, and it's fragile in the face of third-party assets that often add layers. Better to specify them exactly. Programmer Note: You'll often see \"+\" used instead of \"|\" to combine masks like this. That's fine, so long as there are no duplicate values in the mask . If there are, addition will get you the wrong answer. Next up, we decide whether we want to collect render surfaces or collider ones. Typically, we think of a NavMesh as avoiding things we want to not collide with, so usually NavMeshCollectGeometry.PhysicsColliders is the right answer. The next two parameters to our collection function are the default area type (0 for \"walkable\") and a list of NavMeshBuildMarkup objects. These are what college professors often refer to as \"left for the interested reader to discover.\" They allow you to build meshes with non-uniform surfaces in them (for example, hard ground and soft mud), but we'll just assume it's all uniform, and pass \"0\" and an empty list for these two. Finally, we pass an empty list of NavMeshBuildSources , and the function will fill them in for us. With these six decisions in hand, we're ready to call NavMeshBuilder.CollectSources , which will do the actual scan of the Scene to find the sources and return them to us: // Get the list of all \"sources\" around us. This is basically little gridded subsquares // of our terrains. List < NavMeshBuildSource > buildSources = new List < NavMeshBuildSource >(); // Set up a boundary area for the build sources collector to look at; Bounds patchBounds = new Bounds ( player . transform . position , new Vector3 ( Monster . navigationMeshRadius , Monster . navigationMeshRadius , Monster . navigationMeshRadius )); // This actually collects them NavMeshBuilder . CollectSources ( patchBounds , 1 << LayerMask . NameToLayer ( \"Terrain\" ), NavMeshCollectGeometry . PhysicsColliders , 0 , new List < NavMeshBuildMarkup >(), buildSources ); There's an alternate form of CollectSources that takes a GameObject as the first parameter (instead of the bounds) and builds only from that object and it's children. Depending on how your game objects are structured in the hierarchy, one of the other will likely be easiest for you. Get the Build Settings for each Agent Type \u00b6 This one's easy: for ( int agentIndex = 0 ; agentIndex < NavMesh . GetSettingsCount (); agentIndex ++) { // Get the settings for each of our agent \"sizes\" (humanoid, giant humanoid) NavMeshBuildSettings bSettings = NavMesh . GetSettingsByIndex ( agentIndex ); ... } We can treat the NavMeshBuildSettings object as opaque, but if you look into it, you'll see it pretty much just contains all those values we set in the Navigation Window's \"Agents\" tab. But there's a handy function on NavMeshBuildSettings objects (a member function, not a class/static function) called ValidationReport . You use it like this: #if DEBUG // If there are any issues with the agent, print them out as a warning. foreach ( string s in bSettings . ValidationReport ( patchBounds )) { Debug . LogWarning ( $\"BuildSettings Report: {NavMesh.GetSettingsNameFromID(bSettings.agentTypeID)} : {s}\" ); } #endif This will verify that various of the parameters in each Agent Type's build settings are compatible; typically \"Step Size\" and \"Maximum Slope\" are the ones most likely to conflict. These don't necessarily make the NavMesh unusable, but you'll get some weird NavMeshAgent behaviors if you just ignore the warnings. The warning will tell you exactly what parameters are incompatible and what values will make them compatible. Build the NavMeshData \u00b6 Now that we've got all that, we need to use it to build the actual NavMeshData . For that, we call NavMeshBuilder.BuildNavMeshData for each Agent Type : NavMeshData newData = NavMeshBuilder . BuildNavMeshData ( bSettings , buildSources , patchBounds , transform . position , Quaternion . Euler ( Vector3 . up )); The first three parameters there, we've already discussed, the fourth is the center of the NavMesh and should match the center position of patch bounds, and the last is the \"up\" vector for the local space. This is where the real work is happening. Once it completes, we effectively have our new NavMesh in hand, and we just need to make it available to the scene. Add the NavMesh to the Scene \u00b6 This one's easy, too: NavMesh . AddNavMeshData ( meshData ); The new NavMesh will be available for NavMeshAgents and viewing in the Scene editor on the next frame. Note that if this is a replacement for an existing NavMesh (you're moving around a large open world with a floating origin system that moves the terrains, hypothetically ), there are a couple more steps: First, we'll need to remove the existing NavMesh before we add the new one. NavMesh . RemoveAllNavMeshData (); NavMesh . AddNavMeshData ( meshData ); And second, we'll need to walk through every NavMeshAgent and \"re-attach\" them to the new mesh by calling NavMesh.SamplePosition() and NavMeshAgent.Warp() on them. That's it! We've successfully made a NavMesh at runtime. We're done! Wait, why are you still here? \u00b6 OK, maybe we're done. Does your game have discrete levels with loading screens or other natural breaks between them? Then the code above should work fine for you. The fact that the NavMesh takes a fairly long time to generate can be \"hidden\" in the level transition, even an extra second might not be a dealbreaker. But how 'bout that floating origin system we were talking about, above\u2014or a game where deformation of the levels (explosions taking out walls, collapsing floors, sliding walls, portcullises, or whatever) can invalidate the NavMesh during play, requiring us to rebuild one. Well, the above code might still work for you. It depends on the complexity (and raw size) of your level, and the frame rate you want to maintain. Turn-based games might still be fine. Maybe. Let's look at some numbers. I just used the System.Diagnostics.Stopwatch to record elapsed time markers in at various places, then printed them out after the process was complete (using Debug.Log or other printing during the process would affect the results). Assuming we want our game to run at 120 frames/second, that gives us a budget of 1000/120 = about 8 milliseconds per frame. Your frame rate needs may vary. That 8 ms is the total time available; not just for mesh generation, but everything else that Unity needs to do in a frame. That's a perfect world -- it's usually OK for a frame to occasionally run long, but we need the total number of milliseconds per frame to be low, ideally single digits. So here's my results on two different machines. The first is a first generation Apple Silicon Mac, (Mac Studio M1 \"Max\", if it matters), and the other on a PC with a Ryzen 7 3700 processor and an Nvidia RTX 3080 video card, so comparable, high-end systems in most respects: Mac Windows Collect Sources 0 ms 1 ms Get Build Sources 1 ms 2 ms Build NavMesh 780 ms 1280 ms Add To NavMesh 1 ms 0 ms So...Good News and Bad News? Those small numbers have some randomness in them because I'm only sampling to the millisecond, but clearly most of these steps aren't going to give us any trouble. The problem, clearly, is that Build NavMesh step. This was for a 700 meter radius on a generated terrain. Not huge, by level standards, but it took more than a second on Windows, and a significant fraction of one on the Mac. And remember that these are high-end systems. The average mid-range gaming machine or MacBook Air is going to do a lot worse. By lowering the radius to 250 meters, I got down to about 100 ms on the Mac, so we have one knob we can play with. But even with that change, there's a very, very obvious stutter when the NavMesh rebuilds. It would be almost impossible to hide. We could lower the radius even more (maybe 50 meters), and build a little bit of the mesh each frame, adding them together over time. But that's a pain to write, and we'd be better off using some asynchronous method (co-routines, jobs, or some other mechanism) to spread the work out more conventionally, instead. So let's look back at that NavMeshBuilder documentation page. There it is! \" BuildNavMeshAsync !\" We're saved. ...except for that \"(UnityEditor)\" at the end of it. It's literally exactly what we want, but we're not allowed to use it at runtime. Aside: OK, what the HECK Unity? In what possible universe does it make sense for the non-time-dependent editor building to be asynchronous, but the runtime version where literally 100% of the users are going to need it to be fast not be? That's not just annoying, it's way past the line into \"actively malicious.\" At this point we should run through our list of obscenities, but once we're done, note that there's one more possibility: UpdateNavMeshDataAsync() . This is similar to BuildNavMeshData , except that it adds or removes data from an existing NavMeshData object (and doesn't take an \"up\" vector, so it can only be used for standard orientations). We can work with that. It's a little weird, but if we just make an empty NavMeshData object and then \"Update\" it with all the data, we'll get the same end result. Something like: // Make a new mesh data object. NavMeshData meshData = new NavMeshData (); // \"Update\" it from scratch. AsyncOperation buildOp = NavMeshBuilder . UpdateNavMeshDataAsync ( meshData , bSettings , buildSources , patchBounds ); Note that UpdateNavMeshDataAsync returns an AsyncOperation , one of the approximately 52,937,419 different asynchronous mechanisms in .NET (the Flaming Eye of Microsoft is also easily distracted, especially with developer frameworks). Off the top of my head, I don't even remember whether this one moves the work off-thread or not; for our purposes, it doesn't really matter. Rebuild for Asynchronicity \u00b6 So the trick here is that we're going to need to move this work to a co-routine, and re-arrange things a little bit to make it work. It's not going to be a perfect solution; it's still going to take some time for our new NavMesh to be ready, we're just not going to interrupt the rest of the game while we wait for it. If you're in a scenario where you can keep using the old mesh until the new one is available; you should. If you can't (your \"terrain\" objects are changing position, origin, or whatever), you'll need to be prepared for there to be some time when your NavMeshAgents have no mesh to use, and do something intelligent with that time (move them in a straight line, idle them, have them stand and guard, or taunt, whatever). But in return for that bit of complexity, we should be able to easily do the actual mesh exchange in a millisecond or two, so frame rate shouldn't t be affected at all. Your coroutine may look a little different from mine, depending on where you get some of your parameters from, but I'm going to pass in the center point of the new mesh bounds, a single radius for all axes, and a boolean flag for whether I'm adding to or replacing an existing mesh. Here's the whole thing: /// <summary> /// Coroutine to rebuild the current Scene NavMesh. /// </summary> /// <param name=\"playerPosition\">The center of the mesh search volume</param> /// <param name=\"navigationMeshRadius\">How big a volume should we search for surfaces in.</param> /// <param name=\"rebuildAll\">If \"true\", delete any existing meshes before adding new ones.</param> /// <returns></returns> IEnumerator NavMeshOutOfDateCoroutine ( Vector3 playerPosition , float navigationMeshRadius , bool rebuildAll ) { // Get the list of all \"sources\" around us. This is basically little gridded subsquares // of our terrains. List < NavMeshBuildSource > buildSources = new List < NavMeshBuildSource >(); // Set up a boundary area for the build sources collector to look at; Bounds patchBounds = new Bounds ( playerPosition , new Vector3 ( navigationMeshRadius , navigationMeshRadius , navigationMeshRadius )); // This actually collects the potential surfaces. NavMeshBuilder . CollectSources ( patchBounds , 1 << LayerMask . NameToLayer ( \"Terrain\" ), NavMeshCollectGeometry . PhysicsColliders , 0 , new List < NavMeshBuildMarkup >(), buildSources ); yield return null ; // Build some empty NavMeshData objects int numAgentTypes = NavMesh . GetSettingsCount (); NavMeshData [] meshData = new NavMeshData [ numAgentTypes ]; for ( int agentIndex = 0 ; agentIndex < numAgentTypes ; agentIndex ++) { // Get the settings for each of our agent \"sizes\" (humanoid, giant humanoid) NavMeshBuildSettings bSettings = NavMesh . GetSettingsByIndex ( agentIndex ); // If there are any issues with the agent, print them out as a warning. #if DEBUG foreach ( string s in bSettings . ValidationReport ( patchBounds )) { Debug . LogWarning ( $\"BuildSettings Report: {NavMesh.GetSettingsNameFromID(bSettings.agentTypeID)} : {s}\" ); } #endif // Make empty mesh data object. meshData [ agentIndex ] = new NavMeshData (); AsyncOperation buildOp = NavMeshBuilder . UpdateNavMeshDataAsync ( meshData [ agentIndex ], bSettings , buildSources , patchBounds ); while (! buildOp . isDone ) yield return null ; } if ( rebuildAll ) { NavMesh . RemoveAllNavMeshData (); } for ( int nmd = 0 ; nmd < meshData . Length ; nmd ++) { NavMesh . AddNavMeshData ( meshData [ nmd ]); } yield return null ; } There are a few key lines there, particularly the various yield return null; ones. If you're not familiar with coroutines, that's just code for \"stop here for this frame, go do whatever else you want, and resume here on the next frame.\" In particular, most of the (non) work is done by: while (! buildOp . isDone ) yield return null ; That line is where most of the time in the coroutine is spent. It just checks to see \"is the AsyncOperation done, yet?\" And yields until the next frame if it isn't. Eventually, everything completes and the rest of the code takes only a few milliseconds to actually instantiate the mesh. Also note that we build all the meshes, then remove existing ones (if we're going to), then add the new ones all at once rather than as each one is built. This minimizes the time when no mesh exists at all -- in fact, since there's no yield between the removal and the adds, the new mesh should be available in the very same frame as the old one goes away. (The old NavMesh may or may not still be valid that long, but for most uses it won't matter if it hangs around while we make the new one.) So does it work? \u00b6 In a nutshell, yes. There's no stutter at all when new NavMeshes are being built or instantiated; I had to put Debug logging in or keep the scene window open even to know when it happened. Was it worth all that effort? Also, yes; being able to build at runtime without destroying the frame rate makes possible scenarios that otherwise wouldn't be, even if the \"wait\" for the NavMesh to become available isn't ideal. For small NavMeshes (a simple dungeon level, basement, maybe even a small village or house), this may very well be usable even several times a second (it can't be every frame because of the yield returns ). And for much larger or more complex meshes, it at least makes building them possible . The biggest caveat is that if you're doing something like floating origins, where the terrains occasionally move about and have to be re-generated (remember NavMeshes have to be on Navigation Static objects), your NavMeshAgents have to be able to account for periods where the NavMesh \"goes away\" and a new one isn't available yet. That's a pain, but it's not too horrible.","title":"Asynchronous Runtime Navmesh Generation in Unity"},{"location":"blog/runtime_navmesh/#asynchronous-runtime-navmesh-generation-in-unity","text":"Buckle in, boys and girls. This one's going to be a ride. I've recently started trying to add monsters to the world I'm creating over in my Unity Procedural Terrain system. I'd like to use the NavMesh system for enemy AI, but since my terrains aren't created in the Unity Editor, but rather randomly at runtime, I need to be able to create the NavMeshes for my monsters at runtime. And thus began the rabbit hole. It became quickly obvious that it could be done, but equally obvious that there wasn't really a good known solution out there, particularly one that was performant enough to use in a runtime environment where terrains were being created and destroyed at a reasonably fast cadence as the player moves around a large open world. As every Unity developer knows, the Unity documentation is sort of like the Evil Stepmother of fairy tales: keeping up an appearance of caring about you while secretly undermining any chance you've got for success, and possibly actually poisoning you. [Author's Note] If anyone at Unity is reading this, please consider hiring me to come in and try and clean up some of that documentation, particularly the scripting side. Some simple rules and standards could make it infinitely more useful for actual developers. So I've dug into this, and it turns out that it's not actually as horrifying as it initially seems, although there's a few caveats. Let's see if we can clear it up a bit.","title":"Asynchronous Runtime Navmesh Generation in Unity"},{"location":"blog/runtime_navmesh/#background","text":"Unity provides a built-in AI Navigation system for 3D games. This allows 3D entities to figure out where they can \"walk,\" and provides automatic pathing, obstacle avoidance, patrol points, target tracking, and the like. It's not going to pass the Turing test any time soon, but for many games it provides a moderately sophisticated level of \"enemy\" AI for relatively little effort. The two major components of this system are the NavMesh and the NavMeshAgent .","title":"Background"},{"location":"blog/runtime_navmesh/#navmesh","text":"NavMesh is a property of the Scene . You can think of it as a sort of invisible carpet that covers the scene in places where an entity of a given size can walk. That is, it'll be all over the floor except right next to walls or under doors and arches that the entity is too large to pass through, or on slopes too steep for that entity to walk up. You can visualize a NavMesh in a scene by: Opening the Navigation Inspector (Window->AI->Navigation). You need to have the inspector active in order to see NavMeshes . Go to the Scene View Turn on Gizmos (either all of them, or the specific ones for Navigation AI). Move your viewpoint close enough to the mesh (navmeshes clip out after a few dozen units). If you've done all that\u2014and there's a NavMesh created for the Scene at all\u2014you should see a sort of blue layer across your walkable areas. Note that the NavMesh is pretty smart: it doesn't allow you to \"walk\" on the cliff faces or steeper areas, and avoids the larger rocks (though not the trees in this case). The image above actually shows two overlapping NavMeshes : one for fairly large entities (giants and such), and one for human-sized ones. You can see the difference particularly along the straight cliff edge, where smaller entities can approach much closer than large ones. Note that the NavMesh indicates where the center of the entity can travel, which is why it doesn't go right to the edges. (That screen shot is from a significant distance from the player in the center.) The NavMesh typically is built for \"walkable\" areas, although you have a great deal of flexibility in its creation. For example, you can mark certain areas as \"walkable, but harder,\" like mud, sand, or shallow water. The AI system will assign these areas higher cost, allowing the navigating to be \"smart\" about whether to walk through such an area or go around. It's also possible to add meshes with different \"up\" orientations, such as for spiders that can walk on walls or ceilings (linking them with \"off mesh links\"). You can't see it here because the distances are too large, but the NavMesh will also intelligently create \"jump\" points, where an entity cannot walk because of steepness or interrupted ground, but could safely jump up, down, or over. There are some other capabilities present, as well: the ability for meshes to connect to other meshes via physical joints or outright teleportation, and the ability to make anti-meshes (non-walkable areas) and the like. We won't be using those today. Finally, we need to note the difference between a NavMesh and a HeightMesh. NavMeshes are approximations to the surfaces they describe; in particular \"stairs\" and other steps tend to get smoothed out into ramps. This doesn't matter for the purposed of navigation, but it can make your entities sort of \"float\" above the ground if they're placed directly on the mesh. HeightMeshes are a similar process, but they're more expensive to build and follow the ground more or less precisely (each stair will be flat, for example). The system I'm describing here makes only NavMeshes, so you may need to tweak monster positions a little bit in order to make them stick to the ground. Ultimately NavMeshes describe connectivity : Our entity can move from any blue area to any connected blue area, jump from one blue area to another across paired jump zones, and not move at all through non-blue areas. One final tip here: You can turn on NavMesh gizmos in the Game view as well as the Scene view. This is horrible for performance; your frame rates will drop precipitously. But it can be useful to occasionally check the meshes from the \"point of view\" of the player. It's also generally easier to see the height offsets between the actual ground and the approximating NavMesh in Game view.","title":"NavMesh"},{"location":"blog/runtime_navmesh/#navmeshagent","text":"The other half of the equation is the NavMeshAgent . This is a component that's placed on the gameobject representing the moving 3D entity. It describes the entity's size and movement characteristics, things like: Height Width (technically \"radius\" of an implicit capsule collider) Turn speed in degrees/second How high the agent can step How steep a slope the agent can walk up Speed, acceleration, and stopping distance The NavMeshAgent also includes an \"Agent Type ID\", which is defined in the Navigation window's Agents tab. This duplicates several of the other properties (height, radius, step size, slope), and I'm not at all sure why you have to specify both, since if they don't match, the NavMeshAgent won't work. We'll encounter the Agent Type under another name: \"Build Settings\" later in the process. We will need to generate one NavMesh for every Agent Type that will walk on it. Since it's expensive to make these (in both memory and computation time), you'll likely want to bucket all of your entities into 2-3 different agent types (or just one, if everybody's human), even if that means some of the sizes won't match exactly. (This doesn't apply as much if you're baking in the editor where time doesn't matter, but they still take up a fair amount of memory.) From scripts, we can access the agent in the usual way we access any component: NavMeshAgent _navMeshAgent = gameObject . GetComponent < NavMeshAgent >(); Once you've got the agent, you can set a destination with SetDestination(<Vector3>) and override the speed, acceleration, turn rate, etc. if you like (if you don't, they'll use the ones defined in the agent itself). The Vector3 passed to \"destination\" ignores the Y value unless the NavMesh overlaps itself in 3D. We actually turn it on by telling the agent it should no longer be stopped: _navMeshAgent . isStopped = false ; (You also need the usual stuff like making sure the component is enabled and active.) At this point, one of two things will happen: The agent will start to move the gameObject toward the destination (it controls facing and movement, things like animation are up to you), or you'll start getting tons of error messages about \" can only be called on an active agent that has been placed on a NavMesh.\" Let's ignore the errors for a moment. Assuming your agent is moving your gameObject, you can then use the remainingDistance property on the NavMeshAgent to figure out how far the agent is from its destination (say, to give it another waypoint on a patrol route.). There are two caveats with remainingDistance : 1) It will return 0 when the agent can go no farther. This doesn't necessarily mean that it's at the destination you originally specified, just that it's as close as the NavMesh allows to that point (which could be quite far away, if you specified a someplace way off the mesh). 2) If the agent can't move in a straight line to the destination, it tends to return Infinity while it traverses a path, up until the last \"leg.\" Once it's just on a straight-line route to it's destination, it'll start giving real numbers. Both of these mean that you'll not want to rely on remainingDistance for things like \"time to destination\" calculations, because they'll be as random as a Windows download progress bar. Generally you care if it's very near zero or if it isn't. (It actually seems OK to test for exactly zero, but I've got 45 years of experience telling me to be skittish about exact equality tests on floating point numbers.) You don't need to wait for it to reach a destination before assigning a new one. For example, if it's chasing a player, you can give it the player's position as the destination every few frames.","title":"NavMeshAgent"},{"location":"blog/runtime_navmesh/#navagent-active-agent-placed-on-a-navmesh-errors","text":"OK, back to those errors. In what's probably the biggest understatement in this post: NavAgents are very picky about their placement on a mesh. Very picky. Unbelievably picky. As with many of these sorts of things, a sort of mythology develops, as devs find their superstitious practices that \"fix\" the problem: The position needs to be exactly on the mesh. The feet of your model need to be exactly on the mesh. The model needs a capsule collider of exactly the mesh's agent size. The agent needs to be disabled and then enabled again. The \"Lord of the Rings\" needs to be playing on the TV while you code. The capsule collider thing may be true. Some of the others might work, too, but especially if we're going to be moving these things at runtime on NavMeshes that come and go, we need to have a more reliable way of insuring it. There first thing to check is _navMeshAgent.isActiveAndEnabled . If that returns false, either the gameObject has been set to inactive or the NavMeshAgent component on it is disabled. These are both pretty standard checks for weird Unity behaviors. Next up, we can actually test if the agent is \"really\" on a mesh by asking it. _navMeshAgent.isOnNavMesh returns true , then the agent is properly placed on a NavMesh compatible with its agent. In this case, you should be good to go, and you won't get the \"active agent...\" errors for that particular game object. But what if isOnNavMesh returns false ? First off, verify that the Agent Type selected for the agent is compatible with the NavMesh that you believe it to be on. If you only create the \"humanoid\" NavMesh, and you've got a non-humanoid agent, it'll never work. Otherwise, we should be able to fix it. There's two pieces of \"magic sauce\" here. One of them its the NavMesh.SamplePosition function. Note that this is a class (\"static\" ) function on NavMesh. All of NavMesh's user-accessible functions are static; which means\u2014among other things\u2014that our options for moving it off-thread will be limited, later. SamplePosition () works a lot like Physics.Raycast() . It takes a starting position, tries to find the nearest NavMesh point from it, and returns that value if it works. So: if ( NavMesh . SamplePosition ( transform . position , out NavMeshHit hit , 8f , 1 )) { // \"hit.position\" now contains a valid position on the mesh } else { // We're not close enough to a valid mesh position, do something else } The arguments to SamplePosition are The \"test\" position, probably the location of your gameObject itself. An out parameter of type NavMeshHit to hold the valid point (if any) The greatest distance to look. The manual suggests that this should be limited to twice the height of the agent or else the test starts getting expensive, so \"8f\" may well not be the right value for you. That said, I suspect that \"twice the height\" is a typo, and they mean \"twice the radius,\" since I don't understand how height would have anything to do with it. An \"area mask\" for what part of the NavMesh you want to look at. \"1\" here is the area mask for \"Walkable\", which is often what you want. Alternatively, \"0xFFFF\" (or better, the constant NavMesh.AllAreas ) will give you an area mask with all bits set, which will find allow you to find valid jump points, high-cost walking areas, etc. If your NavMesh has a complex mix of areas, you can be as specific as you want. Look up the area number in the Navigation window, and left-shift \"1\" that many times to set a bit in the mask. (For example, if you want area \"3\", you'd use 1<<3 . If you want area \"3\" and area \"0\", use 1<<3 | 1<<0 , and so on. You may have encountered this before with layer masks, which work the same way.) If SamplePosition returns false, you're out of luck. If you are placing your \"monsters\" randomly, this one's likely in a position that's not walkable or reachable, outside the NavMesh area, or there's no current NavMesh at all. You'll need to determine what to do about it. If this is an initial random placement, try placing somewhere else. There's an example in the documentation for SamplePosition that shows how to use it to find a random point on a mesh, although it's a little, uh, \"hit or miss,\" if you'll excuse the pun. But let's say that SamplePosition has returned true , and now we've got a shiny valid position in hit.position . We can just set our transform.position = hit.position and we're off, right? Right? Of course not. Not always, anyway. It seems to work about half the time. To actually move there, use the NavMeshAgent.Warp() function. This will move the agent's object to the specified position and then apparently do some magic to glue it to the NavMesh. It returns true if successful, which should be basically always if you're feeding it a position from SamplePosition . if ( NavMesh . SamplePosition ( transform . position , out NavMeshHit hit , 8f , 1 )) { // \"hit.position\" now contains a valid position on the mesh if ( _navMeshAgent . Warp ( hit . position )) { // We're good, and the agent should work now. } else { // Something weird happened, probably the NavMesh or NavMeshAgent became invalid // somehow. We have to handle it, of course, but it's going to // be a rare case, so maybe just destroying the object is good enough? } } else { // We're not close enough to a valid mesh position, do something else }","title":"NavAgent \"active agent ... placed on a NavMesh\" Errors"},{"location":"blog/runtime_navmesh/#what-we-we-talking-about-again","text":"Oh yeah. Runtime NavMesh generation. To build a NavMesh at runtime, we need to use a NavMeshBuilder, another class/static class in the AI system. Well, it's actually TWO classes. One's in UnityEngine.AI , the other one's in UnityEditor.AI . But they're documented on the same page, with little annotations for which of the two it applies to. And they have the same name. And do the same things. Except when they don't. Aside: Have I mentioned that the Unity scripting documentation is a crime against humanity? If anybody from Unity is reading this... As with all things runtime, we can only use the functions in UnityEngine.AI; editor functions aren't available to us. We'll come back to this in a bit. If you need to know the answer, you can skip to the end. But I think it's important to understand how to do it wrong, and use the learnings from that to figure out how to do it right.","title":"What we we talking about, again?"},{"location":"blog/runtime_navmesh/#components-for-runtime-navmesh-building","text":"So to start with, users have been wanting build NavMeshes at runtime for a very long time, probably as long as NavMesh has existed. At Unity headquarters, a great flaming eye perches atop a dark tower, sweeping over the landscape looking for developers to torture. At some point about 2016, it settled on developers trying to build runtime NavMeshes. The result was something called \"Components for Runtime NavMesh Building.\" You can learn all about it in a Unity Learn Tutorial here . These were a set of \"prerelease\" components available from a Github project that were eventually meant to end up in Unity itself. They worked by adding a component ( NavMeshSurface ) to the gameObjects that are part of the \"environment\" and then calling a function to go out and find all these, and use them to build a NavMesh. But the Eye of Unity is easily distracted, and it quickly went off to start a new incompatible render pipeline or something. This tutorial makes two claims of note: that these would eventually become part of Unity itself (they didn't), and that they are fast enough to use at runtime, even every frame, at least on simple stuff. That second claim is likely true for things like procedural dungeons with relatively simple structures, but it sure doesn't seem to work that fast on Terrains. You still see poor lost souls wandering the Internet trying to use these; any reference to NavMeshSurface is a red flag. Back away slowly and don't make eye contact. I've actually managed to get them working even in Unity 2021.3, but the fact that these components have been abandoned for half a decade now doesn't give us confidence in using them.","title":"Components for Runtime NavMesh Building."},{"location":"blog/runtime_navmesh/#using-navmeshbuilder","text":"So let's go back to the \"low level\" API, and try to build this ourselves. There are basically four steps that we need to perform: 1) Collect a list of the surfaces we're interested in some volume of (virtual) space. 2) Get descriptions of each of the \"agent types\" we're going to build the NavMeshes for. 3) Construct a \"NavMeshData\" object by evaluating each of those agent types against the surfaces 4) Add (or replace) that NavMeshData to the scene's current NavMesh. Let's look at each of them.","title":"Using NavMeshBuilder"},{"location":"blog/runtime_navmesh/#collecting-sources","text":"The first thing we want to do is collect a list of the surfaces, or sources that are available as potential parts of our NavMesh. This list is independent of Agent Type, so we've only got to do it once for a given volume of space. This will be done with NavMeshBuilder.CollectSources() , which takes six parameters. The first thing we need to do is specify the volume of space that the NavMesh will be built in. The larger this space, the longer it takes to build the mesh; I'll give you some actual numbers later on. But however we determine it, we'll need to create a Bounds object with it. That's basically a cube or box with a center and a radius along each axis. Here I make one centered on the player. My world is very 3D, so I use the same radius on all three axis. If yours is relatively flat, you might want to use a much smaller value for \"y\". Bounds patchBounds = new Bounds ( player . transform . position , new Vector3 ( navigationMeshRadius , navigationMeshRadius , navigationMeshRadius )); Next, you may or may not want every object in your scene to potentially be a walkable surface; it depends on your game. If you want to limit it to just certain objects, collect them into a layer. I use one called \"Terrain\". We're going to need a layer mask , which we get similarly to the area masks we described above: int mask = 1 << LayerMask . NameToLayer ( \"Terrain\" ); If you need more layers, \"or\" them together: int mask = ( 1 << LayerMask . NameToLayer ( \"FirstLayer\" )) | ( 1 << LayerMask . NameToLayer ( \"SecondLayer\" )); And so on. You could use 0xFFFF to set all bits, but that's likely to get you some pretty weird layers, and it's fragile in the face of third-party assets that often add layers. Better to specify them exactly. Programmer Note: You'll often see \"+\" used instead of \"|\" to combine masks like this. That's fine, so long as there are no duplicate values in the mask . If there are, addition will get you the wrong answer. Next up, we decide whether we want to collect render surfaces or collider ones. Typically, we think of a NavMesh as avoiding things we want to not collide with, so usually NavMeshCollectGeometry.PhysicsColliders is the right answer. The next two parameters to our collection function are the default area type (0 for \"walkable\") and a list of NavMeshBuildMarkup objects. These are what college professors often refer to as \"left for the interested reader to discover.\" They allow you to build meshes with non-uniform surfaces in them (for example, hard ground and soft mud), but we'll just assume it's all uniform, and pass \"0\" and an empty list for these two. Finally, we pass an empty list of NavMeshBuildSources , and the function will fill them in for us. With these six decisions in hand, we're ready to call NavMeshBuilder.CollectSources , which will do the actual scan of the Scene to find the sources and return them to us: // Get the list of all \"sources\" around us. This is basically little gridded subsquares // of our terrains. List < NavMeshBuildSource > buildSources = new List < NavMeshBuildSource >(); // Set up a boundary area for the build sources collector to look at; Bounds patchBounds = new Bounds ( player . transform . position , new Vector3 ( Monster . navigationMeshRadius , Monster . navigationMeshRadius , Monster . navigationMeshRadius )); // This actually collects them NavMeshBuilder . CollectSources ( patchBounds , 1 << LayerMask . NameToLayer ( \"Terrain\" ), NavMeshCollectGeometry . PhysicsColliders , 0 , new List < NavMeshBuildMarkup >(), buildSources ); There's an alternate form of CollectSources that takes a GameObject as the first parameter (instead of the bounds) and builds only from that object and it's children. Depending on how your game objects are structured in the hierarchy, one of the other will likely be easiest for you.","title":"Collecting Sources"},{"location":"blog/runtime_navmesh/#get-the-build-settings-for-each-agent-type","text":"This one's easy: for ( int agentIndex = 0 ; agentIndex < NavMesh . GetSettingsCount (); agentIndex ++) { // Get the settings for each of our agent \"sizes\" (humanoid, giant humanoid) NavMeshBuildSettings bSettings = NavMesh . GetSettingsByIndex ( agentIndex ); ... } We can treat the NavMeshBuildSettings object as opaque, but if you look into it, you'll see it pretty much just contains all those values we set in the Navigation Window's \"Agents\" tab. But there's a handy function on NavMeshBuildSettings objects (a member function, not a class/static function) called ValidationReport . You use it like this: #if DEBUG // If there are any issues with the agent, print them out as a warning. foreach ( string s in bSettings . ValidationReport ( patchBounds )) { Debug . LogWarning ( $\"BuildSettings Report: {NavMesh.GetSettingsNameFromID(bSettings.agentTypeID)} : {s}\" ); } #endif This will verify that various of the parameters in each Agent Type's build settings are compatible; typically \"Step Size\" and \"Maximum Slope\" are the ones most likely to conflict. These don't necessarily make the NavMesh unusable, but you'll get some weird NavMeshAgent behaviors if you just ignore the warnings. The warning will tell you exactly what parameters are incompatible and what values will make them compatible.","title":"Get the Build Settings for each Agent Type"},{"location":"blog/runtime_navmesh/#build-the-navmeshdata","text":"Now that we've got all that, we need to use it to build the actual NavMeshData . For that, we call NavMeshBuilder.BuildNavMeshData for each Agent Type : NavMeshData newData = NavMeshBuilder . BuildNavMeshData ( bSettings , buildSources , patchBounds , transform . position , Quaternion . Euler ( Vector3 . up )); The first three parameters there, we've already discussed, the fourth is the center of the NavMesh and should match the center position of patch bounds, and the last is the \"up\" vector for the local space. This is where the real work is happening. Once it completes, we effectively have our new NavMesh in hand, and we just need to make it available to the scene.","title":"Build the NavMeshData"},{"location":"blog/runtime_navmesh/#add-the-navmesh-to-the-scene","text":"This one's easy, too: NavMesh . AddNavMeshData ( meshData ); The new NavMesh will be available for NavMeshAgents and viewing in the Scene editor on the next frame. Note that if this is a replacement for an existing NavMesh (you're moving around a large open world with a floating origin system that moves the terrains, hypothetically ), there are a couple more steps: First, we'll need to remove the existing NavMesh before we add the new one. NavMesh . RemoveAllNavMeshData (); NavMesh . AddNavMeshData ( meshData ); And second, we'll need to walk through every NavMeshAgent and \"re-attach\" them to the new mesh by calling NavMesh.SamplePosition() and NavMeshAgent.Warp() on them. That's it! We've successfully made a NavMesh at runtime. We're done!","title":"Add the NavMesh to the Scene"},{"location":"blog/runtime_navmesh/#wait-why-are-you-still-here","text":"OK, maybe we're done. Does your game have discrete levels with loading screens or other natural breaks between them? Then the code above should work fine for you. The fact that the NavMesh takes a fairly long time to generate can be \"hidden\" in the level transition, even an extra second might not be a dealbreaker. But how 'bout that floating origin system we were talking about, above\u2014or a game where deformation of the levels (explosions taking out walls, collapsing floors, sliding walls, portcullises, or whatever) can invalidate the NavMesh during play, requiring us to rebuild one. Well, the above code might still work for you. It depends on the complexity (and raw size) of your level, and the frame rate you want to maintain. Turn-based games might still be fine. Maybe. Let's look at some numbers. I just used the System.Diagnostics.Stopwatch to record elapsed time markers in at various places, then printed them out after the process was complete (using Debug.Log or other printing during the process would affect the results). Assuming we want our game to run at 120 frames/second, that gives us a budget of 1000/120 = about 8 milliseconds per frame. Your frame rate needs may vary. That 8 ms is the total time available; not just for mesh generation, but everything else that Unity needs to do in a frame. That's a perfect world -- it's usually OK for a frame to occasionally run long, but we need the total number of milliseconds per frame to be low, ideally single digits. So here's my results on two different machines. The first is a first generation Apple Silicon Mac, (Mac Studio M1 \"Max\", if it matters), and the other on a PC with a Ryzen 7 3700 processor and an Nvidia RTX 3080 video card, so comparable, high-end systems in most respects: Mac Windows Collect Sources 0 ms 1 ms Get Build Sources 1 ms 2 ms Build NavMesh 780 ms 1280 ms Add To NavMesh 1 ms 0 ms So...Good News and Bad News? Those small numbers have some randomness in them because I'm only sampling to the millisecond, but clearly most of these steps aren't going to give us any trouble. The problem, clearly, is that Build NavMesh step. This was for a 700 meter radius on a generated terrain. Not huge, by level standards, but it took more than a second on Windows, and a significant fraction of one on the Mac. And remember that these are high-end systems. The average mid-range gaming machine or MacBook Air is going to do a lot worse. By lowering the radius to 250 meters, I got down to about 100 ms on the Mac, so we have one knob we can play with. But even with that change, there's a very, very obvious stutter when the NavMesh rebuilds. It would be almost impossible to hide. We could lower the radius even more (maybe 50 meters), and build a little bit of the mesh each frame, adding them together over time. But that's a pain to write, and we'd be better off using some asynchronous method (co-routines, jobs, or some other mechanism) to spread the work out more conventionally, instead. So let's look back at that NavMeshBuilder documentation page. There it is! \" BuildNavMeshAsync !\" We're saved. ...except for that \"(UnityEditor)\" at the end of it. It's literally exactly what we want, but we're not allowed to use it at runtime. Aside: OK, what the HECK Unity? In what possible universe does it make sense for the non-time-dependent editor building to be asynchronous, but the runtime version where literally 100% of the users are going to need it to be fast not be? That's not just annoying, it's way past the line into \"actively malicious.\" At this point we should run through our list of obscenities, but once we're done, note that there's one more possibility: UpdateNavMeshDataAsync() . This is similar to BuildNavMeshData , except that it adds or removes data from an existing NavMeshData object (and doesn't take an \"up\" vector, so it can only be used for standard orientations). We can work with that. It's a little weird, but if we just make an empty NavMeshData object and then \"Update\" it with all the data, we'll get the same end result. Something like: // Make a new mesh data object. NavMeshData meshData = new NavMeshData (); // \"Update\" it from scratch. AsyncOperation buildOp = NavMeshBuilder . UpdateNavMeshDataAsync ( meshData , bSettings , buildSources , patchBounds ); Note that UpdateNavMeshDataAsync returns an AsyncOperation , one of the approximately 52,937,419 different asynchronous mechanisms in .NET (the Flaming Eye of Microsoft is also easily distracted, especially with developer frameworks). Off the top of my head, I don't even remember whether this one moves the work off-thread or not; for our purposes, it doesn't really matter.","title":"Wait, why are you still here?"},{"location":"blog/runtime_navmesh/#rebuild-for-asynchronicity","text":"So the trick here is that we're going to need to move this work to a co-routine, and re-arrange things a little bit to make it work. It's not going to be a perfect solution; it's still going to take some time for our new NavMesh to be ready, we're just not going to interrupt the rest of the game while we wait for it. If you're in a scenario where you can keep using the old mesh until the new one is available; you should. If you can't (your \"terrain\" objects are changing position, origin, or whatever), you'll need to be prepared for there to be some time when your NavMeshAgents have no mesh to use, and do something intelligent with that time (move them in a straight line, idle them, have them stand and guard, or taunt, whatever). But in return for that bit of complexity, we should be able to easily do the actual mesh exchange in a millisecond or two, so frame rate shouldn't t be affected at all. Your coroutine may look a little different from mine, depending on where you get some of your parameters from, but I'm going to pass in the center point of the new mesh bounds, a single radius for all axes, and a boolean flag for whether I'm adding to or replacing an existing mesh. Here's the whole thing: /// <summary> /// Coroutine to rebuild the current Scene NavMesh. /// </summary> /// <param name=\"playerPosition\">The center of the mesh search volume</param> /// <param name=\"navigationMeshRadius\">How big a volume should we search for surfaces in.</param> /// <param name=\"rebuildAll\">If \"true\", delete any existing meshes before adding new ones.</param> /// <returns></returns> IEnumerator NavMeshOutOfDateCoroutine ( Vector3 playerPosition , float navigationMeshRadius , bool rebuildAll ) { // Get the list of all \"sources\" around us. This is basically little gridded subsquares // of our terrains. List < NavMeshBuildSource > buildSources = new List < NavMeshBuildSource >(); // Set up a boundary area for the build sources collector to look at; Bounds patchBounds = new Bounds ( playerPosition , new Vector3 ( navigationMeshRadius , navigationMeshRadius , navigationMeshRadius )); // This actually collects the potential surfaces. NavMeshBuilder . CollectSources ( patchBounds , 1 << LayerMask . NameToLayer ( \"Terrain\" ), NavMeshCollectGeometry . PhysicsColliders , 0 , new List < NavMeshBuildMarkup >(), buildSources ); yield return null ; // Build some empty NavMeshData objects int numAgentTypes = NavMesh . GetSettingsCount (); NavMeshData [] meshData = new NavMeshData [ numAgentTypes ]; for ( int agentIndex = 0 ; agentIndex < numAgentTypes ; agentIndex ++) { // Get the settings for each of our agent \"sizes\" (humanoid, giant humanoid) NavMeshBuildSettings bSettings = NavMesh . GetSettingsByIndex ( agentIndex ); // If there are any issues with the agent, print them out as a warning. #if DEBUG foreach ( string s in bSettings . ValidationReport ( patchBounds )) { Debug . LogWarning ( $\"BuildSettings Report: {NavMesh.GetSettingsNameFromID(bSettings.agentTypeID)} : {s}\" ); } #endif // Make empty mesh data object. meshData [ agentIndex ] = new NavMeshData (); AsyncOperation buildOp = NavMeshBuilder . UpdateNavMeshDataAsync ( meshData [ agentIndex ], bSettings , buildSources , patchBounds ); while (! buildOp . isDone ) yield return null ; } if ( rebuildAll ) { NavMesh . RemoveAllNavMeshData (); } for ( int nmd = 0 ; nmd < meshData . Length ; nmd ++) { NavMesh . AddNavMeshData ( meshData [ nmd ]); } yield return null ; } There are a few key lines there, particularly the various yield return null; ones. If you're not familiar with coroutines, that's just code for \"stop here for this frame, go do whatever else you want, and resume here on the next frame.\" In particular, most of the (non) work is done by: while (! buildOp . isDone ) yield return null ; That line is where most of the time in the coroutine is spent. It just checks to see \"is the AsyncOperation done, yet?\" And yields until the next frame if it isn't. Eventually, everything completes and the rest of the code takes only a few milliseconds to actually instantiate the mesh. Also note that we build all the meshes, then remove existing ones (if we're going to), then add the new ones all at once rather than as each one is built. This minimizes the time when no mesh exists at all -- in fact, since there's no yield between the removal and the adds, the new mesh should be available in the very same frame as the old one goes away. (The old NavMesh may or may not still be valid that long, but for most uses it won't matter if it hangs around while we make the new one.)","title":"Rebuild for Asynchronicity"},{"location":"blog/runtime_navmesh/#so-does-it-work","text":"In a nutshell, yes. There's no stutter at all when new NavMeshes are being built or instantiated; I had to put Debug logging in or keep the scene window open even to know when it happened. Was it worth all that effort? Also, yes; being able to build at runtime without destroying the frame rate makes possible scenarios that otherwise wouldn't be, even if the \"wait\" for the NavMesh to become available isn't ideal. For small NavMeshes (a simple dungeon level, basement, maybe even a small village or house), this may very well be usable even several times a second (it can't be every frame because of the yield returns ). And for much larger or more complex meshes, it at least makes building them possible . The biggest caveat is that if you're doing something like floating origins, where the terrains occasionally move about and have to be re-generated (remember NavMeshes have to be on Navigation Static objects), your NavMeshAgents have to be able to account for periods where the NavMesh \"goes away\" and a new one isn't available yet. That's a pain, but it's not too horrible.","title":"So does it work?"}]}